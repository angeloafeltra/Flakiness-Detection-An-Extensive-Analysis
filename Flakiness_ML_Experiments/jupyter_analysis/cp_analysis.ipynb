{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi funzionamento cross project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9484 entries, 0 to 9483\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   nameProject               9484 non-null   object \n",
      " 1   testCase                  9484 non-null   object \n",
      " 2   tloc                      9484 non-null   int64  \n",
      " 3   tmcCabe                   9484 non-null   int64  \n",
      " 4   assertionDensity          9484 non-null   float64\n",
      " 5   assertionRoulette         9484 non-null   int64  \n",
      " 6   mysteryGuest              9484 non-null   int64  \n",
      " 7   eagerTest                 9484 non-null   int64  \n",
      " 8   sensitiveEquality         9484 non-null   int64  \n",
      " 9   resourceOptimism          9484 non-null   int64  \n",
      " 10  conditionalTestLogic      9484 non-null   int64  \n",
      " 11  fireAndForget             9484 non-null   int64  \n",
      " 12  testRunWar                9484 non-null   int64  \n",
      " 13  loc                       9484 non-null   int64  \n",
      " 14  lcom2                     9484 non-null   int64  \n",
      " 15  lcom5                     9484 non-null   int64  \n",
      " 16  cbo                       9484 non-null   int64  \n",
      " 17  wmc                       9484 non-null   int64  \n",
      " 18  rfc                       9484 non-null   int64  \n",
      " 19  mpc                       9484 non-null   int64  \n",
      " 20  halsteadVocabulary        9484 non-null   int64  \n",
      " 21  halsteadLength            9484 non-null   int64  \n",
      " 22  halsteadVolume            9484 non-null   float64\n",
      " 23  classDataShouldBePrivate  9484 non-null   int64  \n",
      " 24  complexClass              9484 non-null   int64  \n",
      " 25  spaghettiCode             9484 non-null   int64  \n",
      " 26  isFlaky                   9484 non-null   int64  \n",
      " 27  functionalDecomposition   9484 non-null   int64  \n",
      " 28  godClass                  9484 non-null   int64  \n",
      "dtypes: float64(2), int64(25), object(2)\n",
      "memory usage: 2.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "datasetName='FlakeFlagger_Pulito'\n",
    "dataset = pd.read_csv(os.path.join('..','..','Dataset','{}.csv'.format(datasetName)))\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleziono 3 repository in modo casuale su cui eseguire l'analisi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 1: hbase_e593f0efbf1144bcb5909d2630321e631a2e66bb\n",
      "Repository 2: activiti_b11f757a\n",
      "Repository 3: hector_29e88d0b988d9e5c8dc3b529414a270805ce0d7c\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "list_repository=dataset['nameProject'].unique()\n",
    "repository1=random.choice(list_repository)\n",
    "repository2=random.choice(list_repository)\n",
    "repository3=random.choice(list_repository)\n",
    "\n",
    "print(\"Repository 1: {}\".format(repository1))\n",
    "print(\"Repository 2: {}\".format(repository2))\n",
    "print(\"Repository 3: {}\".format(repository3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CrossProject - Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "\n",
    "def eval_and_log_metrics(prefix,  y_true, y_predict):\n",
    "    acc=accuracy_score(y_true,y_predict)\n",
    "    pr=precision_score(y_true,y_predict)\n",
    "    rec=recall_score(y_true,y_predict)\n",
    "    f1=f1_score(y_true,y_predict)\n",
    "\n",
    "    print(\"    |--- {}_ACC\".format(prefix),acc)\n",
    "    print(\"    |--- {}_PR\".format(prefix),pr)\n",
    "    print(\"    |--- {}_REC\".format(prefix),rec)\n",
    "    print(\"    |--- {}_F1\".format(prefix),f1)\n",
    "\n",
    "    return acc,pr,rec,f1\n",
    "\n",
    "\n",
    "def val_and_log_metrics(y_true, y_predict,print=True):\n",
    "    acc = accuracy_score(y_true, y_predict)\n",
    "    pr = precision_score(y_true, y_predict)\n",
    "    rec = recall_score(y_true, y_predict)\n",
    "    f1 = f1_score(y_true, y_predict)\n",
    "    auc = roc_auc_score(y_true, y_predict)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_predict).ravel()\n",
    "    fpr, tpr, _ = roc_curve(y_true,  y_predict)\n",
    "    \n",
    "    if print:\n",
    "        print(\"    |--- TEST_ACC\",acc)\n",
    "        print(\"    |--- TEST_PR\",pr)\n",
    "        print(\"    |--- TEST_REC\",rec)\n",
    "        print(\"    |--- TEST_F1\",f1)\n",
    "        print(\"    |--- TEST_AUC\",auc)\n",
    "\n",
    "    return acc, pr, rec, f1, tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def informationGain_epplsilon_feature(X,y):\n",
    "    eppsilon_feature=[]\n",
    "\n",
    "    randomForest=RandomForestClassifier(n_estimators=200,random_state=0,n_jobs=1)\n",
    "    columns_name=X.columns  #Nome Features\n",
    "    randomForest.fit(X=X,y=y)\n",
    "    importanceFeatures=randomForest.feature_importances_\n",
    "    indices = np.argsort(importanceFeatures)[::-1] #Ordino gli indici in maniera decrescente\n",
    "\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        if importanceFeatures[indices[f]] < 0.02:\n",
    "            eppsilon_feature.append(X.columns[indices[f]])\n",
    "\n",
    "    return eppsilon_feature\n",
    "\n",
    "\n",
    "def multicollinearity_eppsilon_feature(X):\n",
    "    eppsilon_features=[]\n",
    "\n",
    "    eliminato = True\n",
    "    while eliminato:\n",
    "        max = 0\n",
    "\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]  # Calcolo il vif\n",
    "        vif[\"features\"] = X.columns\n",
    "\n",
    "        for vif_value, feature in zip(vif[\"VIF Factor\"], vif[\"features\"]):\n",
    "            if vif_value >= 5:\n",
    "                if vif_value > max:\n",
    "                    max = vif_value\n",
    "                    feature_da_rimuovere = feature\n",
    "\n",
    "        if max > 0:\n",
    "            eliminato = True\n",
    "            X = X.drop([feature_da_rimuovere], axis=1)\n",
    "            eppsilon_features.append(feature_da_rimuovere)\n",
    "        else:\n",
    "            eliminato = False\n",
    "\n",
    "    return eppsilon_features\n",
    "\n",
    "\n",
    "\n",
    "class FeatureSelection(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.eppsilon_features=[]\n",
    "        X_copy=copy.copy(X)\n",
    "        if isinstance(X_copy, np.ndarray):\n",
    "            X_copy = pd.DataFrame(X_copy)\n",
    "\n",
    "        #Multicollinearity\n",
    "        self.eppsilon_features=self.eppsilon_features+multicollinearity_eppsilon_feature(X_copy)\n",
    "        X_copy.drop(self.eppsilon_features,axis=1)\n",
    "        #Information Gain\n",
    "        self.eppsilon_features=self.eppsilon_features+informationGain_epplsilon_feature(X_copy,y)\n",
    "        mlflow.log_param(\"Eppsilon_features\",len(self.eppsilon_features))\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        X=X.drop(self.eppsilon_features,axis=1)\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X,y)\n",
    "        X=self.transform(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository: hbase_e593f0efbf1144bcb5909d2630321e631a2e66bb\n",
      "    |--- Train_ACC 1.0\n",
      "    |--- Train_PR 1.0\n",
      "    |--- Train_REC 1.0\n",
      "    |--- Train_F1 1.0\n",
      "     Performance Test\n",
      "    |--- TEST_ACC 0.9780821917808219\n",
      "    |--- TEST_PR 0.8656716417910447\n",
      "    |--- TEST_REC 0.651685393258427\n",
      "    |--- TEST_F1 0.7435897435897435\n",
      "    |--- TEST_AUC 0.8232505307305961\n",
      "     Performance Target\n",
      "    |--- TEST_ACC 0.6777777777777778\n",
      "    |--- TEST_PR 0.4\n",
      "    |--- TEST_REC 0.03508771929824561\n",
      "    |--- TEST_F1 0.06451612903225806\n",
      "    |--- TEST_AUC 0.5053487376979033\n",
      "\n",
      "Repository: activiti_b11f757a\n",
      "    |--- Train_ACC 1.0\n",
      "    |--- Train_PR 1.0\n",
      "    |--- Train_REC 1.0\n",
      "    |--- Train_F1 1.0\n",
      "     Performance Test\n",
      "    |--- TEST_ACC 0.978513356562137\n",
      "    |--- TEST_PR 0.9285714285714286\n",
      "    |--- TEST_REC 0.7155963302752294\n",
      "    |--- TEST_F1 0.8082901554404146\n",
      "    |--- TEST_AUC 0.8559382767309192\n",
      "     Performance Target\n",
      "    |--- TEST_ACC 0.9816933638443935\n",
      "    |--- TEST_PR 0.0\n",
      "    |--- TEST_REC 0.0\n",
      "    |--- TEST_F1 0.0\n",
      "    |--- TEST_AUC 0.5\n",
      "\n",
      "Repository: hector_29e88d0b988d9e5c8dc3b529414a270805ce0d7c\n",
      "    |--- Train_ACC 1.0\n",
      "    |--- Train_PR 1.0\n",
      "    |--- Train_REC 1.0\n",
      "    |--- Train_F1 1.0\n",
      "     Performance Test\n",
      "    |--- TEST_ACC 0.9797116924719701\n",
      "    |--- TEST_PR 0.8850574712643678\n",
      "    |--- TEST_REC 0.7333333333333333\n",
      "    |--- TEST_F1 0.8020833333333334\n",
      "    |--- TEST_AUC 0.8638386123680242\n",
      "     Performance Target\n",
      "    |--- TEST_ACC 0.7295081967213115\n",
      "    |--- TEST_PR 0.0\n",
      "    |--- TEST_REC 0.0\n",
      "    |--- TEST_F1 0.0\n",
      "    |--- TEST_AUC 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "list_target=[repository1, repository2, repository3]\n",
    "\n",
    "tmp={\n",
    "    'repository': [],\n",
    "    'X_source_train': [],\n",
    "    'y_source_train': [],\n",
    "    'X_source_test': [],\n",
    "    'y_source_test': [],\n",
    "    'X_target': [],\n",
    "    'y_target': [],\n",
    "    'clf': [],\n",
    "}\n",
    "\n",
    "for target in list_target:\n",
    "    print('Repository: {}'.format(target))\n",
    "    \n",
    "    tmp['repository'].append(target)\n",
    "    target_set=dataset.loc[dataset['nameProject']==target]\n",
    "    source_set=dataset.loc[dataset['nameProject']!=target]\n",
    "\n",
    "    X_target=target_set.drop(['nameProject','testCase','isFlaky'], axis=1)\n",
    "    y_target=target_set['isFlaky']\n",
    "    X_source=source_set.drop(['nameProject','testCase','isFlaky'], axis=1)\n",
    "    y_source=source_set['isFlaky']\n",
    "    \n",
    "    columns=X_source.columns\n",
    "\n",
    "    X_source_train, X_source_test, y_source_train, y_source_test= train_test_split(X_source, y_source,stratify=y_source, test_size=0.20,random_state=42)\n",
    "    \n",
    "    tmp['X_source_train'].append(X_source_train)\n",
    "    tmp['y_source_train'].append(y_source_train)\n",
    "    tmp['X_source_test'].append(X_source_test)\n",
    "    tmp['y_source_test'].append(y_source_test)\n",
    "    tmp['X_target'].append(X_target)\n",
    "    tmp['y_target'].append(y_target)\n",
    "    \n",
    "    pipeline = Pipeline(steps = [('scaler',MinMaxScaler()),\n",
    "                                 (\"model\", RandomForestClassifier(criterion='gini',\n",
    "                                                                  n_estimators=150,\n",
    "                                                                  class_weight='balanced', random_state=42))])\n",
    "\n",
    "    pipeline.fit(X_source_train,y_source_train)\n",
    "    y_predict=pipeline.predict(X_source_train)\n",
    "    eval_and_log_metrics('Train',y_source_train,y_predict)\n",
    "    print('     Performance Test')\n",
    "    y_predict=pipeline.predict(X_source_test)\n",
    "    val_and_log_metrics(y_source_test,y_predict)\n",
    "    print('     Performance Target')\n",
    "    y_predict=pipeline.predict(X_target)\n",
    "    val_and_log_metrics(y_target,y_predict)\n",
    "    print('')\n",
    "    \n",
    "    tmp['clf'].append(pipeline.get_params('steps')['model'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_distribution(X_source_train, X_source_test, X_target, columns):\n",
    "    \n",
    "    data={\n",
    "        'column':[],\n",
    "        \n",
    "        'Mean_S_TR':[],\n",
    "        'STD_S_TR': [],\n",
    "        'Mean_S_T':[],\n",
    "        'STD_S_T': [],\n",
    "        'Mean_T':[],\n",
    "        'STD_T': [],\n",
    "        \n",
    "        'Min_S_TR':[],\n",
    "        'Max_S_TR': [],\n",
    "        'Min_S_T':[],\n",
    "        'Max_S_T': [],\n",
    "        'Min_T':[],\n",
    "        'Max_T': [],\n",
    "    }\n",
    "    \n",
    "    for col in columns:\n",
    "        data['column'].append(col)\n",
    "        \n",
    "        data['Mean_S_TR'].append(X_source_train[col].mean())\n",
    "        data['STD_S_TR'].append(X_source_train[col].std())\n",
    "        data['Mean_S_T'].append(X_source_test[col].mean())\n",
    "        data['STD_S_T'].append(X_source_test[col].std())\n",
    "        data['Mean_T'].append(X_target[col].mean())\n",
    "        data['STD_T'].append(X_target[col].std())\n",
    "        \n",
    "        data['Min_S_TR'].append(X_source_train[col].min())\n",
    "        data['Max_S_TR'].append(X_source_train[col].max())\n",
    "        data['Min_S_T'].append(X_source_test[col].min())\n",
    "        data['Max_S_T'].append(X_source_test[col].max())\n",
    "        data['Min_T'].append(X_target[col].min())\n",
    "        data['Max_T'].append(X_target[col].max())\n",
    "    \n",
    "    df=pd.DataFrame(data)\n",
    "    display(df)\n",
    "\n",
    "\n",
    "def print_featureImportances(clf,columns):\n",
    "\n",
    "    importanceFeatures=clf.feature_importances_\n",
    "    indices = np.argsort(importanceFeatures)[::-1]\n",
    "    for i in indices:\n",
    "        print('{} : {}'.format(columns[i], importanceFeatures[i]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hbase_e593f0efbf1144bcb5909d2630321e631a2e66bb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>Mean_S_TR</th>\n",
       "      <th>STD_S_TR</th>\n",
       "      <th>Mean_S_T</th>\n",
       "      <th>STD_S_T</th>\n",
       "      <th>Mean_T</th>\n",
       "      <th>STD_T</th>\n",
       "      <th>Min_S_TR</th>\n",
       "      <th>Max_S_TR</th>\n",
       "      <th>Min_S_T</th>\n",
       "      <th>Max_S_T</th>\n",
       "      <th>Min_T</th>\n",
       "      <th>Max_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tloc</td>\n",
       "      <td>10.819427</td>\n",
       "      <td>10.965291</td>\n",
       "      <td>10.602740</td>\n",
       "      <td>11.577139</td>\n",
       "      <td>20.091667</td>\n",
       "      <td>17.753024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tmcCabe</td>\n",
       "      <td>2.175366</td>\n",
       "      <td>0.968080</td>\n",
       "      <td>2.190137</td>\n",
       "      <td>0.940390</td>\n",
       "      <td>2.758333</td>\n",
       "      <td>1.073841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assertionDensity</td>\n",
       "      <td>0.154304</td>\n",
       "      <td>0.224010</td>\n",
       "      <td>0.141676</td>\n",
       "      <td>0.200503</td>\n",
       "      <td>0.097307</td>\n",
       "      <td>0.145783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.788732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assertionRoulette</td>\n",
       "      <td>1.571859</td>\n",
       "      <td>3.073750</td>\n",
       "      <td>1.431781</td>\n",
       "      <td>2.623460</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>4.090511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mysteryGuest</td>\n",
       "      <td>0.250582</td>\n",
       "      <td>1.389222</td>\n",
       "      <td>0.217534</td>\n",
       "      <td>1.238243</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>1.146577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eagerTest</td>\n",
       "      <td>1.672558</td>\n",
       "      <td>2.701446</td>\n",
       "      <td>1.567671</td>\n",
       "      <td>2.389888</td>\n",
       "      <td>2.502778</td>\n",
       "      <td>3.191212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sensitiveEquality</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>0.232895</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.157285</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.216164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resourceOptimism</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>0.183520</td>\n",
       "      <td>0.020274</td>\n",
       "      <td>0.207123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conditionalTestLogic</td>\n",
       "      <td>0.704206</td>\n",
       "      <td>1.596978</td>\n",
       "      <td>0.711781</td>\n",
       "      <td>1.729263</td>\n",
       "      <td>2.119444</td>\n",
       "      <td>3.594279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fireAndForget</td>\n",
       "      <td>0.011508</td>\n",
       "      <td>0.142902</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.104248</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>testRunWar</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>loc</td>\n",
       "      <td>287.715988</td>\n",
       "      <td>443.045241</td>\n",
       "      <td>293.008767</td>\n",
       "      <td>479.401267</td>\n",
       "      <td>786.841667</td>\n",
       "      <td>853.141205</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3259.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3259.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2770.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lcom2</td>\n",
       "      <td>447.788327</td>\n",
       "      <td>1880.311793</td>\n",
       "      <td>487.123836</td>\n",
       "      <td>2084.209072</td>\n",
       "      <td>642.955556</td>\n",
       "      <td>1150.782085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14183.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14183.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3514.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lcom5</td>\n",
       "      <td>1.994109</td>\n",
       "      <td>3.734486</td>\n",
       "      <td>1.899726</td>\n",
       "      <td>3.413294</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>2.064152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cbo</td>\n",
       "      <td>12.592547</td>\n",
       "      <td>12.175963</td>\n",
       "      <td>13.033425</td>\n",
       "      <td>12.669616</td>\n",
       "      <td>20.677778</td>\n",
       "      <td>15.982635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wmc</td>\n",
       "      <td>50.960132</td>\n",
       "      <td>83.941929</td>\n",
       "      <td>51.302466</td>\n",
       "      <td>89.612938</td>\n",
       "      <td>101.400000</td>\n",
       "      <td>114.207069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rfc</td>\n",
       "      <td>61.295931</td>\n",
       "      <td>89.220195</td>\n",
       "      <td>63.612055</td>\n",
       "      <td>94.981881</td>\n",
       "      <td>147.138889</td>\n",
       "      <td>185.867544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mpc</td>\n",
       "      <td>42.561721</td>\n",
       "      <td>69.598367</td>\n",
       "      <td>44.979726</td>\n",
       "      <td>73.580515</td>\n",
       "      <td>116.169444</td>\n",
       "      <td>156.635861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>halsteadVocabulary</td>\n",
       "      <td>985.103850</td>\n",
       "      <td>1367.156053</td>\n",
       "      <td>920.121644</td>\n",
       "      <td>1224.693088</td>\n",
       "      <td>3086.772222</td>\n",
       "      <td>4491.888719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12109.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12109.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>halsteadLength</td>\n",
       "      <td>190.993287</td>\n",
       "      <td>180.562276</td>\n",
       "      <td>183.017534</td>\n",
       "      <td>173.064515</td>\n",
       "      <td>526.622222</td>\n",
       "      <td>678.874475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1265.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1293.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>halsteadVolume</td>\n",
       "      <td>1370.501597</td>\n",
       "      <td>1547.425274</td>\n",
       "      <td>1303.160268</td>\n",
       "      <td>1456.354149</td>\n",
       "      <td>4596.453581</td>\n",
       "      <td>6483.547706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11893.155885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11893.155885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19626.038963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>classDataShouldBePrivate</td>\n",
       "      <td>0.627757</td>\n",
       "      <td>4.123631</td>\n",
       "      <td>0.792877</td>\n",
       "      <td>4.902543</td>\n",
       "      <td>0.547222</td>\n",
       "      <td>2.560247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>complexClass</td>\n",
       "      <td>16.228798</td>\n",
       "      <td>82.940119</td>\n",
       "      <td>16.814795</td>\n",
       "      <td>88.896214</td>\n",
       "      <td>52.438889</td>\n",
       "      <td>121.967056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>spaghettiCode</td>\n",
       "      <td>5.137964</td>\n",
       "      <td>50.864211</td>\n",
       "      <td>3.106301</td>\n",
       "      <td>33.339243</td>\n",
       "      <td>175.594444</td>\n",
       "      <td>388.854022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>functionalDecomposition</td>\n",
       "      <td>0.145636</td>\n",
       "      <td>0.488030</td>\n",
       "      <td>0.158904</td>\n",
       "      <td>0.509729</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.166062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>godClass</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      column    Mean_S_TR     STD_S_TR     Mean_S_T  \\\n",
       "0                       tloc    10.819427    10.965291    10.602740   \n",
       "1                    tmcCabe     2.175366     0.968080     2.190137   \n",
       "2           assertionDensity     0.154304     0.224010     0.141676   \n",
       "3          assertionRoulette     1.571859     3.073750     1.431781   \n",
       "4               mysteryGuest     0.250582     1.389222     0.217534   \n",
       "5                  eagerTest     1.672558     2.701446     1.567671   \n",
       "6          sensitiveEquality     0.029045     0.232895     0.021918   \n",
       "7           resourceOptimism     0.020962     0.183520     0.020274   \n",
       "8       conditionalTestLogic     0.704206     1.596978     0.711781   \n",
       "9              fireAndForget     0.011508     0.142902     0.009863   \n",
       "10                testRunWar     0.000000     0.000000     0.000000   \n",
       "11                       loc   287.715988   443.045241   293.008767   \n",
       "12                     lcom2   447.788327  1880.311793   487.123836   \n",
       "13                     lcom5     1.994109     3.734486     1.899726   \n",
       "14                       cbo    12.592547    12.175963    13.033425   \n",
       "15                       wmc    50.960132    83.941929    51.302466   \n",
       "16                       rfc    61.295931    89.220195    63.612055   \n",
       "17                       mpc    42.561721    69.598367    44.979726   \n",
       "18        halsteadVocabulary   985.103850  1367.156053   920.121644   \n",
       "19            halsteadLength   190.993287   180.562276   183.017534   \n",
       "20            halsteadVolume  1370.501597  1547.425274  1303.160268   \n",
       "21  classDataShouldBePrivate     0.627757     4.123631     0.792877   \n",
       "22              complexClass    16.228798    82.940119    16.814795   \n",
       "23             spaghettiCode     5.137964    50.864211     3.106301   \n",
       "24   functionalDecomposition     0.145636     0.488030     0.158904   \n",
       "25                  godClass     0.000000     0.000000     0.000000   \n",
       "\n",
       "        STD_S_T       Mean_T        STD_T  Min_S_TR      Max_S_TR  Min_S_T  \\\n",
       "0     11.577139    20.091667    17.753024       2.0    194.000000      2.0   \n",
       "1      0.940390     2.758333     1.073841       1.0      9.000000      1.0   \n",
       "2      0.200503     0.097307     0.145783       0.0      1.788732      0.0   \n",
       "3      2.623460     2.444444     4.090511       0.0     52.000000      0.0   \n",
       "4      1.238243     0.211111     1.146577       0.0     22.000000      0.0   \n",
       "5      2.389888     2.502778     3.191212       0.0     42.000000      0.0   \n",
       "6      0.157285     0.025000     0.216164       0.0      6.000000      0.0   \n",
       "7      0.207123     0.000000     0.000000       0.0      2.000000      0.0   \n",
       "8      1.729263     2.119444     3.594279       0.0     37.000000      0.0   \n",
       "9      0.104248     0.027778     0.180700       0.0      5.000000      0.0   \n",
       "10     0.000000     0.000000     0.000000       0.0      0.000000      0.0   \n",
       "11   479.401267   786.841667   853.141205      16.0   3259.000000     16.0   \n",
       "12  2084.209072   642.955556  1150.782085       0.0  14183.000000      0.0   \n",
       "13     3.413294     2.033333     2.064152       0.0     38.000000      0.0   \n",
       "14    12.669616    20.677778    15.982635       0.0     64.000000      0.0   \n",
       "15    89.612938   101.400000   114.207069       0.0    583.000000      0.0   \n",
       "16    94.981881   147.138889   185.867544       0.0    531.000000      0.0   \n",
       "17    73.580515   116.169444   156.635861       0.0    450.000000      0.0   \n",
       "18  1224.693088  3086.772222  4491.888719       1.0  12109.000000      1.0   \n",
       "19   173.064515   526.622222   678.874475       1.0   1265.000000      1.0   \n",
       "20  1456.354149  4596.453581  6483.547706       0.0  11893.155885      0.0   \n",
       "21     4.902543     0.547222     2.560247       0.0     30.000000      0.0   \n",
       "22    88.896214    52.438889   121.967056       0.0    583.000000      0.0   \n",
       "23    33.339243   175.594444   388.854022       0.0    855.000000      0.0   \n",
       "24     0.509729     0.016667     0.166062       0.0      2.000000      0.0   \n",
       "25     0.000000     0.000000     0.000000       0.0      0.000000      0.0   \n",
       "\n",
       "         Max_S_T  Min_T         Max_T  \n",
       "0     187.000000    2.0    109.000000  \n",
       "1       6.000000    1.0      7.000000  \n",
       "2       1.500000    0.0      0.842105  \n",
       "3      24.000000    0.0     40.000000  \n",
       "4      20.000000    0.0     13.000000  \n",
       "5      23.000000    0.0     14.000000  \n",
       "6       2.000000    0.0      2.000000  \n",
       "7       5.000000    0.0      0.000000  \n",
       "8      42.000000    0.0     23.000000  \n",
       "9       2.000000    0.0      2.000000  \n",
       "10      0.000000    0.0      0.000000  \n",
       "11   3259.000000   47.0   2770.000000  \n",
       "12  14183.000000    0.0   3514.000000  \n",
       "13     32.000000    0.0      8.000000  \n",
       "14     64.000000    0.0     64.000000  \n",
       "15    583.000000    2.0    360.000000  \n",
       "16    531.000000    1.0    614.000000  \n",
       "17    450.000000    0.0    514.000000  \n",
       "18  12109.000000    1.0  13477.000000  \n",
       "19   1293.000000    1.0   2064.000000  \n",
       "20  11893.155885    0.0  19626.038963  \n",
       "21     80.000000    0.0     14.000000  \n",
       "22    583.000000    0.0    360.000000  \n",
       "23    855.000000    0.0   1180.000000  \n",
       "24      2.000000    0.0      2.000000  \n",
       "25      0.000000    0.0      0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Feature Importances\n",
      "tloc : 0.09311358167634919\n",
      "halsteadVocabulary : 0.08306445664456397\n",
      "halsteadVolume : 0.08003649622329453\n",
      "wmc : 0.07850923789474323\n",
      "loc : 0.07616375675220743\n",
      "halsteadLength : 0.07607171957369682\n",
      "mpc : 0.06523848302866664\n",
      "lcom2 : 0.06099855964315879\n",
      "cbo : 0.057040656333604924\n",
      "mysteryGuest : 0.050557073090011326\n",
      "rfc : 0.0499092178004732\n",
      "assertionDensity : 0.04738513800134234\n",
      "eagerTest : 0.03926984918760636\n",
      "assertionRoulette : 0.03426416072543857\n",
      "tmcCabe : 0.032909592384881406\n",
      "conditionalTestLogic : 0.02764956785233591\n",
      "lcom5 : 0.02402269064785945\n",
      "fireAndForget : 0.00590906239720777\n",
      "spaghettiCode : 0.005474199156435799\n",
      "complexClass : 0.0042157133255936495\n",
      "resourceOptimism : 0.0023417209774260987\n",
      "sensitiveEquality : 0.0023213104231725296\n",
      "functionalDecomposition : 0.0020007124959912958\n",
      "classDataShouldBePrivate : 0.0015330437639387638\n",
      "testRunWar : 0.0\n",
      "godClass : 0.0\n",
      "\n",
      "\n",
      "activiti_b11f757a\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>Mean_S_TR</th>\n",
       "      <th>STD_S_TR</th>\n",
       "      <th>Mean_S_T</th>\n",
       "      <th>STD_S_T</th>\n",
       "      <th>Mean_T</th>\n",
       "      <th>STD_T</th>\n",
       "      <th>Min_S_TR</th>\n",
       "      <th>Max_S_TR</th>\n",
       "      <th>Min_S_T</th>\n",
       "      <th>Max_S_T</th>\n",
       "      <th>Min_T</th>\n",
       "      <th>Max_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tloc</td>\n",
       "      <td>10.794280</td>\n",
       "      <td>11.370814</td>\n",
       "      <td>10.414053</td>\n",
       "      <td>10.184406</td>\n",
       "      <td>15.183066</td>\n",
       "      <td>14.369319</td>\n",
       "      <td>2.0</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tmcCabe</td>\n",
       "      <td>2.250871</td>\n",
       "      <td>0.985630</td>\n",
       "      <td>2.217770</td>\n",
       "      <td>0.965210</td>\n",
       "      <td>1.767735</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assertionDensity</td>\n",
       "      <td>0.146126</td>\n",
       "      <td>0.220993</td>\n",
       "      <td>0.140301</td>\n",
       "      <td>0.214346</td>\n",
       "      <td>0.196495</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.788732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assertionRoulette</td>\n",
       "      <td>1.448171</td>\n",
       "      <td>2.827233</td>\n",
       "      <td>1.363531</td>\n",
       "      <td>2.330161</td>\n",
       "      <td>3.024027</td>\n",
       "      <td>4.951598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mysteryGuest</td>\n",
       "      <td>0.260308</td>\n",
       "      <td>1.410114</td>\n",
       "      <td>0.264808</td>\n",
       "      <td>1.392110</td>\n",
       "      <td>0.060641</td>\n",
       "      <td>0.580107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eagerTest</td>\n",
       "      <td>1.670877</td>\n",
       "      <td>2.597283</td>\n",
       "      <td>1.654472</td>\n",
       "      <td>2.916762</td>\n",
       "      <td>1.844394</td>\n",
       "      <td>2.723374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sensitiveEquality</td>\n",
       "      <td>0.030633</td>\n",
       "      <td>0.239347</td>\n",
       "      <td>0.028455</td>\n",
       "      <td>0.189199</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resourceOptimism</td>\n",
       "      <td>0.022213</td>\n",
       "      <td>0.193401</td>\n",
       "      <td>0.021487</td>\n",
       "      <td>0.196135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conditionalTestLogic</td>\n",
       "      <td>0.791812</td>\n",
       "      <td>1.830380</td>\n",
       "      <td>0.704413</td>\n",
       "      <td>1.511633</td>\n",
       "      <td>0.612128</td>\n",
       "      <td>1.644008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fireAndForget</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>0.149910</td>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.120019</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>testRunWar</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>loc</td>\n",
       "      <td>312.943961</td>\n",
       "      <td>493.734997</td>\n",
       "      <td>300.961092</td>\n",
       "      <td>492.330503</td>\n",
       "      <td>279.439359</td>\n",
       "      <td>341.788392</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3259.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3259.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lcom2</td>\n",
       "      <td>410.746951</td>\n",
       "      <td>1907.676812</td>\n",
       "      <td>412.236353</td>\n",
       "      <td>1982.630680</td>\n",
       "      <td>972.283753</td>\n",
       "      <td>1564.753136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14183.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14183.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lcom5</td>\n",
       "      <td>2.159117</td>\n",
       "      <td>3.753196</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.736775</td>\n",
       "      <td>0.172769</td>\n",
       "      <td>0.672579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cbo</td>\n",
       "      <td>13.621370</td>\n",
       "      <td>12.810480</td>\n",
       "      <td>13.414053</td>\n",
       "      <td>12.483755</td>\n",
       "      <td>7.116705</td>\n",
       "      <td>8.098484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wmc</td>\n",
       "      <td>51.951800</td>\n",
       "      <td>86.225746</td>\n",
       "      <td>50.123113</td>\n",
       "      <td>87.834904</td>\n",
       "      <td>66.284897</td>\n",
       "      <td>89.385314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rfc</td>\n",
       "      <td>68.684233</td>\n",
       "      <td>101.274352</td>\n",
       "      <td>66.118467</td>\n",
       "      <td>99.233348</td>\n",
       "      <td>33.762014</td>\n",
       "      <td>33.019979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mpc</td>\n",
       "      <td>50.557636</td>\n",
       "      <td>79.760675</td>\n",
       "      <td>48.587108</td>\n",
       "      <td>76.973902</td>\n",
       "      <td>3.042334</td>\n",
       "      <td>11.588270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>halsteadVocabulary</td>\n",
       "      <td>1027.932346</td>\n",
       "      <td>1605.293854</td>\n",
       "      <td>935.846109</td>\n",
       "      <td>1452.507286</td>\n",
       "      <td>1474.608696</td>\n",
       "      <td>2034.419382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13477.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13477.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>halsteadLength</td>\n",
       "      <td>202.710801</td>\n",
       "      <td>236.533436</td>\n",
       "      <td>188.572590</td>\n",
       "      <td>207.239401</td>\n",
       "      <td>225.008009</td>\n",
       "      <td>207.235341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>684.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>halsteadVolume</td>\n",
       "      <td>1482.224849</td>\n",
       "      <td>2129.982061</td>\n",
       "      <td>1355.096652</td>\n",
       "      <td>1831.254705</td>\n",
       "      <td>1708.513432</td>\n",
       "      <td>1849.725463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19626.038963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19626.038963</td>\n",
       "      <td>13.621371</td>\n",
       "      <td>6053.950070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>classDataShouldBePrivate</td>\n",
       "      <td>0.706882</td>\n",
       "      <td>4.419047</td>\n",
       "      <td>0.749710</td>\n",
       "      <td>4.496569</td>\n",
       "      <td>0.075515</td>\n",
       "      <td>0.908794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>complexClass</td>\n",
       "      <td>15.218060</td>\n",
       "      <td>84.396730</td>\n",
       "      <td>15.209640</td>\n",
       "      <td>86.031214</td>\n",
       "      <td>42.340961</td>\n",
       "      <td>95.927715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>spaghettiCode</td>\n",
       "      <td>12.575348</td>\n",
       "      <td>103.619579</td>\n",
       "      <td>9.248548</td>\n",
       "      <td>80.216802</td>\n",
       "      <td>4.393593</td>\n",
       "      <td>16.192167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1180.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>functionalDecomposition</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.486410</td>\n",
       "      <td>0.135889</td>\n",
       "      <td>0.461286</td>\n",
       "      <td>0.161327</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>godClass</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      column    Mean_S_TR     STD_S_TR     Mean_S_T  \\\n",
       "0                       tloc    10.794280    11.370814    10.414053   \n",
       "1                    tmcCabe     2.250871     0.985630     2.217770   \n",
       "2           assertionDensity     0.146126     0.220993     0.140301   \n",
       "3          assertionRoulette     1.448171     2.827233     1.363531   \n",
       "4               mysteryGuest     0.260308     1.410114     0.264808   \n",
       "5                  eagerTest     1.670877     2.597283     1.654472   \n",
       "6          sensitiveEquality     0.030633     0.239347     0.028455   \n",
       "7           resourceOptimism     0.022213     0.193401     0.021487   \n",
       "8       conditionalTestLogic     0.791812     1.830380     0.704413   \n",
       "9              fireAndForget     0.013357     0.149910     0.011034   \n",
       "10                testRunWar     0.000000     0.000000     0.000000   \n",
       "11                       loc   312.943961   493.734997   300.961092   \n",
       "12                     lcom2   410.746951  1907.676812   412.236353   \n",
       "13                     lcom5     2.159117     3.753196     2.166667   \n",
       "14                       cbo    13.621370    12.810480    13.414053   \n",
       "15                       wmc    51.951800    86.225746    50.123113   \n",
       "16                       rfc    68.684233   101.274352    66.118467   \n",
       "17                       mpc    50.557636    79.760675    48.587108   \n",
       "18        halsteadVocabulary  1027.932346  1605.293854   935.846109   \n",
       "19            halsteadLength   202.710801   236.533436   188.572590   \n",
       "20            halsteadVolume  1482.224849  2129.982061  1355.096652   \n",
       "21  classDataShouldBePrivate     0.706882     4.419047     0.749710   \n",
       "22              complexClass    15.218060    84.396730    15.209640   \n",
       "23             spaghettiCode    12.575348   103.619579     9.248548   \n",
       "24   functionalDecomposition     0.142857     0.486410     0.135889   \n",
       "25                  godClass     0.000000     0.000000     0.000000   \n",
       "\n",
       "        STD_S_T       Mean_T        STD_T  Min_S_TR      Max_S_TR  Min_S_T  \\\n",
       "0     10.184406    15.183066    14.369319       2.0    194.000000      2.0   \n",
       "1      0.965210     1.767735     0.762712       1.0      9.000000      1.0   \n",
       "2      0.214346     0.196495     0.188024       0.0      1.788732      0.0   \n",
       "3      2.330161     3.024027     4.951598       0.0     46.000000      0.0   \n",
       "4      1.392110     0.060641     0.580107       0.0     22.000000      0.0   \n",
       "5      2.916762     1.844394     2.723374       0.0     42.000000      0.0   \n",
       "6      0.189199     0.001144     0.033826       0.0      6.000000      0.0   \n",
       "7      0.196135     0.000000     0.000000       0.0      5.000000      0.0   \n",
       "8      1.511633     0.612128     1.644008       0.0     42.000000      0.0   \n",
       "9      0.120019     0.001144     0.033826       0.0      5.000000      0.0   \n",
       "10     0.000000     0.000000     0.000000       0.0      0.000000      0.0   \n",
       "11   492.330503   279.439359   341.788392      16.0   3259.000000     16.0   \n",
       "12  1982.630680   972.283753  1564.753136       0.0  14183.000000      0.0   \n",
       "13     3.736775     0.172769     0.672579       0.0     38.000000      0.0   \n",
       "14    12.483755     7.116705     8.098484       0.0     64.000000      0.0   \n",
       "15    87.834904    66.284897    89.385314       0.0    583.000000      0.0   \n",
       "16    99.233348    33.762014    33.019979       0.0    614.000000      0.0   \n",
       "17    76.973902     3.042334    11.588270       0.0    514.000000      0.0   \n",
       "18  1452.507286  1474.608696  2034.419382       1.0  13477.000000      1.0   \n",
       "19   207.239401   225.008009   207.235341       1.0   2064.000000      1.0   \n",
       "20  1831.254705  1708.513432  1849.725463       0.0  19626.038963      0.0   \n",
       "21     4.496569     0.075515     0.908794       0.0     80.000000      0.0   \n",
       "22    86.031214    42.340961    95.927715       0.0    583.000000      0.0   \n",
       "23    80.216802     4.393593    16.192167       0.0   1180.000000      0.0   \n",
       "24     0.461286     0.161327     0.515791       0.0      2.000000      0.0   \n",
       "25     0.000000     0.000000     0.000000       0.0      0.000000      0.0   \n",
       "\n",
       "         Max_S_T      Min_T        Max_T  \n",
       "0     120.000000   3.000000   136.000000  \n",
       "1       8.000000   1.000000     6.000000  \n",
       "2       1.772727   0.000000     0.863636  \n",
       "3      27.000000   0.000000    52.000000  \n",
       "4      19.000000   0.000000    11.000000  \n",
       "5      42.000000   0.000000    18.000000  \n",
       "6       2.000000   0.000000     1.000000  \n",
       "7       2.000000   0.000000     0.000000  \n",
       "8      17.000000   0.000000    21.000000  \n",
       "9       2.000000   0.000000     1.000000  \n",
       "10      0.000000   0.000000     0.000000  \n",
       "11   3259.000000  17.000000  1227.000000  \n",
       "12  14183.000000   0.000000  4950.000000  \n",
       "13     32.000000   0.000000     5.000000  \n",
       "14     64.000000   0.000000    39.000000  \n",
       "15    583.000000   0.000000   300.000000  \n",
       "16    614.000000   0.000000   143.000000  \n",
       "17    514.000000   0.000000   129.000000  \n",
       "18  13477.000000   7.000000  6980.000000  \n",
       "19   2064.000000   7.000000   684.000000  \n",
       "20  19626.038963  13.621371  6053.950070  \n",
       "21     30.000000   0.000000    11.000000  \n",
       "22    583.000000   0.000000   300.000000  \n",
       "23   1180.000000   0.000000    64.000000  \n",
       "24      2.000000   0.000000     2.000000  \n",
       "25      0.000000   0.000000     0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Feature Importances\n",
      "tloc : 0.08961268151446206\n",
      "wmc : 0.08656745455675076\n",
      "loc : 0.08542460228126551\n",
      "halsteadVolume : 0.07787527086301181\n",
      "lcom2 : 0.0765350230727314\n",
      "halsteadVocabulary : 0.07309734919286012\n",
      "cbo : 0.06918585809899326\n",
      "halsteadLength : 0.06696481281640637\n",
      "mpc : 0.05936710583839135\n",
      "rfc : 0.051706305734729924\n",
      "assertionDensity : 0.04564519137476185\n",
      "mysteryGuest : 0.03994052674832842\n",
      "assertionRoulette : 0.035445821648995436\n",
      "lcom5 : 0.032616537706298424\n",
      "tmcCabe : 0.03259758095258692\n",
      "eagerTest : 0.03070609407492443\n",
      "conditionalTestLogic : 0.027245056372045648\n",
      "fireAndForget : 0.006153589222230839\n",
      "functionalDecomposition : 0.003429709494296192\n",
      "spaghettiCode : 0.002276032381768186\n",
      "resourceOptimism : 0.0021863134468109095\n",
      "complexClass : 0.0018659502675040748\n",
      "sensitiveEquality : 0.0018030218551556435\n",
      "classDataShouldBePrivate : 0.0017521104846905647\n",
      "testRunWar : 0.0\n",
      "godClass : 0.0\n",
      "\n",
      "\n",
      "hector_29e88d0b988d9e5c8dc3b529414a270805ce0d7c\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>Mean_S_TR</th>\n",
       "      <th>STD_S_TR</th>\n",
       "      <th>Mean_S_T</th>\n",
       "      <th>STD_S_T</th>\n",
       "      <th>Mean_T</th>\n",
       "      <th>STD_T</th>\n",
       "      <th>Min_S_TR</th>\n",
       "      <th>Max_S_TR</th>\n",
       "      <th>Min_S_T</th>\n",
       "      <th>Max_S_T</th>\n",
       "      <th>Min_T</th>\n",
       "      <th>Max_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tloc</td>\n",
       "      <td>11.101082</td>\n",
       "      <td>11.593512</td>\n",
       "      <td>11.078484</td>\n",
       "      <td>11.336196</td>\n",
       "      <td>13.672131</td>\n",
       "      <td>11.994105</td>\n",
       "      <td>2.0</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tmcCabe</td>\n",
       "      <td>2.201095</td>\n",
       "      <td>0.971767</td>\n",
       "      <td>2.219434</td>\n",
       "      <td>0.958769</td>\n",
       "      <td>1.860656</td>\n",
       "      <td>1.208206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assertionDensity</td>\n",
       "      <td>0.150169</td>\n",
       "      <td>0.218041</td>\n",
       "      <td>0.149381</td>\n",
       "      <td>0.218713</td>\n",
       "      <td>0.126621</td>\n",
       "      <td>0.152860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.788732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assertionRoulette</td>\n",
       "      <td>1.553478</td>\n",
       "      <td>2.948291</td>\n",
       "      <td>1.641751</td>\n",
       "      <td>3.410534</td>\n",
       "      <td>2.106557</td>\n",
       "      <td>2.744814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mysteryGuest</td>\n",
       "      <td>0.257044</td>\n",
       "      <td>1.383771</td>\n",
       "      <td>0.201281</td>\n",
       "      <td>1.267003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eagerTest</td>\n",
       "      <td>1.675124</td>\n",
       "      <td>2.664727</td>\n",
       "      <td>1.725040</td>\n",
       "      <td>2.727804</td>\n",
       "      <td>1.590164</td>\n",
       "      <td>2.023638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sensitiveEquality</td>\n",
       "      <td>0.024970</td>\n",
       "      <td>0.191405</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>0.311937</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.090536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resourceOptimism</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>0.182644</td>\n",
       "      <td>0.018687</td>\n",
       "      <td>0.199286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conditionalTestLogic</td>\n",
       "      <td>0.745493</td>\n",
       "      <td>1.648657</td>\n",
       "      <td>0.810464</td>\n",
       "      <td>2.163918</td>\n",
       "      <td>0.827869</td>\n",
       "      <td>1.497616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fireAndForget</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>0.128703</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.173899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>testRunWar</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>loc</td>\n",
       "      <td>311.879023</td>\n",
       "      <td>488.100148</td>\n",
       "      <td>303.024026</td>\n",
       "      <td>467.235057</td>\n",
       "      <td>121.450820</td>\n",
       "      <td>126.701452</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3259.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3259.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>516.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lcom2</td>\n",
       "      <td>480.199626</td>\n",
       "      <td>1946.188934</td>\n",
       "      <td>420.001068</td>\n",
       "      <td>1764.024814</td>\n",
       "      <td>49.139344</td>\n",
       "      <td>128.473383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14183.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14183.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lcom5</td>\n",
       "      <td>1.955935</td>\n",
       "      <td>3.600018</td>\n",
       "      <td>2.108382</td>\n",
       "      <td>3.702693</td>\n",
       "      <td>1.286885</td>\n",
       "      <td>3.825706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cbo</td>\n",
       "      <td>13.116437</td>\n",
       "      <td>12.637103</td>\n",
       "      <td>12.725040</td>\n",
       "      <td>12.204267</td>\n",
       "      <td>8.852459</td>\n",
       "      <td>9.922570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wmc</td>\n",
       "      <td>53.754440</td>\n",
       "      <td>88.424772</td>\n",
       "      <td>51.596369</td>\n",
       "      <td>83.009605</td>\n",
       "      <td>23.622951</td>\n",
       "      <td>24.381380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rfc</td>\n",
       "      <td>65.407665</td>\n",
       "      <td>97.388361</td>\n",
       "      <td>65.616658</td>\n",
       "      <td>98.512963</td>\n",
       "      <td>30.516393</td>\n",
       "      <td>35.168833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mpc</td>\n",
       "      <td>45.932434</td>\n",
       "      <td>76.630865</td>\n",
       "      <td>46.911372</td>\n",
       "      <td>79.189272</td>\n",
       "      <td>22.245902</td>\n",
       "      <td>30.656538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>halsteadVocabulary</td>\n",
       "      <td>1061.086660</td>\n",
       "      <td>1623.821864</td>\n",
       "      <td>1053.046983</td>\n",
       "      <td>1690.970897</td>\n",
       "      <td>507.360656</td>\n",
       "      <td>583.089195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13477.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13477.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>halsteadLength</td>\n",
       "      <td>203.651756</td>\n",
       "      <td>227.499170</td>\n",
       "      <td>201.009076</td>\n",
       "      <td>239.471606</td>\n",
       "      <td>131.254098</td>\n",
       "      <td>127.378175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>504.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>halsteadVolume</td>\n",
       "      <td>1491.028555</td>\n",
       "      <td>2038.223823</td>\n",
       "      <td>1475.977954</td>\n",
       "      <td>2168.737276</td>\n",
       "      <td>864.445665</td>\n",
       "      <td>979.826272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19626.038963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19626.038963</td>\n",
       "      <td>62.709884</td>\n",
       "      <td>3868.475185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>classDataShouldBePrivate</td>\n",
       "      <td>0.672586</td>\n",
       "      <td>4.243855</td>\n",
       "      <td>0.634810</td>\n",
       "      <td>4.349711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>complexClass</td>\n",
       "      <td>18.314995</td>\n",
       "      <td>87.847708</td>\n",
       "      <td>16.475174</td>\n",
       "      <td>81.974072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>spaghettiCode</td>\n",
       "      <td>10.868874</td>\n",
       "      <td>92.140900</td>\n",
       "      <td>13.341164</td>\n",
       "      <td>107.694266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1180.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>functionalDecomposition</td>\n",
       "      <td>0.140873</td>\n",
       "      <td>0.479602</td>\n",
       "      <td>0.141484</td>\n",
       "      <td>0.483436</td>\n",
       "      <td>0.319672</td>\n",
       "      <td>0.730294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>godClass</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      column    Mean_S_TR     STD_S_TR     Mean_S_T  \\\n",
       "0                       tloc    11.101082    11.593512    11.078484   \n",
       "1                    tmcCabe     2.201095     0.971767     2.219434   \n",
       "2           assertionDensity     0.150169     0.218041     0.149381   \n",
       "3          assertionRoulette     1.553478     2.948291     1.641751   \n",
       "4               mysteryGuest     0.257044     1.383771     0.201281   \n",
       "5                  eagerTest     1.675124     2.664727     1.725040   \n",
       "6          sensitiveEquality     0.024970     0.191405     0.038975   \n",
       "7           resourceOptimism     0.020697     0.182644     0.018687   \n",
       "8       conditionalTestLogic     0.745493     1.648657     0.810464   \n",
       "9              fireAndForget     0.011350     0.128703     0.014415   \n",
       "10                testRunWar     0.000000     0.000000     0.000000   \n",
       "11                       loc   311.879023   488.100148   303.024026   \n",
       "12                     lcom2   480.199626  1946.188934   420.001068   \n",
       "13                     lcom5     1.955935     3.600018     2.108382   \n",
       "14                       cbo    13.116437    12.637103    12.725040   \n",
       "15                       wmc    53.754440    88.424772    51.596369   \n",
       "16                       rfc    65.407665    97.388361    65.616658   \n",
       "17                       mpc    45.932434    76.630865    46.911372   \n",
       "18        halsteadVocabulary  1061.086660  1623.821864  1053.046983   \n",
       "19            halsteadLength   203.651756   227.499170   201.009076   \n",
       "20            halsteadVolume  1491.028555  2038.223823  1475.977954   \n",
       "21  classDataShouldBePrivate     0.672586     4.243855     0.634810   \n",
       "22              complexClass    18.314995    87.847708    16.475174   \n",
       "23             spaghettiCode    10.868874    92.140900    13.341164   \n",
       "24   functionalDecomposition     0.140873     0.479602     0.141484   \n",
       "25                  godClass     0.000000     0.000000     0.000000   \n",
       "\n",
       "        STD_S_T      Mean_T       STD_T  Min_S_TR      Max_S_TR  Min_S_T  \\\n",
       "0     11.336196   13.672131   11.994105       2.0    194.000000      2.0   \n",
       "1      0.958769    1.860656    1.208206       1.0      8.000000      1.0   \n",
       "2      0.218713    0.126621    0.152860       0.0      1.772727      0.0   \n",
       "3      3.410534    2.106557    2.744814       0.0     52.000000      0.0   \n",
       "4      1.267003    0.000000    0.000000       0.0     22.000000      0.0   \n",
       "5      2.727804    1.590164    2.023638       0.0     42.000000      0.0   \n",
       "6      0.311937    0.008197    0.090536       0.0      6.000000      0.0   \n",
       "7      0.199286    0.000000    0.000000       0.0      2.000000      0.0   \n",
       "8      2.163918    0.827869    1.497616       0.0     33.000000      0.0   \n",
       "9      0.173899    0.000000    0.000000       0.0      5.000000      0.0   \n",
       "10     0.000000    0.000000    0.000000       0.0      0.000000      0.0   \n",
       "11   467.235057  121.450820  126.701452      17.0   3259.000000     17.0   \n",
       "12  1764.024814   49.139344  128.473383       0.0  14183.000000      0.0   \n",
       "13     3.702693    1.286885    3.825706       0.0     32.000000      0.0   \n",
       "14    12.204267    8.852459    9.922570       0.0     64.000000      0.0   \n",
       "15    83.009605   23.622951   24.381380       0.0    583.000000      0.0   \n",
       "16    98.512963   30.516393   35.168833       0.0    614.000000      0.0   \n",
       "17    79.189272   22.245902   30.656538       0.0    514.000000      0.0   \n",
       "18  1690.970897  507.360656  583.089195       1.0  13477.000000      1.0   \n",
       "19   239.471606  131.254098  127.378175       1.0   2064.000000      1.0   \n",
       "20  2168.737276  864.445665  979.826272       0.0  19626.038963      0.0   \n",
       "21     4.349711    0.000000    0.000000       0.0     30.000000      0.0   \n",
       "22    81.974072    0.000000    0.000000       0.0    583.000000      0.0   \n",
       "23   107.694266    0.000000    0.000000       0.0   1180.000000      0.0   \n",
       "24     0.483436    0.319672    0.730294       0.0      2.000000      0.0   \n",
       "25     0.000000    0.000000    0.000000       0.0      0.000000      0.0   \n",
       "\n",
       "         Max_S_T      Min_T        Max_T  \n",
       "0     136.000000   2.000000    57.000000  \n",
       "1       9.000000   1.000000     5.000000  \n",
       "2       1.788732   0.000000     0.666667  \n",
       "3      44.000000   0.000000    12.000000  \n",
       "4      21.000000   0.000000     0.000000  \n",
       "5      42.000000   0.000000    10.000000  \n",
       "6       6.000000   0.000000     1.000000  \n",
       "7       5.000000   0.000000     0.000000  \n",
       "8      42.000000   0.000000     8.000000  \n",
       "9       5.000000   0.000000     0.000000  \n",
       "10      0.000000   0.000000     0.000000  \n",
       "11   3259.000000  16.000000   516.000000  \n",
       "12  14183.000000   0.000000   768.000000  \n",
       "13     32.000000   0.000000    38.000000  \n",
       "14     64.000000   1.000000    62.000000  \n",
       "15    583.000000   1.000000   110.000000  \n",
       "16    614.000000   1.000000   145.000000  \n",
       "17    514.000000   0.000000   125.000000  \n",
       "18  13477.000000  23.000000  2155.000000  \n",
       "19   2064.000000  20.000000   504.000000  \n",
       "20  19626.038963  62.709884  3868.475185  \n",
       "21     80.000000   0.000000     0.000000  \n",
       "22    583.000000   0.000000     0.000000  \n",
       "23   1180.000000   0.000000     0.000000  \n",
       "24      2.000000   0.000000     2.000000  \n",
       "25      0.000000   0.000000     0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Feature Importances\n",
      "wmc : 0.09173186272163572\n",
      "halsteadVolume : 0.0852485326807959\n",
      "loc : 0.08044733332867063\n",
      "halsteadLength : 0.07232762330561397\n",
      "lcom2 : 0.07176253214485713\n",
      "halsteadVocabulary : 0.07109473097818099\n",
      "tloc : 0.06988546959502216\n",
      "cbo : 0.06816064759657839\n",
      "mpc : 0.06285890627807328\n",
      "rfc : 0.0544954015921205\n",
      "mysteryGuest : 0.047493043873119006\n",
      "tmcCabe : 0.043477320741322587\n",
      "assertionDensity : 0.04067478423693871\n",
      "assertionRoulette : 0.03230283493286688\n",
      "eagerTest : 0.031613576734116515\n",
      "lcom5 : 0.030134236222951364\n",
      "conditionalTestLogic : 0.025409294026895006\n",
      "fireAndForget : 0.006269245056863044\n",
      "functionalDecomposition : 0.004486410576393735\n",
      "complexClass : 0.0027527587571000004\n",
      "spaghettiCode : 0.0025704056795460644\n",
      "resourceOptimism : 0.0021300955018590784\n",
      "classDataShouldBePrivate : 0.0014117270731340663\n",
      "sensitiveEquality : 0.0012612263653452146\n",
      "testRunWar : 0.0\n",
      "godClass : 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(tmp['repository'])):\n",
    "    print(tmp['repository'][i])\n",
    "    print_distribution(tmp['X_source_train'][i], \n",
    "                       tmp['X_source_test'][i], \n",
    "                       tmp['X_target'][i], \n",
    "                       columns)\n",
    "    print('\\n Feature Importances')\n",
    "    print_featureImportances(tmp['clf'][i],columns)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CrossProject - BurakFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def euclidean(point, data):\n",
    "    # Euclidean distance between points a & data\n",
    "    return np.sqrt(np.sum((point - data)**2, axis=1))\n",
    "\n",
    "def classic_burakFilter(Xsource,ysource,Xtarget,ytarget,k):\n",
    "    \n",
    "    knn=KNeighborsClassifier()\n",
    "    knn.fit(Xsource,ysource)\n",
    "\n",
    "    Xdata=[]\n",
    "    ydata=[]\n",
    "    \n",
    "    TF_countTF=0\n",
    "    TF_countTNF=0\n",
    "    TNF_countTF=0\n",
    "    TNF_countTNF=0\n",
    "\n",
    "    for instance,l in zip(Xtarget,ytarget):\n",
    "        neighbors_index=knn.kneighbors(instance.reshape(1,-1), k, return_distance=False)\n",
    "        for neighbor_index in neighbors_index[0]:\n",
    "            \n",
    "            if l==0:\n",
    "                if ysource[neighbor_index]==0: TNF_countTNF=TNF_countTNF+1\n",
    "                else: TNF_countTF=TNF_countTF+1\n",
    "            else:\n",
    "                if ysource[neighbor_index]==0: TF_countTNF=TF_countTNF+1\n",
    "                else: TF_countTF=TF_countTF+1\n",
    "                    \n",
    "            if not list(Xsource[neighbor_index]) in Xdata:\n",
    "                Xdata.append(list(Xsource[neighbor_index]))\n",
    "                ydata.append(ysource[neighbor_index])\n",
    "                \n",
    "    \n",
    "    print(\"Per le istanze non flaky sono stati selezionati: {} TF e {} TNF\".format(TNF_countTF,TNF_countTNF))\n",
    "    print(\"Per le istanze flaky sono stati selezionati: {} TF e {} TNF\\n\".format(TF_countTF,TF_countTNF))\n",
    "    print(\"Con il filtro di burak il source set è stato ridotto passado da {} TF, {} TNF a {} TF, {} TNF\\n\".format(\n",
    "        np.count_nonzero(ysource),\n",
    "        ysource.size - np.count_nonzero(ysource),\n",
    "        np.count_nonzero(np.asarray(ydata)),\n",
    "        np.asarray(ydata).size - np.count_nonzero(np.asarray(ydata))\n",
    "    ))\n",
    "\n",
    "    return np.asanyarray(Xdata), np.asarray(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository: hbase_e593f0efbf1144bcb5909d2630321e631a2e66bb\n",
      "Per le istanze non flaky sono stati selezionati: 609 TF e 1851 TNF\n",
      "Per le istanze flaky sono stati selezionati: 85 TF e 1055 TNF\n",
      "\n",
      "Con il filtro di burak il source set è stato ridotto passado da 445 TF, 8679 TNF a 48 TF, 555 TNF\n",
      "\n",
      "    |--- Train_ACC 1.0\n",
      "    |--- Train_PR 1.0\n",
      "    |--- Train_REC 1.0\n",
      "    |--- Train_F1 1.0\n",
      "     Performance Test\n",
      "    |--- TEST_ACC 0.9752066115702479\n",
      "    |--- TEST_PR 1.0\n",
      "    |--- TEST_REC 0.7\n",
      "    |--- TEST_F1 0.8235294117647058\n",
      "    |--- TEST_AUC 0.85\n",
      "     Performance Target\n",
      "    |--- TEST_ACC 0.5861111111111111\n",
      "    |--- TEST_PR 0.14285714285714285\n",
      "    |--- TEST_REC 0.06140350877192982\n",
      "    |--- TEST_F1 0.08588957055214724\n",
      "    |--- TEST_AUC 0.4453359007274283\n",
      "\n",
      "Repository: activiti_b11f757a\n",
      "Per le istanze non flaky sono stati selezionati: 254 TF e 8326 TNF\n",
      "Per le istanze flaky sono stati selezionati: 0 TF e 160 TNF\n",
      "\n",
      "Con il filtro di burak il source set è stato ridotto passado da 543 TF, 8067 TNF a 30 TF, 561 TNF\n",
      "\n",
      "    |--- Train_ACC 1.0\n",
      "    |--- Train_PR 1.0\n",
      "    |--- Train_REC 1.0\n",
      "    |--- Train_F1 1.0\n",
      "     Performance Test\n",
      "    |--- TEST_ACC 0.9915966386554622\n",
      "    |--- TEST_PR 1.0\n",
      "    |--- TEST_REC 0.8333333333333334\n",
      "    |--- TEST_F1 0.9090909090909091\n",
      "    |--- TEST_AUC 0.9166666666666667\n",
      "     Performance Target\n",
      "    |--- TEST_ACC 0.9816933638443935\n",
      "    |--- TEST_PR 0.0\n",
      "    |--- TEST_REC 0.0\n",
      "    |--- TEST_F1 0.0\n",
      "    |--- TEST_AUC 0.5\n",
      "\n",
      "Repository: hector_29e88d0b988d9e5c8dc3b529414a270805ce0d7c\n",
      "Per le istanze non flaky sono stati selezionati: 68 TF e 822 TNF\n",
      "Per le istanze flaky sono stati selezionati: 4 TF e 326 TNF\n",
      "\n",
      "Con il filtro di burak il source set è stato ridotto passado da 526 TF, 8836 TNF a 18 TF, 301 TNF\n",
      "\n",
      "    |--- Train_ACC 1.0\n",
      "    |--- Train_PR 1.0\n",
      "    |--- Train_REC 1.0\n",
      "    |--- Train_F1 1.0\n",
      "     Performance Test\n",
      "    |--- TEST_ACC 0.96875\n",
      "    |--- TEST_PR 1.0\n",
      "    |--- TEST_REC 0.5\n",
      "    |--- TEST_F1 0.6666666666666666\n",
      "    |--- TEST_AUC 0.75\n",
      "     Performance Target\n",
      "    |--- TEST_ACC 0.7295081967213115\n",
      "    |--- TEST_PR 0.0\n",
      "    |--- TEST_REC 0.0\n",
      "    |--- TEST_F1 0.0\n",
      "    |--- TEST_AUC 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "list_target=[repository1, repository2, repository3]\n",
    "\n",
    "tmp={\n",
    "    'repository': [],\n",
    "    'X_source_train': [],\n",
    "    'y_source_train': [],\n",
    "    'X_source_test': [],\n",
    "    'y_source_test': [],\n",
    "    'X_target': [],\n",
    "    'y_target': [],\n",
    "    'clf': [],\n",
    "}\n",
    "\n",
    "for target in list_target:\n",
    "    print('Repository: {}'.format(target))\n",
    "    \n",
    "    tmp['repository'].append(target)\n",
    "    target_set=dataset.loc[dataset['nameProject']==target]\n",
    "    source_set=dataset.loc[dataset['nameProject']!=target]\n",
    "\n",
    "    X_target=target_set.drop(['nameProject','testCase','isFlaky'], axis=1)\n",
    "    y_target=target_set['isFlaky']\n",
    "    X_source=source_set.drop(['nameProject','testCase','isFlaky'], axis=1)\n",
    "    y_source=source_set['isFlaky']\n",
    "    columns=X_source.columns\n",
    "    \n",
    "    X_source,y_source=classic_burakFilter(X_source.to_numpy(),y_source.to_numpy(),X_target.to_numpy(),y_target.to_numpy(),10)\n",
    "    X_source_train, X_source_test, y_source_train, y_source_test= train_test_split(X_source, y_source,stratify=y_source, test_size=0.20,random_state=42)\n",
    "    \n",
    "    tmp['X_source_train'].append(pd.DataFrame(X_source_train,columns=columns))\n",
    "    tmp['y_source_train'].append(y_source_train)\n",
    "    tmp['X_source_test'].append(pd.DataFrame(X_source_test,columns=columns))\n",
    "    tmp['y_source_test'].append(y_source_test)\n",
    "    tmp['X_target'].append(pd.DataFrame(X_target,columns=columns))\n",
    "    tmp['y_target'].append(y_target)\n",
    "    \n",
    "    pipeline = Pipeline(steps = [('scaler',MinMaxScaler()),\n",
    "                                 (\"model\", RandomForestClassifier(class_weight='balanced', random_state=42))]).set_output(transform = \"pandas\")\n",
    "\n",
    "    pipeline.fit(X_source_train,y_source_train)\n",
    "    y_predict=pipeline.predict(X_source_train)\n",
    "    eval_and_log_metrics('Train',y_source_train,y_predict)\n",
    "    print('     Performance Test')\n",
    "    y_predict=pipeline.predict(X_source_test)\n",
    "    val_and_log_metrics(y_source_test,y_predict)\n",
    "    print('     Performance Target')\n",
    "    y_predict=pipeline.predict(X_target)\n",
    "    val_and_log_metrics(y_target,y_predict)\n",
    "    print('')\n",
    "    \n",
    "    tmp['clf'].append(pipeline.get_params('steps')['model'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hbase_e593f0efbf1144bcb5909d2630321e631a2e66bb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>Mean_S_TR</th>\n",
       "      <th>STD_S_TR</th>\n",
       "      <th>Mean_S_T</th>\n",
       "      <th>STD_S_T</th>\n",
       "      <th>Mean_T</th>\n",
       "      <th>STD_T</th>\n",
       "      <th>Min_S_TR</th>\n",
       "      <th>Max_S_TR</th>\n",
       "      <th>Min_S_T</th>\n",
       "      <th>Max_S_T</th>\n",
       "      <th>Min_T</th>\n",
       "      <th>Max_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tloc</td>\n",
       "      <td>11.960581</td>\n",
       "      <td>12.074634</td>\n",
       "      <td>10.628099</td>\n",
       "      <td>7.417471</td>\n",
       "      <td>20.091667</td>\n",
       "      <td>17.753024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tmcCabe</td>\n",
       "      <td>2.161826</td>\n",
       "      <td>0.890441</td>\n",
       "      <td>2.132231</td>\n",
       "      <td>0.884516</td>\n",
       "      <td>2.758333</td>\n",
       "      <td>1.073841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assertionDensity</td>\n",
       "      <td>0.207379</td>\n",
       "      <td>0.271881</td>\n",
       "      <td>0.192790</td>\n",
       "      <td>0.290769</td>\n",
       "      <td>0.097307</td>\n",
       "      <td>0.145783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.590909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.772727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assertionRoulette</td>\n",
       "      <td>1.931535</td>\n",
       "      <td>3.862163</td>\n",
       "      <td>1.537190</td>\n",
       "      <td>1.875461</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>4.090511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mysteryGuest</td>\n",
       "      <td>0.587137</td>\n",
       "      <td>2.120507</td>\n",
       "      <td>0.396694</td>\n",
       "      <td>1.599371</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>1.146577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eagerTest</td>\n",
       "      <td>2.020747</td>\n",
       "      <td>3.541202</td>\n",
       "      <td>2.157025</td>\n",
       "      <td>5.600608</td>\n",
       "      <td>2.502778</td>\n",
       "      <td>3.191212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sensitiveEquality</td>\n",
       "      <td>0.026971</td>\n",
       "      <td>0.297772</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.267629</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.216164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resourceOptimism</td>\n",
       "      <td>0.029046</td>\n",
       "      <td>0.211879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conditionalTestLogic</td>\n",
       "      <td>0.560166</td>\n",
       "      <td>1.351641</td>\n",
       "      <td>0.429752</td>\n",
       "      <td>1.223563</td>\n",
       "      <td>2.119444</td>\n",
       "      <td>3.594279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fireAndForget</td>\n",
       "      <td>0.016598</td>\n",
       "      <td>0.157073</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>testRunWar</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>loc</td>\n",
       "      <td>358.056017</td>\n",
       "      <td>385.011309</td>\n",
       "      <td>369.677686</td>\n",
       "      <td>356.634365</td>\n",
       "      <td>786.841667</td>\n",
       "      <td>853.141205</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1780.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1780.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2770.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lcom2</td>\n",
       "      <td>158.576763</td>\n",
       "      <td>381.632394</td>\n",
       "      <td>190.421488</td>\n",
       "      <td>490.495358</td>\n",
       "      <td>642.955556</td>\n",
       "      <td>1150.782085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3790.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3403.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3514.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lcom5</td>\n",
       "      <td>1.742739</td>\n",
       "      <td>1.900924</td>\n",
       "      <td>1.479339</td>\n",
       "      <td>1.466851</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>2.064152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cbo</td>\n",
       "      <td>15.950207</td>\n",
       "      <td>11.602638</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.695014</td>\n",
       "      <td>20.677778</td>\n",
       "      <td>15.982635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wmc</td>\n",
       "      <td>54.759336</td>\n",
       "      <td>64.844867</td>\n",
       "      <td>56.082645</td>\n",
       "      <td>62.532203</td>\n",
       "      <td>101.400000</td>\n",
       "      <td>114.207069</td>\n",
       "      <td>2.0</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rfc</td>\n",
       "      <td>82.935685</td>\n",
       "      <td>107.691009</td>\n",
       "      <td>84.446281</td>\n",
       "      <td>95.098979</td>\n",
       "      <td>147.138889</td>\n",
       "      <td>185.867544</td>\n",
       "      <td>1.0</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mpc</td>\n",
       "      <td>66.404564</td>\n",
       "      <td>92.668996</td>\n",
       "      <td>67.363636</td>\n",
       "      <td>81.310311</td>\n",
       "      <td>116.169444</td>\n",
       "      <td>156.635861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>halsteadVocabulary</td>\n",
       "      <td>1405.612033</td>\n",
       "      <td>2407.562755</td>\n",
       "      <td>1338.008264</td>\n",
       "      <td>2099.591081</td>\n",
       "      <td>3086.772222</td>\n",
       "      <td>4491.888719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12109.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12109.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>halsteadLength</td>\n",
       "      <td>246.302905</td>\n",
       "      <td>278.077988</td>\n",
       "      <td>248.446281</td>\n",
       "      <td>269.839642</td>\n",
       "      <td>526.622222</td>\n",
       "      <td>678.874475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1293.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1265.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>halsteadVolume</td>\n",
       "      <td>1886.133236</td>\n",
       "      <td>2547.091952</td>\n",
       "      <td>1896.916121</td>\n",
       "      <td>2397.305983</td>\n",
       "      <td>4596.453581</td>\n",
       "      <td>6483.547706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11893.155885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11893.155885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19626.038963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>classDataShouldBePrivate</td>\n",
       "      <td>1.045643</td>\n",
       "      <td>4.572583</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>4.197106</td>\n",
       "      <td>0.547222</td>\n",
       "      <td>2.560247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>complexClass</td>\n",
       "      <td>11.153527</td>\n",
       "      <td>53.807206</td>\n",
       "      <td>10.429752</td>\n",
       "      <td>50.857452</td>\n",
       "      <td>52.438889</td>\n",
       "      <td>121.967056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>spaghettiCode</td>\n",
       "      <td>34.790456</td>\n",
       "      <td>151.662662</td>\n",
       "      <td>22.628099</td>\n",
       "      <td>117.796019</td>\n",
       "      <td>175.594444</td>\n",
       "      <td>388.854022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>functionalDecomposition</td>\n",
       "      <td>0.089212</td>\n",
       "      <td>0.395305</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.359062</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.166062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>godClass</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      column    Mean_S_TR     STD_S_TR     Mean_S_T  \\\n",
       "0                       tloc    11.960581    12.074634    10.628099   \n",
       "1                    tmcCabe     2.161826     0.890441     2.132231   \n",
       "2           assertionDensity     0.207379     0.271881     0.192790   \n",
       "3          assertionRoulette     1.931535     3.862163     1.537190   \n",
       "4               mysteryGuest     0.587137     2.120507     0.396694   \n",
       "5                  eagerTest     2.020747     3.541202     2.157025   \n",
       "6          sensitiveEquality     0.026971     0.297772     0.057851   \n",
       "7           resourceOptimism     0.029046     0.211879     0.000000   \n",
       "8       conditionalTestLogic     0.560166     1.351641     0.429752   \n",
       "9              fireAndForget     0.016598     0.157073     0.024793   \n",
       "10                testRunWar     0.000000     0.000000     0.000000   \n",
       "11                       loc   358.056017   385.011309   369.677686   \n",
       "12                     lcom2   158.576763   381.632394   190.421488   \n",
       "13                     lcom5     1.742739     1.900924     1.479339   \n",
       "14                       cbo    15.950207    11.602638    18.000000   \n",
       "15                       wmc    54.759336    64.844867    56.082645   \n",
       "16                       rfc    82.935685   107.691009    84.446281   \n",
       "17                       mpc    66.404564    92.668996    67.363636   \n",
       "18        halsteadVocabulary  1405.612033  2407.562755  1338.008264   \n",
       "19            halsteadLength   246.302905   278.077988   248.446281   \n",
       "20            halsteadVolume  1886.133236  2547.091952  1896.916121   \n",
       "21  classDataShouldBePrivate     1.045643     4.572583     0.867769   \n",
       "22              complexClass    11.153527    53.807206    10.429752   \n",
       "23             spaghettiCode    34.790456   151.662662    22.628099   \n",
       "24   functionalDecomposition     0.089212     0.395305     0.066116   \n",
       "25                  godClass     0.000000     0.000000     0.000000   \n",
       "\n",
       "        STD_S_T       Mean_T        STD_T  Min_S_TR      Max_S_TR  Min_S_T  \\\n",
       "0      7.417471    20.091667    17.753024       2.0    131.000000      3.0   \n",
       "1      0.884516     2.758333     1.073841       1.0      6.000000      1.0   \n",
       "2      0.290769     0.097307     0.145783       0.0      1.590909      0.0   \n",
       "3      1.875461     2.444444     4.090511       0.0     44.000000      0.0   \n",
       "4      1.599371     0.211111     1.146577       0.0     17.000000      0.0   \n",
       "5      5.600608     2.502778     3.191212       0.0     42.000000      0.0   \n",
       "6      0.267629     0.025000     0.216164       0.0      6.000000      0.0   \n",
       "7      0.000000     0.000000     0.000000       0.0      2.000000      0.0   \n",
       "8      1.223563     2.119444     3.594279       0.0     11.000000      0.0   \n",
       "9      0.272727     0.027778     0.180700       0.0      2.000000      0.0   \n",
       "10     0.000000     0.000000     0.000000       0.0      0.000000      0.0   \n",
       "11   356.634365   786.841667   853.141205      34.0   1780.000000     34.0   \n",
       "12   490.495358   642.955556  1150.782085       0.0   3790.000000      0.0   \n",
       "13     1.466851     2.033333     2.064152       0.0      9.000000      0.0   \n",
       "14    10.695014    20.677778    15.982635       1.0     51.000000      1.0   \n",
       "15    62.532203   101.400000   114.207069       2.0    286.000000      4.0   \n",
       "16    95.098979   147.138889   185.867544       1.0    520.000000      2.0   \n",
       "17    81.310311   116.169444   156.635861       0.0    450.000000      0.0   \n",
       "18  2099.591081  3086.772222  4491.888719       1.0  12109.000000      1.0   \n",
       "19   269.839642   526.622222   678.874475       1.0   1293.000000      1.0   \n",
       "20  2397.305983  4596.453581  6483.547706       0.0  11893.155885      0.0   \n",
       "21     4.197106     0.547222     2.560247       0.0     21.000000      0.0   \n",
       "22    50.857452    52.438889   121.967056       0.0    286.000000      0.0   \n",
       "23   117.796019   175.594444   388.854022       0.0    855.000000      0.0   \n",
       "24     0.359062     0.016667     0.166062       0.0      2.000000      0.0   \n",
       "25     0.000000     0.000000     0.000000       0.0      0.000000      0.0   \n",
       "\n",
       "         Max_S_T  Min_T         Max_T  \n",
       "0      43.000000    2.0    109.000000  \n",
       "1       5.000000    1.0      7.000000  \n",
       "2       1.772727    0.0      0.842105  \n",
       "3      12.000000    0.0     40.000000  \n",
       "4      10.000000    0.0     13.000000  \n",
       "5      42.000000    0.0     14.000000  \n",
       "6       2.000000    0.0      2.000000  \n",
       "7       0.000000    0.0      0.000000  \n",
       "8       8.000000    0.0     23.000000  \n",
       "9       3.000000    0.0      2.000000  \n",
       "10      0.000000    0.0      0.000000  \n",
       "11   1780.000000   47.0   2770.000000  \n",
       "12   3403.000000    0.0   3514.000000  \n",
       "13      8.000000    0.0      8.000000  \n",
       "14     51.000000    0.0     64.000000  \n",
       "15    286.000000    2.0    360.000000  \n",
       "16    520.000000    1.0    614.000000  \n",
       "17    450.000000    0.0    514.000000  \n",
       "18  12109.000000    1.0  13477.000000  \n",
       "19   1265.000000    1.0   2064.000000  \n",
       "20  11893.155885    0.0  19626.038963  \n",
       "21     21.000000    0.0     14.000000  \n",
       "22    286.000000    0.0    360.000000  \n",
       "23    855.000000    0.0   1180.000000  \n",
       "24      2.000000    0.0      2.000000  \n",
       "25      0.000000    0.0      0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Feature Importances\n",
      "mysteryGuest : 0.1305759456579947\n",
      "halsteadVocabulary : 0.11473569187060258\n",
      "mpc : 0.0904383616493648\n",
      "halsteadVolume : 0.08255491054624384\n",
      "wmc : 0.08207954355762463\n",
      "loc : 0.06920614862940681\n",
      "rfc : 0.06417688183569857\n",
      "halsteadLength : 0.05951110269656888\n",
      "cbo : 0.04979777725126897\n",
      "lcom2 : 0.04477036937593702\n",
      "assertionRoulette : 0.04417399584857502\n",
      "assertionDensity : 0.031712254453582264\n",
      "tloc : 0.02692754921580562\n",
      "spaghettiCode : 0.0247638269325831\n",
      "lcom5 : 0.02052743375879204\n",
      "complexClass : 0.019225218530150405\n",
      "tmcCabe : 0.01469933364148031\n",
      "eagerTest : 0.014547638847071102\n",
      "conditionalTestLogic : 0.009063710484234254\n",
      "sensitiveEquality : 0.002091959875575977\n",
      "classDataShouldBePrivate : 0.0014274400236054337\n",
      "fireAndForget : 0.0013957477787583702\n",
      "resourceOptimism : 0.001246912545780828\n",
      "functionalDecomposition : 0.00035024499329455505\n",
      "testRunWar : 0.0\n",
      "godClass : 0.0\n",
      "\n",
      "\n",
      "activiti_b11f757a\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>Mean_S_TR</th>\n",
       "      <th>STD_S_TR</th>\n",
       "      <th>Mean_S_T</th>\n",
       "      <th>STD_S_T</th>\n",
       "      <th>Mean_T</th>\n",
       "      <th>STD_T</th>\n",
       "      <th>Min_S_TR</th>\n",
       "      <th>Max_S_TR</th>\n",
       "      <th>Min_S_T</th>\n",
       "      <th>Max_S_T</th>\n",
       "      <th>Min_T</th>\n",
       "      <th>Max_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tloc</td>\n",
       "      <td>11.453390</td>\n",
       "      <td>11.969439</td>\n",
       "      <td>13.689076</td>\n",
       "      <td>12.953468</td>\n",
       "      <td>15.183066</td>\n",
       "      <td>14.369319</td>\n",
       "      <td>2.0</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tmcCabe</td>\n",
       "      <td>2.275424</td>\n",
       "      <td>1.028464</td>\n",
       "      <td>2.294118</td>\n",
       "      <td>1.188597</td>\n",
       "      <td>1.767735</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assertionDensity</td>\n",
       "      <td>0.143406</td>\n",
       "      <td>0.227946</td>\n",
       "      <td>0.180313</td>\n",
       "      <td>0.285646</td>\n",
       "      <td>0.196495</td>\n",
       "      <td>0.188024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assertionRoulette</td>\n",
       "      <td>1.387712</td>\n",
       "      <td>2.465924</td>\n",
       "      <td>1.781513</td>\n",
       "      <td>2.487800</td>\n",
       "      <td>3.024027</td>\n",
       "      <td>4.951598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mysteryGuest</td>\n",
       "      <td>0.201271</td>\n",
       "      <td>0.957570</td>\n",
       "      <td>0.260504</td>\n",
       "      <td>1.037126</td>\n",
       "      <td>0.060641</td>\n",
       "      <td>0.580107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eagerTest</td>\n",
       "      <td>1.701271</td>\n",
       "      <td>3.315306</td>\n",
       "      <td>2.420168</td>\n",
       "      <td>6.617255</td>\n",
       "      <td>1.844394</td>\n",
       "      <td>2.723374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sensitiveEquality</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.315151</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.091670</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resourceOptimism</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.316944</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.272930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conditionalTestLogic</td>\n",
       "      <td>0.800847</td>\n",
       "      <td>1.623396</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>1.484286</td>\n",
       "      <td>0.612128</td>\n",
       "      <td>1.644008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fireAndForget</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.129218</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.091670</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>testRunWar</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>loc</td>\n",
       "      <td>163.766949</td>\n",
       "      <td>218.072702</td>\n",
       "      <td>170.941176</td>\n",
       "      <td>233.952273</td>\n",
       "      <td>279.439359</td>\n",
       "      <td>341.788392</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1321.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1321.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lcom2</td>\n",
       "      <td>319.830508</td>\n",
       "      <td>1007.059412</td>\n",
       "      <td>290.100840</td>\n",
       "      <td>822.296870</td>\n",
       "      <td>972.283753</td>\n",
       "      <td>1564.753136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6670.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6670.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lcom5</td>\n",
       "      <td>1.281780</td>\n",
       "      <td>2.789700</td>\n",
       "      <td>1.798319</td>\n",
       "      <td>4.043366</td>\n",
       "      <td>0.172769</td>\n",
       "      <td>0.672579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cbo</td>\n",
       "      <td>7.858051</td>\n",
       "      <td>8.193194</td>\n",
       "      <td>7.840336</td>\n",
       "      <td>7.208732</td>\n",
       "      <td>7.116705</td>\n",
       "      <td>8.098484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wmc</td>\n",
       "      <td>33.633475</td>\n",
       "      <td>52.850380</td>\n",
       "      <td>34.689076</td>\n",
       "      <td>54.344592</td>\n",
       "      <td>66.284897</td>\n",
       "      <td>89.385314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rfc</td>\n",
       "      <td>33.572034</td>\n",
       "      <td>46.814300</td>\n",
       "      <td>34.386555</td>\n",
       "      <td>48.906883</td>\n",
       "      <td>33.762014</td>\n",
       "      <td>33.019979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mpc</td>\n",
       "      <td>18.375000</td>\n",
       "      <td>29.058716</td>\n",
       "      <td>18.873950</td>\n",
       "      <td>27.403314</td>\n",
       "      <td>3.042334</td>\n",
       "      <td>11.588270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>halsteadVocabulary</td>\n",
       "      <td>627.792373</td>\n",
       "      <td>1092.081671</td>\n",
       "      <td>657.218487</td>\n",
       "      <td>1050.033923</td>\n",
       "      <td>1474.608696</td>\n",
       "      <td>2034.419382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6577.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5261.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>halsteadLength</td>\n",
       "      <td>138.171610</td>\n",
       "      <td>163.664544</td>\n",
       "      <td>144.722689</td>\n",
       "      <td>170.021530</td>\n",
       "      <td>225.008009</td>\n",
       "      <td>207.235341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>971.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>940.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>684.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>halsteadVolume</td>\n",
       "      <td>940.129152</td>\n",
       "      <td>1417.128531</td>\n",
       "      <td>996.450628</td>\n",
       "      <td>1446.244605</td>\n",
       "      <td>1708.513432</td>\n",
       "      <td>1849.725463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8536.385307</td>\n",
       "      <td>13.621371</td>\n",
       "      <td>8053.991818</td>\n",
       "      <td>13.621371</td>\n",
       "      <td>6053.950070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>classDataShouldBePrivate</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>1.421396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075515</td>\n",
       "      <td>0.908794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>complexClass</td>\n",
       "      <td>12.207627</td>\n",
       "      <td>50.621103</td>\n",
       "      <td>12.890756</td>\n",
       "      <td>51.789468</td>\n",
       "      <td>42.340961</td>\n",
       "      <td>95.927715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>spaghettiCode</td>\n",
       "      <td>0.224576</td>\n",
       "      <td>3.446342</td>\n",
       "      <td>0.890756</td>\n",
       "      <td>6.841783</td>\n",
       "      <td>4.393593</td>\n",
       "      <td>16.192167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>functionalDecomposition</td>\n",
       "      <td>0.256356</td>\n",
       "      <td>0.597200</td>\n",
       "      <td>0.302521</td>\n",
       "      <td>0.645120</td>\n",
       "      <td>0.161327</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>godClass</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      column   Mean_S_TR     STD_S_TR    Mean_S_T  \\\n",
       "0                       tloc   11.453390    11.969439   13.689076   \n",
       "1                    tmcCabe    2.275424     1.028464    2.294118   \n",
       "2           assertionDensity    0.143406     0.227946    0.180313   \n",
       "3          assertionRoulette    1.387712     2.465924    1.781513   \n",
       "4               mysteryGuest    0.201271     0.957570    0.260504   \n",
       "5                  eagerTest    1.701271     3.315306    2.420168   \n",
       "6          sensitiveEquality    0.050847     0.315151    0.008403   \n",
       "7           resourceOptimism    0.038136     0.316944    0.042017   \n",
       "8       conditionalTestLogic    0.800847     1.623396    0.840336   \n",
       "9              fireAndForget    0.016949     0.129218    0.008403   \n",
       "10                testRunWar    0.000000     0.000000    0.000000   \n",
       "11                       loc  163.766949   218.072702  170.941176   \n",
       "12                     lcom2  319.830508  1007.059412  290.100840   \n",
       "13                     lcom5    1.281780     2.789700    1.798319   \n",
       "14                       cbo    7.858051     8.193194    7.840336   \n",
       "15                       wmc   33.633475    52.850380   34.689076   \n",
       "16                       rfc   33.572034    46.814300   34.386555   \n",
       "17                       mpc   18.375000    29.058716   18.873950   \n",
       "18        halsteadVocabulary  627.792373  1092.081671  657.218487   \n",
       "19            halsteadLength  138.171610   163.664544  144.722689   \n",
       "20            halsteadVolume  940.129152  1417.128531  996.450628   \n",
       "21  classDataShouldBePrivate    0.186441     1.421396    0.000000   \n",
       "22              complexClass   12.207627    50.621103   12.890756   \n",
       "23             spaghettiCode    0.224576     3.446342    0.890756   \n",
       "24   functionalDecomposition    0.256356     0.597200    0.302521   \n",
       "25                  godClass    0.000000     0.000000    0.000000   \n",
       "\n",
       "        STD_S_T       Mean_T        STD_T  Min_S_TR     Max_S_TR    Min_S_T  \\\n",
       "0     12.953468    15.183066    14.369319       2.0   119.000000   3.000000   \n",
       "1      1.188597     1.767735     0.762712       1.0     6.000000   1.000000   \n",
       "2      0.285646     0.196495     0.188024       0.0     1.375000   0.000000   \n",
       "3      2.487800     3.024027     4.951598       0.0    21.000000   0.000000   \n",
       "4      1.037126     0.060641     0.580107       0.0    10.000000   0.000000   \n",
       "5      6.617255     1.844394     2.723374       0.0    42.000000   0.000000   \n",
       "6      0.091670     0.001144     0.033826       0.0     3.000000   0.000000   \n",
       "7      0.272930     0.000000     0.000000       0.0     5.000000   0.000000   \n",
       "8      1.484286     0.612128     1.644008       0.0    14.000000   0.000000   \n",
       "9      0.091670     0.001144     0.033826       0.0     1.000000   0.000000   \n",
       "10     0.000000     0.000000     0.000000       0.0     0.000000   0.000000   \n",
       "11   233.952273   279.439359   341.788392      16.0  1321.000000  16.000000   \n",
       "12   822.296870   972.283753  1564.753136       0.0  6670.000000   0.000000   \n",
       "13     4.043366     0.172769     0.672579       0.0    23.000000   0.000000   \n",
       "14     7.208732     7.116705     8.098484       0.0    47.000000   0.000000   \n",
       "15    54.344592    66.284897    89.385314       0.0   226.000000   0.000000   \n",
       "16    48.906883    33.762014    33.019979       0.0   204.000000   0.000000   \n",
       "17    27.403314     3.042334    11.588270       0.0   155.000000   0.000000   \n",
       "18  1050.033923  1474.608696  2034.419382       1.0  6577.000000   7.000000   \n",
       "19   170.021530   225.008009   207.235341       1.0   971.000000   7.000000   \n",
       "20  1446.244605  1708.513432  1849.725463       0.0  8536.385307  13.621371   \n",
       "21     0.000000     0.075515     0.908794       0.0    11.000000   0.000000   \n",
       "22    51.789468    42.340961    95.927715       0.0   226.000000   0.000000   \n",
       "23     6.841783     4.393593    16.192167       0.0    53.000000   0.000000   \n",
       "24     0.645120     0.161327     0.515791       0.0     2.000000   0.000000   \n",
       "25     0.000000     0.000000     0.000000       0.0     0.000000   0.000000   \n",
       "\n",
       "        Max_S_T      Min_T        Max_T  \n",
       "0     71.000000   3.000000   136.000000  \n",
       "1      7.000000   1.000000     6.000000  \n",
       "2      1.500000   0.000000     0.863636  \n",
       "3     14.000000   0.000000    52.000000  \n",
       "4      6.000000   0.000000    11.000000  \n",
       "5     42.000000   0.000000    18.000000  \n",
       "6      1.000000   0.000000     1.000000  \n",
       "7      2.000000   0.000000     0.000000  \n",
       "8      8.000000   0.000000    21.000000  \n",
       "9      1.000000   0.000000     1.000000  \n",
       "10     0.000000   0.000000     0.000000  \n",
       "11  1321.000000  17.000000  1227.000000  \n",
       "12  6670.000000   0.000000  4950.000000  \n",
       "13    23.000000   0.000000     5.000000  \n",
       "14    33.000000   0.000000    39.000000  \n",
       "15   226.000000   0.000000   300.000000  \n",
       "16   204.000000   0.000000   143.000000  \n",
       "17   109.000000   0.000000   129.000000  \n",
       "18  5261.000000   7.000000  6980.000000  \n",
       "19   940.000000   7.000000   684.000000  \n",
       "20  8053.991818  13.621371  6053.950070  \n",
       "21     0.000000   0.000000    11.000000  \n",
       "22   226.000000   0.000000   300.000000  \n",
       "23    53.000000   0.000000    64.000000  \n",
       "24     2.000000   0.000000     2.000000  \n",
       "25     0.000000   0.000000     0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Feature Importances\n",
      "tloc : 0.1745017997105458\n",
      "loc : 0.09788428463428248\n",
      "assertionRoulette : 0.0869156333505903\n",
      "wmc : 0.07797515388503977\n",
      "rfc : 0.06536677478401684\n",
      "assertionDensity : 0.06526028181900706\n",
      "halsteadVocabulary : 0.061891822027430494\n",
      "halsteadLength : 0.060804020715121664\n",
      "halsteadVolume : 0.06049119293636487\n",
      "cbo : 0.05957870086149361\n",
      "mpc : 0.04330504740017368\n",
      "lcom2 : 0.036031102972454335\n",
      "conditionalTestLogic : 0.03431974567769254\n",
      "tmcCabe : 0.028022175129165494\n",
      "fireAndForget : 0.011727650397604445\n",
      "eagerTest : 0.009009831862303978\n",
      "lcom5 : 0.008780411499185464\n",
      "functionalDecomposition : 0.008756083996942813\n",
      "mysteryGuest : 0.006858043436176295\n",
      "sensitiveEquality : 0.001369413010064337\n",
      "resourceOptimism : 0.0011508298943434796\n",
      "classDataShouldBePrivate : 1.849767336266537e-16\n",
      "complexClass : 1.2515409548639453e-16\n",
      "spaghettiCode : 1.0078794578887585e-16\n",
      "testRunWar : 0.0\n",
      "godClass : 0.0\n",
      "\n",
      "\n",
      "hector_29e88d0b988d9e5c8dc3b529414a270805ce0d7c\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>Mean_S_TR</th>\n",
       "      <th>STD_S_TR</th>\n",
       "      <th>Mean_S_T</th>\n",
       "      <th>STD_S_T</th>\n",
       "      <th>Mean_T</th>\n",
       "      <th>STD_T</th>\n",
       "      <th>Min_S_TR</th>\n",
       "      <th>Max_S_TR</th>\n",
       "      <th>Min_S_T</th>\n",
       "      <th>Max_S_T</th>\n",
       "      <th>Min_T</th>\n",
       "      <th>Max_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tloc</td>\n",
       "      <td>11.372549</td>\n",
       "      <td>9.171938</td>\n",
       "      <td>11.015625</td>\n",
       "      <td>8.823655</td>\n",
       "      <td>13.672131</td>\n",
       "      <td>11.994105</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tmcCabe</td>\n",
       "      <td>2.137255</td>\n",
       "      <td>1.087140</td>\n",
       "      <td>2.218750</td>\n",
       "      <td>1.119364</td>\n",
       "      <td>1.860656</td>\n",
       "      <td>1.208206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assertionDensity</td>\n",
       "      <td>0.169340</td>\n",
       "      <td>0.241499</td>\n",
       "      <td>0.146052</td>\n",
       "      <td>0.210370</td>\n",
       "      <td>0.126621</td>\n",
       "      <td>0.152860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assertionRoulette</td>\n",
       "      <td>1.341176</td>\n",
       "      <td>1.894166</td>\n",
       "      <td>1.187500</td>\n",
       "      <td>1.457057</td>\n",
       "      <td>2.106557</td>\n",
       "      <td>2.744814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mysteryGuest</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>1.772188</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>1.400733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eagerTest</td>\n",
       "      <td>1.211765</td>\n",
       "      <td>1.378354</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>0.952102</td>\n",
       "      <td>1.590164</td>\n",
       "      <td>2.023638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sensitiveEquality</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.175898</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.090536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resourceOptimism</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.255071</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conditionalTestLogic</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>1.398736</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.201850</td>\n",
       "      <td>0.827869</td>\n",
       "      <td>1.497616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fireAndForget</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.108037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>testRunWar</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>loc</td>\n",
       "      <td>131.031373</td>\n",
       "      <td>128.362549</td>\n",
       "      <td>122.406250</td>\n",
       "      <td>114.709117</td>\n",
       "      <td>121.450820</td>\n",
       "      <td>126.701452</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>489.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>516.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lcom2</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>143.215849</td>\n",
       "      <td>62.531250</td>\n",
       "      <td>152.058674</td>\n",
       "      <td>49.139344</td>\n",
       "      <td>128.473383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>561.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>561.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lcom5</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>1.438278</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>1.209154</td>\n",
       "      <td>1.286885</td>\n",
       "      <td>3.825706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cbo</td>\n",
       "      <td>8.368627</td>\n",
       "      <td>10.119240</td>\n",
       "      <td>7.765625</td>\n",
       "      <td>10.108526</td>\n",
       "      <td>8.852459</td>\n",
       "      <td>9.922570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wmc</td>\n",
       "      <td>23.019608</td>\n",
       "      <td>27.278738</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>24.459880</td>\n",
       "      <td>23.622951</td>\n",
       "      <td>24.381380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rfc</td>\n",
       "      <td>26.235294</td>\n",
       "      <td>33.951789</td>\n",
       "      <td>22.609375</td>\n",
       "      <td>30.880526</td>\n",
       "      <td>30.516393</td>\n",
       "      <td>35.168833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mpc</td>\n",
       "      <td>17.141176</td>\n",
       "      <td>25.446324</td>\n",
       "      <td>14.171875</td>\n",
       "      <td>23.320782</td>\n",
       "      <td>22.245902</td>\n",
       "      <td>30.656538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>halsteadVocabulary</td>\n",
       "      <td>519.580392</td>\n",
       "      <td>585.795764</td>\n",
       "      <td>485.187500</td>\n",
       "      <td>536.854770</td>\n",
       "      <td>507.360656</td>\n",
       "      <td>583.089195</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2076.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2076.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>halsteadLength</td>\n",
       "      <td>142.423529</td>\n",
       "      <td>131.985567</td>\n",
       "      <td>133.046875</td>\n",
       "      <td>119.706842</td>\n",
       "      <td>131.254098</td>\n",
       "      <td>127.378175</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>504.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>halsteadVolume</td>\n",
       "      <td>936.234708</td>\n",
       "      <td>1033.810920</td>\n",
       "      <td>860.822894</td>\n",
       "      <td>933.496898</td>\n",
       "      <td>864.445665</td>\n",
       "      <td>979.826272</td>\n",
       "      <td>50.167907</td>\n",
       "      <td>3933.672096</td>\n",
       "      <td>68.420027</td>\n",
       "      <td>3933.672096</td>\n",
       "      <td>62.709884</td>\n",
       "      <td>3868.475185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>classDataShouldBePrivate</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>complexClass</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>spaghettiCode</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>functionalDecomposition</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.744866</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.704119</td>\n",
       "      <td>0.319672</td>\n",
       "      <td>0.730294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>godClass</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      column   Mean_S_TR     STD_S_TR    Mean_S_T     STD_S_T  \\\n",
       "0                       tloc   11.372549     9.171938   11.015625    8.823655   \n",
       "1                    tmcCabe    2.137255     1.087140    2.218750    1.119364   \n",
       "2           assertionDensity    0.169340     0.241499    0.146052    0.210370   \n",
       "3          assertionRoulette    1.341176     1.894166    1.187500    1.457057   \n",
       "4               mysteryGuest    0.509804     1.772188    0.421875    1.400733   \n",
       "5                  eagerTest    1.211765     1.378354    1.171875    0.952102   \n",
       "6          sensitiveEquality    0.023529     0.175898    0.031250    0.250000   \n",
       "7           resourceOptimism    0.043137     0.255071    0.031250    0.250000   \n",
       "8       conditionalTestLogic    0.705882     1.398736    0.625000    1.201850   \n",
       "9              fireAndForget    0.011765     0.108037    0.000000    0.000000   \n",
       "10                testRunWar    0.000000     0.000000    0.000000    0.000000   \n",
       "11                       loc  131.031373   128.362549  122.406250  114.709117   \n",
       "12                     lcom2   60.000000   143.215849   62.531250  152.058674   \n",
       "13                     lcom5    0.952941     1.438278    0.671875    1.209154   \n",
       "14                       cbo    8.368627    10.119240    7.765625   10.108526   \n",
       "15                       wmc   23.019608    27.278738   20.250000   24.459880   \n",
       "16                       rfc   26.235294    33.951789   22.609375   30.880526   \n",
       "17                       mpc   17.141176    25.446324   14.171875   23.320782   \n",
       "18        halsteadVocabulary  519.580392   585.795764  485.187500  536.854770   \n",
       "19            halsteadLength  142.423529   131.985567  133.046875  119.706842   \n",
       "20            halsteadVolume  936.234708  1033.810920  860.822894  933.496898   \n",
       "21  classDataShouldBePrivate    0.000000     0.000000    0.000000    0.000000   \n",
       "22              complexClass    0.000000     0.000000    0.000000    0.000000   \n",
       "23             spaghettiCode    0.000000     0.000000    0.000000    0.000000   \n",
       "24   functionalDecomposition    0.443137     0.744866    0.390625    0.704119   \n",
       "25                  godClass    0.000000     0.000000    0.000000    0.000000   \n",
       "\n",
       "        Mean_T       STD_T   Min_S_TR     Max_S_TR    Min_S_T      Max_S_T  \\\n",
       "0    13.672131   11.994105   3.000000    57.000000   3.000000    48.000000   \n",
       "1     1.860656    1.208206   1.000000     7.000000   1.000000     5.000000   \n",
       "2     0.126621    0.152860   0.000000     1.375000   0.000000     1.000000   \n",
       "3     2.106557    2.744814   0.000000     9.000000   0.000000     5.000000   \n",
       "4     0.000000    0.000000   0.000000    10.000000   0.000000     7.000000   \n",
       "5     1.590164    2.023638   0.000000     8.000000   0.000000     4.000000   \n",
       "6     0.008197    0.090536   0.000000     2.000000   0.000000     2.000000   \n",
       "7     0.000000    0.000000   0.000000     2.000000   0.000000     2.000000   \n",
       "8     0.827869    1.497616   0.000000     9.000000   0.000000     6.000000   \n",
       "9     0.000000    0.000000   0.000000     1.000000   0.000000     0.000000   \n",
       "10    0.000000    0.000000   0.000000     0.000000   0.000000     0.000000   \n",
       "11  121.450820  126.701452  25.000000   500.000000  25.000000   489.000000   \n",
       "12   49.139344  128.473383   0.000000   561.000000   0.000000   561.000000   \n",
       "13    1.286885    3.825706   0.000000     8.000000   0.000000     6.000000   \n",
       "14    8.852459    9.922570   0.000000    43.000000   0.000000    43.000000   \n",
       "15   23.622951   24.381380   0.000000   101.000000   2.000000   101.000000   \n",
       "16   30.516393   35.168833   0.000000   135.000000   1.000000   135.000000   \n",
       "17   22.245902   30.656538   0.000000    98.000000   0.000000    98.000000   \n",
       "18  507.360656  583.089195  23.000000  2076.000000  26.000000  2076.000000   \n",
       "19  131.254098  127.378175  16.000000   515.000000  19.000000   515.000000   \n",
       "20  864.445665  979.826272  50.167907  3933.672096  68.420027  3933.672096   \n",
       "21    0.000000    0.000000   0.000000     0.000000   0.000000     0.000000   \n",
       "22    0.000000    0.000000   0.000000     0.000000   0.000000     0.000000   \n",
       "23    0.000000    0.000000   0.000000     0.000000   0.000000     0.000000   \n",
       "24    0.319672    0.730294   0.000000     2.000000   0.000000     2.000000   \n",
       "25    0.000000    0.000000   0.000000     0.000000   0.000000     0.000000   \n",
       "\n",
       "        Min_T        Max_T  \n",
       "0    2.000000    57.000000  \n",
       "1    1.000000     5.000000  \n",
       "2    0.000000     0.666667  \n",
       "3    0.000000    12.000000  \n",
       "4    0.000000     0.000000  \n",
       "5    0.000000    10.000000  \n",
       "6    0.000000     1.000000  \n",
       "7    0.000000     0.000000  \n",
       "8    0.000000     8.000000  \n",
       "9    0.000000     0.000000  \n",
       "10   0.000000     0.000000  \n",
       "11  16.000000   516.000000  \n",
       "12   0.000000   768.000000  \n",
       "13   0.000000    38.000000  \n",
       "14   1.000000    62.000000  \n",
       "15   1.000000   110.000000  \n",
       "16   1.000000   145.000000  \n",
       "17   0.000000   125.000000  \n",
       "18  23.000000  2155.000000  \n",
       "19  20.000000   504.000000  \n",
       "20  62.709884  3868.475185  \n",
       "21   0.000000     0.000000  \n",
       "22   0.000000     0.000000  \n",
       "23   0.000000     0.000000  \n",
       "24   0.000000     2.000000  \n",
       "25   0.000000     0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Feature Importances\n",
      "mysteryGuest : 0.1128717286117994\n",
      "wmc : 0.08075176287190061\n",
      "assertionDensity : 0.07934750830151284\n",
      "halsteadVocabulary : 0.07294957381980192\n",
      "halsteadLength : 0.0687511462916018\n",
      "lcom5 : 0.0683073069441553\n",
      "halsteadVolume : 0.06472304098392868\n",
      "loc : 0.06395661730495758\n",
      "mpc : 0.05873813089306022\n",
      "cbo : 0.05294514142119904\n",
      "rfc : 0.051507546510185\n",
      "tloc : 0.048318804820182575\n",
      "lcom2 : 0.04178034248315659\n",
      "eagerTest : 0.03925392083766298\n",
      "tmcCabe : 0.03670987745435704\n",
      "assertionRoulette : 0.028466338469175286\n",
      "conditionalTestLogic : 0.01306286428012877\n",
      "fireAndForget : 0.010596957582339203\n",
      "resourceOptimism : 0.0037166503059876863\n",
      "functionalDecomposition : 0.003082961771038417\n",
      "sensitiveEquality : 0.0001617780418691388\n",
      "classDataShouldBePrivate : 0.0\n",
      "testRunWar : 0.0\n",
      "complexClass : 0.0\n",
      "spaghettiCode : 0.0\n",
      "godClass : 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(tmp['repository'])):\n",
    "    print(tmp['repository'][i])\n",
    "    print_distribution(tmp['X_source_train'][i], \n",
    "                       tmp['X_source_test'][i], \n",
    "                       tmp['X_target'][i], \n",
    "                       columns)\n",
    "    print('\\n Feature Importances')\n",
    "    print_featureImportances(tmp['clf'][i],columns)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CrossProject - LocalModel (Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hbase_e593f0efbf1144bcb5909d2630321e631a2e66bb\n",
      "Numero Cluster generati: 4\n",
      "    |--- TEST_ACC 0.5777777777777777\n",
      "    |--- TEST_PR 0.12\n",
      "    |--- TEST_REC 0.05263157894736842\n",
      "    |--- TEST_F1 0.07317073170731707\n",
      "    |--- TEST_AUC 0.4368848951647411\n",
      "activiti_b11f757a\n",
      "Numero Cluster generati: 6\n",
      "    |--- TEST_ACC 0.9816933638443935\n",
      "    |--- TEST_PR 0.0\n",
      "    |--- TEST_REC 0.0\n",
      "    |--- TEST_F1 0.0\n",
      "    |--- TEST_AUC 0.5\n",
      "hector_29e88d0b988d9e5c8dc3b529414a270805ce0d7c\n",
      "Numero Cluster generati: 5\n",
      "    |--- TEST_ACC 0.7295081967213115\n",
      "    |--- TEST_PR 0.0\n",
      "    |--- TEST_REC 0.0\n",
      "    |--- TEST_F1 0.0\n",
      "    |--- TEST_AUC 0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr4AAAHiCAYAAAAOI89kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3hc1Zn48e+d3tSbLdmybEm25YpwoxhCMxhYhxY2ZNmELEkMgYTfJgtkTQlmCRAIhCxLCT1sNhs2bAILwQFDEloAG9yLXCRbtmT1Lk2fe+/vj9GMqm2NNDN3ZnQ+z8PDaHRn5tXxlHfOPed9JVVVVQRBEARBEAQhxem0DkAQBEEQBEEQ4kEkvoIgCIIgCMKkIBJfQRAEQRAEYVIQia8gCIIgCIIwKYjEVxAEQRAEQZgUROIrCIIgCIIgTAoi8RUEQRAEQRAmBZH4CoIgCIIgCJOCSHwFQRAEQRCESUHTxLejo4O5c+dy7733Rnzbb37zm8ybN2/E9X/3d3/HnDlzmDNnDkuWLKGhoSEaoQqCIAiCIAhJTrPEt7W1lXPOOYfxdExev349n3766Yjrv/vd73Lw4EEuueQSbrrpJpxOJ5dffnkUohUEQRAEQRCSnUGLB/3Nb37DfffdN67bnnfeeRw7dgxJkkb87v3336ewsJDHHnsMAJfLxa9+9SsaGhooLCycUMyCIAiCIAhCctNkxvf3v/89WVlZ/OUvfxnxuwceeIC5c+cyZ84c5s6dy3e/+90hv29sbOTaa69l6tSpQ653u90oisJZZ50Vvu773/8+EEy0BUEQBEEQhMlNkxnfP/zhD6Ne/+mnn/Lyyy9TUVHBddddx+uvv85f/vIXHnjgAe644w4AqqqqAPjrX/865LYHDx4EGLLu1+FwAFBdXR31v0EQBEEQBEFILglV1eFf//VfMZvNvP7661xxxRW8/PLL5OTk8Morr5z0tq2trcBAsjuYx+OJeqyCIAiCIAhCctFkxvd4Ojs78Xq9zJkzZ8j1o63nHS4rKwuAvr6+Eb+z2+3RCVAQBEEQBEFIWgmV+Kqqit1u5+677x5yvdVqPeltFyxYAMD+/fvD14WS4JkzZ0YxSkEQBEEQBCEZJVTim5GRQXt7O1dccUX4uksuuQS/38/q1atPeFuTyYROp+Ojjz4KX/f4448DcO2118YmYEEQBEEQBCFpJNQa37vuugtFUfjSl77EH/7wB/7pn/6JmpoaioqKxnT7M844g7q6Or7//e/z7//+7/znf/4nmZmZopSZIAiCIAiCkFiJ7+rVq7n66qtpbm5m3bp1fPLJJ1RUVPCrX/1qTLd/4YUXmDFjBhs3buSpp57Cbrfzxz/+MbZBC4IgCIIgCElBUsfTOk0QBEEQBEEQkkxCzfgKgiAIgiAIQqyIxFcQBEEQBEGYFOJW1WHLli3xeihBEARBEARhApYsWaJ1CDEhZnwFQRAEQRCESSHudXyT6RuEy+WiqqqKiooKbDab1uGMS19fH/v27QNg7ty5o7Z0jkcM27dvp7a2losuuoi8vDxNYtB6HKIlFZ6XiUKMZfSIsYweMZbRI8Yycql+hj6hGlgI0bdv3z4uvPBCADZu3MjSpUs1ieHLX/4yAG+88YYmiW8ijIMgCIIgCNoSSx0EQRAEQRCESUEkvoIgCIIgCMKkIBJfQRAEQRAEYVIQia8gCIIgCIIwKYjEVxAEQRAEQZgUROIrCIIgCIIgTAoi8RUEQRAEQRAmBVHHN8XZ7fZwzVq73a5ZDKeeeiput1vTGLQeB0EQBEEQtCUS3xRXUVHBxo0bNY/hjTfeoKqqijlz5mgWg9bjIAiCIAiCtlJ6qcPM+37PzPt+r3UYgiAIgiAIQgJI2cR35n2/52iXi6NdLpH8CoIgCIIgCKm51CGU9IaEkt/Dd1+lYVTa6Ojo4MMPPwTg7LPPJjs7W5MY3nvvPerr65kyZQo2m02TGLQeB1VV6XQ14fU7MRvtZNmmIElS3OMQBEEQhMkq5RLf4UlvyGRNfg8dOsT1118PwMaNGzVJ+A4dOsSNN94IwPLlyykqKtIkBi3Hobn7MPubNuHy9YSvs5nSmTNlBQUZM+MaiyAIgiBMVim11OF4SW+IWPYgaKG5+zDbjr47JOkFcPl62Hb0XZq7D2sUmSAIgiBMLimT+J4s6Q0Rya8QT6qqsr9p06ArQFHkIcfsb9qEqqpxjkwQBEEQJp+USHzHmvSGiORXiJdOV9OQmV6nr5suVzMevzN8ncvXQ6erSYvwBEEQBGFSSYnEVxASlXdQgjv4Z5e3e9j1Y//iJgiCIAjC+KRE4nv47qsozhx7pYDiTNuk2+QmaMNsHNQl7gSrGczG+Fe6EARBEITJJiUSXxh78iuSXiGesmxTsJnSgz9IYDE5ghelgZeezZROlm2KFuEJgiAIwqQSceLr8/m49957WbZsGWeccQY///nPE2ZjzsmSX5H0CvEmSRJzpqwI/6yT9ACoqhJ+3cyZskLU8xUEQRCEOIi4ju9PfvITNm3axAsvvIDT6eQHP/gBhYWFXHPNNbGIL2KH775q1M1ukzXpzcrK4vLLLw9f1iqGNWvW0NPTQ2ZmpmYxaDUOBRkzqSxexf6mTfgCnvD1ZoON+UUrJ2UdX9HMQxAEQdBCRIlvV1cXv//973nppZdYtGgRANdffz07duxImMQXRk9+J2PSC1BaWsqLL76oeQxPP/00VVVVzJo1S7MYtByHgoyZqKrKsc791HcdQCfpWDz9PHLS4t/MQ2uimYcgCIKglYgS3y1btuBwOFi+fHn4urVr10Y9qGg4fPdVGP/l1yj9P3e5vGTazJrGJExuR9p30+lqwmywAuCVJ18lh1Azj+FCzTwqi1eJ5FcQBEGImYjW+NbV1VFUVMTrr7/O6tWrOf/883nyySdRFOXkN9bAWbPyw5ff2d+gYSSCAE5vFwBplmxWlv89BemTK8Eb0cxjFKKZhyAIghBLEc34ulwujhw5wiuvvMKDDz5Ia2srP/7xj7FarVx//fVjvo94WVWaxweHWgD44+4jrJlTENHt3W73kP8no7a2Nt577z0ALrjgAnJzc+MeQ3NzM7/73e/o7OzkuuuuY8aMGZrE8NprrwFwxRVXUFAQ2XNhogKyD7cvWMO3wF6KTjHh9fgAX8T3lazPyy5XM73uzhMe0+vupLG9lkxbfP59knUsE5EYy+gRYxk9YiyF4SJKfA0GA319fTz66KMUFQXXJjY0NPDb3/52zIlvVVVV5FGO0wW5Knf1X95R1zbux66trY1aTFpYvHgxAK2trbS2tsb98auqqnjooYcAWLBgQVy//AyO4Sc/+QkA+fn5VFRUxPXxvUovrv4mFU3H2ulunPjrINmel31yC65AcAwUVUbGi6IqmHR2JAY2th08tA+HviOusSXbWCYyMZbRI8YyesRYCiERJb55eXmYzeZw0gswc+ZMGhsbx3wf8Uw4utw+JKpQgaN9/ogf2+12U1tbS0lJCVarNTZBxtjevXu56aabAHjqqaeYN29e3GMY/E176tSpcU86h8dQUlIS9xiaew7R2RQstTd/1imYDTYUVQ6XN4tEsj4vu1zZ9NXXAsEZ8D6fEwmwmM3odQNvReXT5sZ1xjcZxzIRibGMHjGW0SPGMnLxnKDUQkSJ7+LFi/F6vRw+fJiZM4PrEw8dOjQkET4Zmy1+HapsNhuSBKoKfd4AVqt1XCWTrFZrXOOOturq6vBlLf4Oi8USvmw2mzWPwWKxxD2GQK8HvV6PTjLQ6T3Gobpt6HV6zq34+rjvM9mel1ZrCdXtWcFqDpIRydf/WpRU9PrgFwCbKZ2pOSVxL22WbGOZyMRYRo8Yy+gRYymERLS5bdasWZxzzjmsW7eOffv28dFHH/Hss8/yta99LVbxTViGxQQEu8XWdvZpG4wwabm83QDYzRnoJB0BxYc34EZRZY0ji5/BzTwGlzJT1ED4smjmIQiCIMRSxJ3bHnnkEYqLi/na177Gj370I6699lq+/vXxz1rF2sxse/jyO/tEZQdBG07fQOJrMQ48J73+ybXhoiBjJounn4+sDCS7siJjM6WLUmaCIAhCzEXcuS0tLY2HH344FrHExOkleWw9FtxJ/tGhZm48Y47GEQmTUXH2PHo97aRb84Ykvh6/E6vJoWFk8ZdpKyDDmkdA8aGoCjn2Qs4s/4qY6RUEQRBiLuIZ32SzvHigfNe2+hOXUhKEWJmWPZeKwjMpypo9LPGdfMtvPH4nkiRh1JsxG6woqiKSXkEQBCEuUj7xLc9LD1+u73ZqGIkgBJkMAxssvIHJ95wcnuy7/b2oamI2wREEQRBOzuv1cscdd7B06VJWrlzJiy++eNxj9+7dy9VXX83ixYu56qqr2L1796jH/elPf2LOnKFn6d99913mzJkz5L9bbrklolgjXuqQbAYnvk6fjF9WMOpTPt8PmzJlCt/73vfCl7WK4YYbbqCjoyPujSMGx6D1OIToJB1mgx1vwInHPxkT36F/s6oq/Us+0jSKSBAEQZiIhx9+mN27d/Pyyy/T0NDAj370IwoLC1m9evWQ41wuF2vXrmXNmjX89Kc/5be//S033HAD77777pCqGz09Pdx///0jHqe6uppzzz2X++67L3yd2WyOKNaUT3yzbWZMeh0+OTijtLOhkyXTczSOKn6mTZvGv/3bv2kew913301VVVVEpe+iHYNW43CkbTddrmbSrXnMzFsEgMU4mRPf4IyvhMTi4vOxmdIxG0WZIUEQhGTkcrl49dVXee6555g/fz7z58/n4MGD/OY3vxmR+G7YsAGz2cztt9+OJEnceeedfPjhh7z99ttceeWV4eMefvhhpk+fPqLpVk1NDbNnzyYvL2/c8UY89enz+bj33ntZtmwZZ5xxBj//+c9RVXXcAcTDtMyBD9WN+0VlByG+2p0NNHbX0NxzOHxdaJ3v4OoGk0Uo2c+w5TMlYxbp1txxNfIQBEEQtLdv3z4CgQCVlZXh65YsWcKOHTtQlKHL2Hbs2MGSJUvC+zokSeLUU09l+/bt4WM2b97M5s2bufHGG0c8Vk1NDSUlJROKN+IZ35/85Cds2rSJF154AafTyQ9+8AMKCwu55pprxnR7LdrVXjgrm7/2JxiHW9rHHIPo8R09k3kse5ztyLKMUbKGn3ul2csozz0dnaSL+DWR7GPZ5+5ClmX0mDR5Pxgs2ccykYixjB4xltEjxjL2WltbycrKwmQyha/Lzc3F6/XS1dVFdnb2kGPLysqG3D4nJ4eDBw8CwcnVu+++mx//+McYjcYhx6mqyuHDh/n444955plnkGWZ1atXc8sttwx57JOJKPHt6uri97//PS+99BKLFgVP2V5//fXs2LFjzImvFq3wri93cH35QMmoSGMQPb6jZ7KNpaqqtPmaUFHo9PZR1Rm953+yjqVBySdNTcfXYaSqKzgeqqpqWtkhWccyEYmxnBhVVfGo3ciqj6pDXVikDFH1JArE8zJ23G73iMQz9LPP5xvTsaHjnnzySebPn8/KlSvZtGnTkOMaGhrCt//FL35BfX09P/nJT/B4PNx1111jjjeixHfLli04HA6WL18evm7t2rWR3AUVFRURHR8Nf6o6xt1/2g6AWS/xt/93yZhulwo9vvfu3ctNN90EwFNPPcW8efM0jeGxxx4bcjpEixjiOQ5ufx/Nh4PtksumziU/rWTi95kCz8uQ2vYdNHQfxGywsqT40rg/fiqNpdbEWE5ca98Ralq34PR24/F4sFgs2M0ZlOYtIc8xQ+vwkpJ4XkYu0slBs9k8IsEN/WyxWMZ0rMVi4cCBA/zud7/jzTffHPVxioqK2LRpExkZwS+DFRUVKIrCbbfdxrp169Drx7ZkLqI1vnV1dRQVFfH6669zyimnUFlZyZNPPjliDUeiKc600ekJsL/Tw842N90ev9YhTSoej4fq6mqqq6vxeDxahxNX7kGteW2mgQojqqriC3jo9bTjl71ahJYQZFXGG3Di9vdqHYogaKq17wh7Gj4Y8Vpw+3vZ0/ABrX1HNIpMEE6soKCAzs5OAoGBPSutra1YLBbS09NHHNvW1jbkura2NvLz89m4cSPd3d2sWrWKyspKvvOd7wBQWVnJG2+8AUBmZuaQMyClpaV4vV66u7vHHG9EM74ul4sjR47w9NNP43a7Wb58Ob/+9a+xWq1cf/31Y7oPLZY66IB/O7OIG98LvnH8afNOFueNfRd5Mp8ikSSJp59+OvyzFuM/ePwaGxs1iUGrceiWj+EKBNexHqlpQCc1A+BX3dT5gqdxCgzzsesj36GazM/LkB65q398XOzeuxO9ZDzpbWIhFcYyUYixjJyqqtT5NxNQg+tQVYIbxgdPFGyr+SvTjMvFsodxEs/L2KmoqMBgMLB9+3aWLl0KBFcILFy4EJ1u6Pzq4sWLee6558LL21RVZevWrdx4442cf/75rFmzJnzsjh07uO2223j99dfJycnho48+4tZbb+X9998Pz95XVVWRmZk5ZB3xyUSU+BoMBvr6+rBarSxcuJCioiLOP/98fvvb34458dViqQPAt999O3x5v9fENWOIIxVOkSTCUofBmwqmTp2qyXNAq3E42NKLu8uG2WBn/qwF4esVVab94C4ApuTlMS1r7GOSzM/Llt5aqls/x2yws6joAvq8mbjq6wCYUVxEmiW+pQaTeSwTjRjL8etyNdNcL2HChl/20uftRFEU9HoDep0enaRHlhRMuX2U5FZi0GnzBTEZiedl5CKdGLJarVx++eWsX7+eBx54gJaWFl588UUefPBBIDj7m5aWhsViYfXq1Tz66KPcf//9XHPNNbzyyiu43W4uvvhibDYbmZmZ4fttamoCYMaM4DKfyspKzGYzd911FzfffDN1dXU8/PDDfPvb344o3ogS37y8PHQ6HVdeeSUtLS0AzJw5k8bGxjHfx+ACxfFkNJuBYBmlz491RxSH1WrVLO5oqK6uDl/W4u8YvMbHbDZrNpZajINfdaHX60m3ZY94TKvJjk/2oOoC44onGZ+XitNPQPUi+/2kO9IxmfXhdVmKzqfZ35OMY5moxFhGrtsnh18Hbr+XgUldBUVRUQgQwMvhzh1UTD8Doz64OUhWAmw78i5WUxo2U3rwP3MaVmM6Bv34k2NVVel0NeH1OzEb7WTZpiT9TLN4XsbWunXrWL9+Pddddx0Oh4Pvf//7XHjhhQCsXLmSBx98kCuvvBKHw8EzzzzDPffcw+9+9zvmzJnDs88+O6Z/G4fDwQsvvMADDzzAVVddhd1u55prrolt4quqKoqicMkll/CrX/0KgEOHDkXUlECr8kWzcxxsqe8A4EBL95jiSIUyKINPlXk8Hk3Gf3AMXq9X8xjiOQ4zs5eQby9Fp9OPeEyDZMEtO+l1dUYUTzI/L3udnciyjMVgwe32oKo6VEVFURW6+trIME2NazzJPJaJRozl+KkBPbIsAxBQ/Kgq6NBj0ltRUVBUGUWRMUgm/N4AfoJrKZ2+bpq7a0e9T5PegsWYRpolm9n5pw08Vn/d/eMlsqENdoPXGluNaUm7wU48L+PDarXy0EMP8dBDD4343f79+4f8vGjRIl577bWT3ueKFStG3La8vJyXXnppQrGOOfH1er388pe/ZNGiRaxfv56srCw8Hg8ffPAB3/3ud8f8gFqs7wRIVwae9C19Hvbu3Tvmb7DJvDZocOy1tbWanOpJhDW+iTAOzQxdfN/rd+FSXDS665G6Ih+TZHxeNvmP4FJcKJIx/Dzw+mT8qpsj9TW4mrVpJpmMY5moxFhGTlVVfH6VgOpGVSUk9OgkAwQMSIAesEhW8vyVQ94/fYoTVTbjV90E1KEbh124gA46pQ7k9oyB65V2mv17MEgWjJJ14P9Y8KtuOuSaEfG5cNHevWHc+xESgXheCiFj/pR54oknWLBgAffeey/33Xcfb731Fnq9nrVr1/L1r399zA+o1RrfFX4Hz+wKtr6TVUgrLGF65omn1lNhbdDgb7klJSWajH8irPFNhHEYTt/SzbEuN1ajhYqZk2ONr/NoDXhs5KdNo2Jq8G/2HTtGh/MY6TYrFdPi+++SzGOZaMRYTkxen509DR+gYkNRlHA5M51Oh4TE/MIvHWfGNbiZSFEVvP5ghRS3vxePvw+3vwebKYNZuQOvq/rOKnpaQ8vP3ARwE6ATVVXp9bahSDImvW1IFZqQgLGduSVnJdWyB/G8jJxWE5TxMubE96233qKtrY2//vWv4etkWeaFF17ge9/73pgfUKs1NvOLcof8vLWplzmFucc5eqhkXhtUXl4ePvVQXl6uyd9RXl7OfffdR1NTE6WlpZrFEO9xUFUFSTp+xcA0Wxb6Xj1+1YPVao34wyQZn5cB1du/5jkrHHu6LZtuTxNIqljjmwLEWI7PDFsFFrOF/U2b6HV3AqDT6UizZjFnygoKMmae9D4cOICCEx5TIBWjN+pw+Xpw+Xpw+4JJsl/2Bt+zkIKb6kapiepTnHjpIdsW3yVJ0SCel0LImBPfX//610NqtD3yyCMA3HrrrdGPKgbKc9OG/Px+dRNfO/XkbyTJrqCgIFwLT8sY/umf/omqqiry8/M1iyHe43C4bReHW7fjMGexfNaaEYmtxWgHggmyT/ZgNqT2bISiyPgCwZn30N8OUFawhNlTloc37AjCZFWQMZP89BIa22s5eGgf5dPmMjWnJKozrBnWPDKsQ5cryEqAo+272VX/IYoqn7BqhNevbZtxQZioMSe+wzew2e3BD65QmYlEl2E1kWM30e4MdgzZdqxD44iEVOfyduOXvXgD7lE/uEI7sc1GO4oSGOUeUosn4AxfHpz4pnrCLwhjVddRhdPbhVlKw6HPJ9NWEJdlBXqdgQxbASbD0C5bqMGawoNjMBvFrKmQ3LTZSaKROXkZfOIMrvM91N6ncTRCqnN6uwCwmzNG/X22fSpnz7kmjhFpy+MfnPg6NIxEEBJTc3ctbX11pJnzsFAc18fOsk3BZkrH5etBVVW63a0oqozdlBFOdm2mdLJsU+IalyBEW0Qtiwf76U9/yk9/+tNoxhJzpYOWO3S5fXgDsobRxEd1dTX/+I//yD/+4z8OqWMb7xi+9a1vcc8993Do0CHNYoj3OLh8wSoOx0t8J5ts+1QumPdNVpZfjcOSNeR3shKgz9OF2ye+kAqTl9PXBYDNGP/3DEmSmDNlRfAyEooqg6oG/99vzpQVSbWxTRBGM+7ENxkNXuerAlXNY+/tnKy6urrYsGEDGzZsoKurS7MY3nnnHT755BNNY4jnOARkH97+9aw2k0h8Qwx6Ew5LFnrd0JNNH+5/hY8P/o4j7bs1ikwQtCUrAdy+YO1cu0bvGQUZM6ksXoXNnI5O6m8so8rYTOlUFq8a0wY7QUh0kyrxLcsdWp7lb4dbNIpESHVO38CXqhPN+Pa422jsqqG1ty4eYSUsqyn4pdTt69E4EkHQhmvQe4Z1lFJi8VKQMZOzZn+Vosxy7JYsCtKDP4ukV0gVkyrxLc8bWtnho0Mi8RViw+kdW+J7oPlzdtT9mdq2nfEIS1MevxP5OJv4QjVDXSLxFSapPk9X+LLWZ4kkSSLDVhDeeCqWNwipZFJtbisbVtJsV2OnRpEIqc7Vn/jqJANmg/24x1n6fzd441eq2lr7Dj2eNqZlzWXBtLOH/C404+vy9aKqqvigFSad0GZYnaQPvy9oyWqcPO9NwuQyqWZ80y0m8h0D5VqOdooXtBAbfjnYPtRuTj9hEmcJf7j0oapqXGLTitsf3LhmNJhH/C404ysrfnyyZ8TvBSHVDa4Ckwhf/CymYOWVgOIjIPs0jkYQomdSzfhCcINbS1/wg9Xll+lwecm2jfwgFoSJqCg8k9lTVuALnDiJCyW+shIgoPhTtomDrATCXwZGK2U2uD2qy9sjavsKk05oeZTdnKltIP0G19r2+F04UvS9SZh8JtWML0BZ3tBNAzsbxHIHITb0OgNW04nr1Q79cEndUl6DT5daR0l8Q0sdANx+sc5XmHwqCs9kftFZFGXN0ToUYOC9SSfp8clujaMRhOiZdDO+w9f5fnSohXPKREFuQRvmQYmv1+8kzZKtYTSxMzipH5zsh5gNNnSSAUUN4PKKxFeYfLLsBWTZCwBwubRvC2w3Z3Juxdcx6S0JsfRCEKJl0ie+n9a2ahRJfJSVlfGb3/wmfFmrGF588UXq6uqYNWuWZjHEaxy8ATdevxObKR3DSU4PDj7tn8qbSAb/beZREl9Jksiw5qKo8si2qYIgxJ1O0oslR0JKmnSJb/mwWr5VzV3aBBInmZmZXHzxxZrHcOGFF1JVVUVmZqZmMcRrHFp7jrL72AcAnF9x3aibuUIMOiN6nRFZ8U+KxFcn6THpR09sV5R+OZ4hCYIgCJPQpEt8h8/4NvS4URQVnU6cyhGiI9R21Kg3nzDpheBM59SMUgDSrbmxDk0zoaUOFqNdnDYVhGH2NX5GW28dWfapzC9aqXU4YYqq4PW7kBX/iDbjgpCsJl3im2YxMiXNSlNvcLF+QFE53NFH6bCEWBDGyxXenT22IvTDa9qmomA9Y+uoG9sEYbLr9bTT5+3EbLRpHcoQe459yLHOAzjMWaycfbXW4QhCVEy6qg4wctY3lSs77N27l3POOYdzzjmHvXv3ahbD6tWr+e53v0tVVZVmMcRrHEJlibTuvpRIKgpP59yKr7N05qXHPSYg+2jpOcqRtt0pvexDEIYbqOGbqWkcw02mBjvC5DHpZnwhmPh+fHigXfFHh5q5YlGxhhHFjsvlYufOneHLWsWwe/duANxubcrixGscVFUNt91NtA+xRHCiZQ4ev4utR94GguXNRqv+IAipJiAPrO+3J9iX5aFNLPwY9EaNIxKEiZuUM77leUNnfDfXtWsUiZBqPP4+FFUGhjZlOJE+TxfVzVvYXf8hAcUfy/AS2uCax6EvD4KQ6ly+7vBluyVTu0BGMbTOuJj1FVLDpEx8y4ZVdjjYKj5khegILXOAsc/4unzdVLdsob5zH94U/HDxB7y09Byhx92GrASOe5xeZwh/0LpF4itMEn39yxwAHAl2lmiyNNgRJpdJmvgOnfFtd3px+4//gSwIY+UcNHtjM49txjfVZ1W6Pa1sPfIOn1T/YcgXg9FY+2fJXb7eeIQmCJoLre/V6wyYDYm1vMdimBx1xoXJRSS+gArsbTrxB7IgjIVJbyHbPpV0ax4G3djWw6V6EwuP78TtigezhRNfMeMrTA7hjW2mzIQr9WfQm9BJwa1AYsZXSBWTcnObw2xkarqVxp6BjVbbj3WwZHqOhlEJqWBqZilTM0sjuo1Rb0Yn6VFUOTUT3/4PTJ1kOGknu1Di6/b1oqpqwiUCghBt7v6zG2MtfxhPkiRhNdpx+rpT8r1JmJwmZeILUJ6bNiTx/fhwC986rVzDiITJSpIkLEY7Ll9PSn64hP4m6xiaV1hNwbMxiirjDbhEZQch5Z1Wejkefx8qqtahjMphyUKSdAlXY1gQxmvSJr6luWl8eGigpNm2Yx0aRiNMdub+xDcVN7eFEt+xJLGDK2G4fD0i8RVSniRJ4S98iahyxoVahyAIUTVpE9/yYZUdDrWn5vqliooKPvjgAwBmzZqlWQzvvPMOhw4dYu7cuZrFEOtx8Pj7aOisxm7OINtRhPEkp/UHCyV4qTnj29+u2HTyrm12UwZTM0qxmtIxG8QMkyAIghBdkzbxLRtWy9fpC9Dc66YgzapRRLFht9tZuHCh5jHMnz8fnU6HzaZNMhOPceh2t3GgeTMAZ83++3Emvqn3BSyc+I6hXbHRYGZx8fmxDkkQEkLwtSFhNtjEenZBiJNJm/gOn/EF2NXYlXKJrxA/oVJdEpGfusxPm4HZYE24ckYTFZB94aYcYtmCIAxV07KNuo4qHOYsVs6+WutwRhWQfXS5W/D4nOSlF2M2iM9IIblN2sS3NGfk7NP2Yx1cMHuqBtEIqcDVn/haTWnoJH1Et82yTyHLPiUWYWlKVmUKM8tx+/tEC2dBGCZUymwsZ0O04vb38sXhDQAsNV6COW2axhEJwsRMyjq+AHazkcL0od9c/3a45ThHJ6/t27dTVlZGWVkZ27dv1yyGhQsXctVVV7Fz507NYoj1OISaV9gSsCyRVswGK4umn8uKWWvIto/tS2Wns4mqhk/YcfTPMY5OELQVruGbwF8KRRMLIdVM2hlfgPK8dBoGlTTb1dilXTAxEggE6OjoCF/WKobOzk7NY4j1OIRmfO2mzJjc/2TR5+ngSPtuAObLZ5209q8gJCO/7MMbCH7+JGIN35BQEwtFDaTkHgRh8pm0M74w0MEttKWgrsuJrCjaBSQkrYDswxtwAWAfY6vi4XbVv8+mQ29S37EvmqElHeuQkmaidbGQmkKzvZDYM76hJhYgZnyF1DCpE9/QBrdQ2fCAolLdJj5ohcgNbrE73g+x9r4GOp2N9HraoxSV9hq7qjncupO23rox38Y26IuDW7QuFlLU0MQ3cWd8IbXLLQqTz6ROfEtzR+68T8XlDkLsDf4Qs5nG9yGWih8u9Z0H2N/0GYfbdo35NhajHan/PIxTJL5Cigq9Zxh0xoSvWR2qwS2WOgipYFInvuV5IxPfrfWpM9smxE+aJYfygmUUZc0Zd9muVEx8Qx+U1gjGRCfpwx+0YsZXSFWDN7Yleg1fiyH13puEySvizW3vvvsu3/ve94Zcd9FFF/H4449HLah4Kc0Zmfh+dqRNg0iEZOewZOGwZE3oPlIt8VVVdVC74sjKNdlM6bh9vWKNr5CyLEY7dlMGDku21qGcVOiLaEDxEZB9YsOpkNQiTnyrq6s599xzue+++8LXmc3mqAYVLzaTgWkZNuq7XeHr9jZ3aReQMKmFEl9vwIWiKuik5D4hE1B8yONsXmEzpdPOMTHjK6SsisIzgeAXxETnMGdTkD4Ti9GeFPEKwolEnPjW1NQwe/Zs8vLyYhFP3JXlplHf7UIngaJCa5+XPq8fh9modWjCJDO4a5sv4EroovZjMXg9YKR/S6iyg9vXlxJfAgTheBJ9mQNAlr2ALPsqrcMQhKiI+NOkpqaGkpKSGISijbL+db76QR+se5q6NIom+k455RRqamqoqanhlFNO0SyGXbt28fvf/55FixZpFkOsxsEbcLP50B/ZXf8hvZ6Ocd/P4OQwFZY7DP4bIp3xzUubzoJpX2LZrEujHZYgCIIQZV6vlzvuuIOlS5eycuVKXnzxxeMeu3fvXq6++moWL17MVVddxe7du0c97k9/+hNz5swZ9+McT0QzvqqqcvjwYT7++GOeeeYZZFlm9erV3HLLLZhMY1vz43K5Tn5QHFXmO5iTZaHR6cPvC173xZEWFubZcbuDxcVD/09WoaUoPp8Pn8+nSQwWi4X09HT8fr9mz4FYjUOXu5nWnmC5rhxrMXrFMq77UQM6ZFkO3mdvOyZGrkEHkuZ52d3XEf57lIAuon93PRayzdMB8Lg9MYkPkmcsk4EYy7HrcjXj9vdiN2WQbh159lSMZfSIsYyPhx9+mN27d/Pyyy/T0NDAj370IwoLC1m9evWQ41wuF2vXrmXNmjX89Kc/5be//S033HAD7777LjbbQHWTnp4e7r///nE/zolIagQLdo4dO8Z5553HFVdcwXXXXUd9fT0/+clPWLVqFXfdddcJb7tly5YxB6WFVw908LMvmgC4oiyTdcsLNY5ISBa9ciOtgf0AzDCdiV4a3zIZVVVxKR0YJDNGyYpO0kczzLjrCBymSz6CDgMl5pVahyMICaPVv59epRGjZGW6aYXW4YxJn9yCT+3DIFlJ14+t/biQ3JYsWTKm41wuF6eddhrPPfccK1YEn89PPfUUn376Kb/+9a+HHPu///u/PP3007z33ntIkoSqqlx00UXceOONXHnlleHj7rrrLmpqati6dSv79++P+HFOJKIZ36KiIjZt2kRGRgaSJFFRUYGiKNx2222sW7cOvf7kH9QVFRWRPGTM1bT18tX//BCXf6Bj2yGnSkVFBW63m9raWkpKSrBarRpGOX6yLIdnN00m05j+jWIRQ1dXF0eOHGH27Nk4HPFfuyrLMl6vFwjO/EZzHGra3Dg7bBj1ZubPWhjzNXvJ8rzscmXT5S5CRWVmTmK97kOSZSyTgRjLsXPXHUF228ixT6OiaORrIxHHcnt9HX2uNhz2olFjTlSJOJaJrqqqKqLj9+3bRyAQoLKyMnzdkiVL+OUvf4miKOh0A0tJd+zYwZIlS8Kfk5Ikceqpp7J9+/Zw4rt582Y2b97MnXfeydq1a8f1OCcS8RrfzMyhNQdLS0vxer10d3dHelcJoSgj+EKwGXXMybIwJ8uCJAdSZufq/v37ufjii7n44ovD35q0iOGqq67ihz/8IQcPHtQshksuuYRLLrkk6uPg9gWf+1ZjelJsVImXTFsBJTmLmZlzyrhuX936BZtr/4+9TR9FNzBB0FjoPWO8zW60ENp8602B/QdCdLW2tpKVlTVkyWtubi5er5eurq4Rx+bn5w+5Licnh6am4Bl3n8/H3XffzY9//GMsFsuI2471cU4kohnfjz76iFtvvZX3338//M2pqqqKzMxMsrPHVosw0m8S8fDri2eNuG7fvn3hy7W1tXGMJrokSeLpp58O/6zF+Kd6DI2+OnyqC53HQ5UzOverqupJk+hkfl6ORbP/CE6lhW6pB6kzN6aPlepjGU9iLE9MVv10+YKbYNt9Pfjbjv+ekUhj2RHoxiW78Lh8Cfk5fjKJNJapxu12j9jnFfp5+H6a4x0bOu7JJ59k/vz5rFy5kk2bNo37cU4kosS3srISs9nMXXfdxc0330xdXR0PP/ww3/72t8d8H4m21AHgu69+xud17djNepze4Gacx69YRuWUtKQ/RbJ3715uuukmILgWZt68eZrG8Nhjjw05TaFFDNEcB1VVaanegkG1MSOnlJIJntI/2rGbuq696CUDp828ctRjJsupO3ObhyMdfRh0euaWzo3JbPpkGct4EGM5Nt3uFlrrgpt45kyfT6a1YMQxiTiWDd169je3AlBeVoZBlxwlPxNxLBNdpF9szGbziMQz9PPwWdvjHWuxWDhw4AC/+93vePPNNyf8OCcSUeLrcDh44YUXeOCBB7jqqquw2+1cc801ESW+g3ftJQqb3cb+zmOkmQ30egMAbG9xcsbM4HS81WpNyLjHqrq6OnxZq78jFIOqqprHANEbB7evF0kHevRkpeVP+H5NTjOy6kNRA1it1hMme4n8vPQHvOyo/wsWg53inPmkW3Mivo9MRy713XpUFIxmPSbD+KpljEUij2WyEWN5Yh0eb3iPQW7G1BM+rxNpLDPkbPRtwbh1BgWbJTHiGqtEGstUU1BQQGdnJ4FAAIMhmFa2traGqzkNP7atbWiH3La2NvLz89m4cSPd3d2sWhWsGR2qClRZWcm9997LtGnTxvw4JxJxA4vy8nJeeumlSG+W0Mr6Wxf39Se9AJ/XtcOKmVqFJCQJp3dgbbvdPPH1eqF6tyoKvoAbszE536jd/j7aeoMl3qZmlo7rPmymgXJuLl9PTBNfQYgXp7cLAKPenFTP6cG1uD1+54RbtAupo6KiAoPBwPbt21m6dCkQrOS1cOHCERvOFi9ezHPPPRdezqeqKlu3buXGG2/k/PPPZ82aNeFjd+zYwW233cbrr79OTk4Oer1+zI9zIqIdElCWF/ymMHg727b68TciECaPLPsUTi+7gkXTz8Nuzpzw/Q3/cElWE+naFhLq3gaI1sVCynD6ugCi8n4RTxZDajXYEaLHarVy+eWXs379enbu3Ml7773Hiy++yDe+8Q0gOCvr8QTrsa9evTpco7e6upr7778ft9vNxRdfTGZmJjNmzAj/V1AQXAY0Y8YMHA7HSR9nrCJOfN99913mzJkz5L9bbrkl0rtJKOW5IxsF1Hb04ZeVUY4WhAF6nYEMax6FmWXodRGfQBkhNRPfyLq2Db6d1N9R0eXrjUpcgqC1qRmlzMiZz5SM5DqjaNCbwu9xg1/fggCwbt065s+fz3XXXce9997L97//fS688EIAVq5cyYYNG4DgktlnnnmGLVu2cOWVV7Jjxw6effbZMS9DOdHjjFXEn9TV1dWce+653HfffeHrQh2xktWsnDQkCVQV7EY9Tr+MrKpUt4kXtxBfZsPAiz+ZP1xCSbtRbx73FwJJkrAZ03D6usWMr5AypmaWMTWzTOswIiZJEmX5S9Hr9GTapmgdjpBgrFYrDz30EA899NCI3w0vIbpo0SJee+21k97nihUrRtz2RI8zVhF/ItXU1DB79mzy8ka2WUxWFqOe4kw7RzqdpFuMOP3BBdW7m7tZkBwbV49Lp9Nht9vDl7WKwWazRVRgOhYxxGIcFFWOaoc1vc6AUW/BL3vwBhKrvXckQonveGd7Q6zm9GDim8RfAgQhVczMW6R1CIIwYeNKfM8444xYxKKpstw0jnQ6MegHkqI9TV0smD7x09daOvXUU6mrq9M8hgMHDlBVVaVZObtYjIOiyry75yUsBjuzpywf9yau4SxGO37ZkxJLHca7vjdk3tQz0RXpwsXzBUEQBGEiIsrqVFXl8OHDfPzxxzzzzDPIsszq1au55ZZbRhQVPh6XKzFnsVYUplPf1kWmVU9rr4RHVtlS38FXp+fjdru1Di/phcYwlcbS6esmEPDTF+jC7wtE7bmtx4Qsy7g8faPeZzKMZZ+7G1mW0ammCY6LAUUGtz82f2syjGWyEGN5ck09NXQ4j2E3ZzEje+FxjxNjGT1iLIXhJDWC3rzHjh3jvPPO44orruC6666jvr6en/zkJ6xatYq77rrrhLfdsmXLhIONlwc3N/JadSdTbEbeuLxc63CEBOWU22gO7AZgmnE5Jl10So/Jqg8JfVSXUMSTqqrU+j5CRSFLP5MswwytQxKEhNDq30ev0oRRsjHdtFzrcCLmUbrplusIqF6mGhejk5L7jKhwYkuWLNE6hJiI6FlbVFTEpk2byMjIQJIkKioqUBSF2267jXXr1oWLcp9IInZuA/iwpokf/l8wOe/0BOv5Nrn89PlkFswuTdqOLx6PJ9wDe8qUKRF1N4kWt9tNdXU1x44dY8WKFWRlxb/+YyzG4WjHHnrbbEhILCyvRCfFZ/1yonciUlWVIk8u3oATuylrwmWbVFXFJ7vRSXqM+uhupE30sUwmYixPznX0MLLHRq6jmIrC438WJupYtjvr2XlsP3qgZMb0pCjJlqhjmciSsSV1JCL+upaZmTnk59LSUrxeL93d3WRnZ5/09onaOWVGfg77O4N15rKsA8s2qru8LEviji979+4Nl/rYuHFjuOhzvGO4+OKLAXjjjTcoKirSJIZoj0Ogw41er8dmSsdhn9ha1vFI5E5EoY2EE6UoMu/tfRlFDVBReCYzcuZH5X6HS+SxTDZiLEenqio+xYleryfTkTumMUq0sZR1OeEJLsmgJFRsJ5NoYyloJ6Ipqo8++ogVK1YMWStTVVVFZmbmmJLeRDYrx4Guvz1svmNgNrC626NVSEKCc/qCXdtsUejYNlxA9tHn6SQg+05+cArT6fQY9cEvoqKkmZDMfLIHv+wFkq95RcjgzarJvPlWmNwiSnwrKysxm83cddddHDp0iA8++ICHH36Yb3/727GKL27MBj3FWcFvgzbTwER4TadIfIXRufrbFdtN0U18nd4u3tv7Kz4++Codzqao3ncysvV3cHN5ReIrJK9Qq2IAR5ImvgadaGIhJL+IEl+Hw8ELL7xAR0cHV111FXfeeSdf/epXUyLxBSjLDX7A+gJy+Lq9HSLxFUYKyL5wnV17lGd8B5fu8ibhh8vB5i/4YP9v2XZkY1Tuz2oKdlZ0iRlfIYkNTnztpkzN4pgISZKw9L8/iRlfIVlFvMa3vLycl156KRaxaK4sN433DjTS4fKGrzvc7SWCwhfCJOENuDDqzfhlb9SXOhj0Rgw6EwHFl5QfLi5vN25fL0ZddDaihWd8fb2oqorUvyRJEJJJKPE16S0YDcnb7dRicuD0dSfle5MgwDgS31RWnhucWWrs9YRbGHtklbpuF3OjtFlHSA12cybnz7sOX8Az7pa8J2Ix2unz+vAEku/DJVpd20JCia+iBvAF3JiNYoOKkHz6+hPfZF3fGxJ6XYulDkKyEonvIGV56eHLhWlWjvUEN/Htae5hbmHqtGgWosdkiE15uGDi25mUsyrRTnytpoHXpcvXIxJfISnNKzyTPk9n0tbnDgltcEvG9yZBAJH4DhGa8QWYlmkLJ767m7q5SqughElpYFYluT5cVFUNz1JPtF1xiM088Lp0+XrIsk+Jyv0KQjzZTOnhsxfJrDCznGz7VCxGu1h6JCQlkfgOMjM7WNJMUVXSLAO1fPc0dWsY1cRYrVbmzJkTvqxVDLNnz8br9WrSQCMUQzTHodPZhMlgxWpKi0njCnN/4utNssTXF3CjqgoAFlN0ZnxNeitGvRmTwSo+ZAVBY3ZzRtQ39ApCPInEdxCTQc+MLDuHO/qAgQ1t2xu7NItpoubPn8+nn36qeQx/+ctfqKqq0qxzXzTHQVVVttS+TUDxMSvvFGZPiX7r0dBsaUDxE5B9GPSmk9wiMbgHrfuL1oyvJEmcV/ENkfQKSUtVFaQ4dXYUBOHEROI7TFluGoc7+ujtb1sMcLijD29AxmxI7rVZQnT4ZS8BJdhYwhblGr4hVqMDi9GBxWgjoCRP4jt4hjpaa3wBkfQKSe1Q6w5q23aSZslh2cxLU+b5LJY6CMlIJL7DlOel8+6BRhp6XOh1ICugqLCvpZvFhcndnU6IDqd3YOlLrE755aZN45y5/xCT+46lwWuSLQZRCUUQIFjKzC978QXcKZEoflr9Ok5vFyW5CykrWKJ1OIIQEZH4DhPa4Fbf7aIs28HB9uCp250NXUmZ+HZ3d/PFF18AsHTpUjIy4r82q7u7m7/97W8cPXqUwsJCTfqlR3McnL6u8OVYtCtOZsU585maWYY34ESni94ZkoDso8fTjsvbw9TM0piUkBOEWHGmSCmzkED/Wa9k23wrCCAS3xFK+xNfVYWSLFs48d3d2KllWON28OBBrr76agA2btzI0qVLNYnhH//xHwFYsGABU6dO1SSGaI1DqFWxQWfCpNdms16ikiQJk8ES9TJvna5mttT+CYAMWx5pluT7EipMTqqqplziK5pYCMlMrLYfpnxQLd8s20B3nR0NyZn4CtEXWupgN2fE9LRlr6eD5u5a2vuOxewxkoVtWC1fQUgW3oCLgOIHwJEqia9oYiEkMTHjO8zMbAd6nYSsqBh0A0mNSHyFEJcvlPhmxvRxqho+ocPZQG7adHIcRTF9rGjx+PswGaxRL9JvNQ1UiHCLxFdIIqHZXkidpVGiiYWQzMSM7zBGvY6SrOCL2htQwte39Hlod3q1CktIEMHTlsHEN9bF6C1JVstXVRU+2PdbNu5+gSPte6J63zpJH/6wdXlF4iskj8GJb6rN+AYUHwHZp3E0ghAZkfiOIrTOt6XPg3HQCO1K0nW+QvTIip+C9BLSLbkxX2eabN3bvAE3an/9a5PefJKjIxf6ouHy90b9vgUhVkKJr9lgS5qyhCczuFRhsrw/CUKISHxHEarscLjTSUn6wAf47iRuZCFEh0FvYnHx+ZxRfiUFGTNj+lihDxe/7EVWAic5WnueGDSvGCyc+IoZXyGJ+PtnRFNlYxuIxFdIbmKN7yjK80IlzdxcNCOdg13BJQ47xYyvEEeDk0eP35nwbUI9MWpeEWI1BV+Xbn+v6IQlJI1F089lftFZ+OXUWSpnMQy8N/lkj4aRCELkROI7irLcgbWb2ZaBIdopNrgJcTR0VqUvCRLfgRlfszH6tZpDM76qquDxu4ZseBOERKbXGVKq9rRBb+JLc/4Bs9GGTnwBFZJM6rwSoyg04wtgMQxUdtjd1IWiqOh0ydN5Jz09nfPPPz98WasYzjnnHJxOp6YxRGMc6tr3oqKSYc0nw5YXrfBGZU6y04mhGM0GW9SrOgA4LFnkpRVjM6WnRPcrQUhWkiSJL55C0hKJ7yhmZA2UNJPVgevdfpnDHX3hzW/JYPbs2bz66quax/Bf//VfVFVVUVZWplkM0RiHw207cfl6mJY1N+aJr0lvQZJ0qKqC1++K6WNFg9sXnPGNxTIHgDRLNktKVsfkvgUhFty+XnyyB7spE4PeqHU4giAgNreNyqjXMTM7+G222xPAZhyYvRKVHSYvRZVx+4IVBeKx7ECSJKZkzKIwczYOS1bMH2+ivIHgjG8sNrYJQjI61nmAT6tf4y9Vv0ZV1ZPfIImoqoo34KbPIz4TheQiEt/jKOuf1a3v81ORP3BqfJeo7DBpuX294XJd8dqhvXj6eSyafg756TPi8ngTodeZMOrNIvEVhH4DrYpTb3lOdcsW/lr1az6reV3rUAQhImKpw3GU56Xz9r4G6np9rJ6Xz5ZjwW+1yTbj29rayoYNGwC45JJLyMuL7en548Xw+uuv09TURF5eHsXFxZrEMNFxCDWuALCZEnujmRaWzbwECG4+i5X2vgY6+o6hArOnLIvZ4whCNAy0N8/UNpAYGGhi4Scg+1KmRrGQ+kTiexxlOf1NLNwBSrMHZrCSrXXxkSNH+MEPfgDA/PnzNUl8jxw5wo9+9CMAzj33XE0S32iMQ6hVMYDNnDzrvOMtlmXG2vvqOdS6HaPeLBJfIaGpqkpfeMY3U9NYYmF4LV+HSHyFJCGWOhxH2aDKDpnWgU0Jh9p7cfkSv5mAEH2DWxXHomrB6I/ZxaHW7ext+BuKKsflMRNZqJavX/amVF1UIfV4/E4UNfhZMRkSX0FIFiLxPY7yQbV8dYPWZikq7G3uHu0mQooLJ75xrKfb5+nkQNNmjrbvwZPAlR1cvh7aeuvp83TGdBNPqJYvEN5oKAiJKLS+F8CRkonv0AY7gpAsIk58jxw5wre+9S0qKys555xzeP7552MRl+ZmZNkx9NfrbXd6ybAMzPom2zpfITrC6/VM8atFPLiWrzeBP1yauw/zRe0GPj74angDYCxYB429yydaFwuJa3DiG88vy/Fi0JnCTTkGN68RhEQXUeKrKApr164lKyuL1157jXvvvZenn36aN998M1bxacag1zEjK5h0HOp0sqhwoJzUblHZYdJRVZXyKUuZlXcKuWnxW6M8vHtbogrN+FiM9ph2crIa7Uj9b1si8RUSWWh9r8XowKBLvRq+kiSFZ33FjK+QTCL6hGpra6OiooL169dTUlLCl770JU4//XS2bNkSq/g0VZoTfFEfau9jXkFm+Hox4zv5SJLEtKw5zJ6ynLy06XF7XLPBikTwzEMif7iEkvJYlzKTJF24Y5TLKxJfIXHZzRlk2aeSZSvQOpSYCX0xT+Qv5YIwXESJb35+Pr/4xS9wOByoqsqWLVv4/PPPWb58eazi01RZf+Jb097HgimZ4et3JlllByF5SZIuvNwhsRPfgRnfWAstd3CLGV8hgZXkLmTFrDUsLj5f61BixmbKwGbKGLIkSxAS3bjLmZ133nk0NDRw7rnnctFFF435di5X4m7QGW56WrA8S2Ovh0LHwKmqVqeX2pYO8h0WrUIbM4/HM+SyFuM/OAav16t5DFqNw3gZJDOy3E2vqwuXy4Xb7QYI/z8R9Hm6kWUZnWqM+dgaJQuyLNPj7pzwYyXiWCYrMZbRkyxjOTPrVGZmnQok7md7soylED/jTnwff/xx2traWL9+PQ8++CB33XXXmG5XVVU13oeMO/ug0zfNx+qH/O5Pn+9i+ZTE71DV1dXFpZdeGr6sxfgPjsHtdmsew3jGoSNwCJ/qxKrLJEMfv6UOAD1+Jy7FRZP7GPrugbhra2vjGsfxqKpCl68dgDZfF/622P77uhUFq1qI0W+N2nMpUcYyFYixjB4xltEjxlIIGXfiu3DhQiA4g3frrbdy++23YzKdvIB1RUXFeB8y/jLa4a9HAUjLm0KevZFWpw+AHlMGFRWztYxuTCoqKjjvvPM0j+H000+ntraWkpISrFarJjFMZBy2HD2Mz+PG4cijojC+z2FDax/1nU7MBhMVsypwu92ajuVwbn8fzYdtAJROnU1eWuK3Vw5JtLFMZmIsB3S7W+hyN2MzpZNrL464XbEYy+gRYxm5ZJqgHI+IEt+2tja2b9/OBRdcEL6urKwMv99PX18f2dnZJ70Pm80WeZQaKS9QMOggoEBdr4+FU7P5S3UTAPvbXUn1tyQKq9WalOPmU5zo9XoyHXlxj39aThkOazpWo2PIYyfKWHqc3ej1wYYeGWk5CRFTpBJlLFOBGEs41tvGkc4d6HUGivPmRpz4hiT6WCqqTJerBY/fSaYtf0id7UST6GOZ7LxeL/feey8bN27EYrFw/fXXc/3114967N69e7nnnns4cOAAZWVl3HvvvSxYsAAAWZZ57LHHeO2113C5XJx99tncfffd5Obmhm97xRVXDLm/+fPn84c//GHMsUa0ua2+vp7vfe97NDc3h6/bvXs32dnZY0p6k41Br6PIEZzFPtjWw/ypmeHf7RaVHSYNX8AT7hJmM8W/HmeOo4jS/EoKs8rj/thjYdAZKUifSYY1H2uMqzoIQjJwDmpVPN6kNxnISoDNh95kZ91f6Ohr1DocQUMPP/wwu3fv5uWXX+aee+7hiSee4O233x5xnMvlYu3atSxdupQ//OEPVFZWcsMNN4TXiD/77LNs2LCBX/ziF7z66qt0d3dz++23h29fXV1NRUUFH3/8cfi/F154IaJYI5rxXbhwIfPnz+eOO+5g3bp1HDt2jJ/97GfceOONET1oMpnuMHGkx0d1Wy//cOrM8PV7mrqRFQW9LrGb39XX1/Pyyy8DcN111zFt2jRNYnj++edpa2vjn//5nykrK9MkhvGOQ6hxBQRLFAlDpVtzqZyxKq6PuefYx/S4W8lLK6asYElcH1sQTmZw4pvKgk0sjMiKX5Q0m8RcLhevvvoqzz33HPPnz2f+/PkcPHiQ3/zmN6xevXrIsRs2bMBsNnP77bcjSRJ33nknH374IW+//TZXXnklsiyzbt06li1bBsDXv/51fvjDH4ZvX1NTQ2lpKXl5eeOON6KsTa/X89RTT2G1WvnqV7/KnXfeyde//nW+8Y1vjDuARDetv7LDwdbeISXNPAGZ6rbEb5na1NTEo48+yqOPPkpTU5NmMTz++OP893//t6YxjHccXL6BxDcVOzAlo15PG93uVno97VqHIghDqKoyqMtjar9fBJtYJH65RSG29u3bRyAQoLKyMnzdkiVL2LFjB4qiDDl2x44dLFmyJHwmRJIkTj31VLZv3w7A9773PVatCk6ktLe38+qrrw4pmVtTU0NJScmE4o14c1tBQQFPPPHEuB8wUUuejMbtdrMo18q2FgugMtWmZ07WQAmzfQ1tTHckfkeewTOsWo1/KAZJkjSPASIbh87eFmRZxqAzEfAqyL74xq+qKvtbPsXrdzIlvZR041RgcpfnMdBf0sw1sZJmotRR9IixDHL7e/EHgpugDVjH9fxMprHUY0KWZXon+FqMlWQay2TV2tpKVlbWkAIHubm5eL1eurq6hiyFbW1tHXHWNycnh4MHDw657vHHH+fJJ58kIyOD3/72t+Hra2pqUBSFNWvW0Nvby9lnn83tt9+OwzH2ZXbjruowXsm2W/CCGRlcMCP4rb2jvpZfXzxr4JdyF1VVXdoENkaSJPH000+Hf9Zi/JM9hmb/IVyKC7OkZ9++fbEI76SOeKuQ8dHb6SXHEFxvnCjlebrlekDCIqVj1qXF5TE7A324ZBcel5e9zr0TXkeZKGOZCib7WLqUdlz+YALYeLSVdt34E65kGMtQuUW/u4Gq3sT9fE+GsUxWbrd7RFWv0M8+n29Mxw4/7rLLLuPcc8/l+eef5/rrr+ett97CbDZTV1fHtGnTeOCBB+jp6eHBBx/ktttuG/L5fjJxT3yTqZyZ2+3m870H+eEHdQA8+Hen8sbuOj6tbQXgS6X5PHrZMi1DPKm9e/dy0003AfDUU08xb948TWN47LHHhpwO0SKGSMeh78hBVK+NgrQZVEzV5vnrPHqIXk8b2WnplGSWJFR5nr/V7MQne8jLyqI0Lz7j09RjpKop+DosmzULk2F8zWREqaPoEWMZVNe5l55WGxISC8pORa/TR3wfyTSWlnYvte09GHRGKsoS7/M9mcYyUUQ6OWU2m0ckrqGfLRbLmI4dftyMGcGymA8//DBnn302Gzdu5Morr+Szzz7DbDZjNAbPtv/0pz/lqquuorm5mYKCsbUHH3fiu3btWrKzs/npT38a0e2SrZxItsXA4R4fPllhb5uL7PQ09ncGE2H/4Y6k+Huqq6vDl7WKNxSDqqqaxwCRjcOKsjU4vV0Y9CZsVm1id1gzcPk7kfGF37wToTyPosjI+NHr9aTbs+IWT6aah761P6EwBCb8uIkwlqliso9loNONXq/HakojzTGxMyDJMJbpniz0XXpUFExmAwb9yev5ayEZxjJZFRQU0NnZSSAQwGAIppWtra1YLBbS09NHHNvW1jbkura2NvLz8wH461//yrx588JJrNlsZvr06XR2BitpDV/SUFpaChBR4juukgRvvfUWH3zwwXhumnT0OomSrODi/eq2XuYP2uB2qL2PPq9fo8iEeLEY7eQ4isiwjn8X6YRjMATfsD2BxNpAMnhDS2iTSzwMrhfq8vXE7XEF4WSmZpZRXrCM4uz4n13TwuDXvdjgNjlVVFRgMBjCG9QAtmzZwsKFC9ENq3y1ePFitm3bhqqqQHAybOvWrSxevBiAhx56iNdffz18fF9fH7W1tZSWllJdXU1lZSV1dXXh31dVVWEwGMIzxGMRceLb1dXFww8/HO7cNhmU5gS/YQQT36G7dHc3dWkQkTDZWPrr43r8zvAbRiJwDyphZIljDV+zwYZOCs74ukXiKySQbPtUSvMrmZm3WOtQ4sJmyiAvrZjp2RXoxrGsQ0h+VquVyy+/nPXr17Nz507ee+89XnzxxXDFr9bWVjweDwCrV6+mp6eH+++/n+rqau6//37cbjcXX3wxANdeey0vvPACH3zwAQcPHuS2226juLiYs88+m1mzZjFjxgzuvvtuDhw4wBdffMHdd9/N1VdfTUbG2CuoRJz4PvTQQ1x22WWa1GLVSijxPdjWw7yCoYO7q7FLg4iEeJGVQEIkmqFZFVVVws00EoF38IyvKX4zvpIkYTUFTyOLGV9B0I7dnMGSktXMLzoroTu3CbG1bt065s+fz3XXXce9997L97//fS688EIAVq5cyYYNG4DgUoVnnnmGLVu2cOWVV7Jjxw6effbZ8DKUa6+9lm9/+9usX7+er3zlK+GN6TqdDp1Ox9NPP43D4eDaa6/l5ptv5vTTT+eOO+6IKNaI1vh++umnfPHFF7z55pusX78+ogcKScRyJ8cTKn+yOM8WLmPmdLkoybJR2xn8O7YdbcW1qEizGE8mLy+PBx98MHxZi/HPysriBz/4AZ2dnWRlZWkWQ6j7SyQxVLd+TkP3AdIteZwy7cJYhnhCqqxHlmUAup0dQGKU5+l2diDLMjpJR8CrxrXUW3nuaeh1RiwGx7ifU6LUUfSIsYweMZbRI8YyPqxWKw899BAPPfTQiN/t379/yM+LFi3itddeG/V+dDoda9euZe3ataP+furUqRMqqQsgqWOczvJ6vaxZs4a7776bs846i3/9138FGPPmti1btow/ygTzLx8c5aNjwVO8p+bb+OUFJdoGJMRMk38XLqUdi5RBoSn+1ShC/KqbOt8mAAoMC7DrczWLZbC2wAF65AYMkoVi02lahyMImnLKrXTLxzDpbGTry9BJid3ZUxBOZMmS1OyKOeYZ3yeeeIIFCxZw1llnTegBk62cWW1tLZbcKVz9608AeODSSpaXFvHRseA3mEO9fubOnZvS/dijIVlLyvTU7gOfjakZJcwt0O65q6gyU/tyMBtsSIqZ+qPHEmIsdx5rIOC0kWktoGJ68ry2Q5L1eZmIxFjCoTY3vR0+0MG80nnj/lxItrFsdx6j19OGXmdkelZibepLtrFMBMnWbyFSY05833rrLdra2sI1WEN12N555x22bds25gdMxnIiM3Iyqe314Q0o7G13s3haLhBMfLvcfroCEkUZyfd3aSGZSsooqoxPdqHX68l05Gket8MeTCyDp/WPJcRYluTPJ9tdgMXo0CyWgOxDknTodeMvS54IY5kqJvNY+tXg+0W6NQe7feJr3pNlLGs6GjjWtR+7OZM5RUu1DmdUyTKWQuyN+ZPi17/+NYFAIPzzI488AsCtt94a/agSjE4nUZqTxt7mbg629nDpvKFrenc1diZs4nv48GEefvhhAG6//XZmzpypSQwPPPAA3d3drF+/XpMmGuMZB7evD5XgSiC7eew7RieTKRmzmJIx6+QHxoDL18un1X/AL3s5dcZq8tOLNYlDEEL6vF3A5Hu/CG2+9YpyZkISGPMCpKKiImbMmBH+z263Y7fbI6qdlsxKc4M7yKvbepmTl8HgE1i7Gro0iWks2tvb+Z//+R/+53/+h/b2ds1i+P3vf897771HR0eHZjFEOg7O/g8xALspcT7IEqHKRCIwG6zhCheipJmgNUVVwhVG7OZMbYOJs1DiG1D8BGTfSY4WBG2N+9zgJ598gtlsjmYsCa08N1impbqtF4tRz+y8dPa3Bt/kdjV1ahmaECMuX3f4ciKU6TnUuoOj7XtAkUhjttbhaE6vM2A22PEGnKKkmaA5t68XVVUAcEzSxBeCtcYdCdq9TRBgAp3bmpubU3bH32jK8oIzvi19Hno8PuYN6uCWyDO+wvg5vcHE12pKS4jC7IoSwOPvwxPoS4hZ325XK1uPbKSq4W94A9qUCrKJWr5CghhyhmiSJ76CkMhE57YxKs8d6Ll+sLWXBYMS36qWbvyyokFUQiwpqowk6bCbMrUOBRjojCYrARQCJzk69vq8nbT01HKkfQ8S2lQ1sZmDM/Ei8RW0Fkp8JaTw83KyGNy10TOom6MgJKKIlzqEOre1tLTEIp6EVZY78EZ2sK2HeYNaF/tlhf0t3SyYmqVFaEKMLJx2DguKziYg+7UOBRg6qyKr2ndvC33A6SQ9Rr02y55CS1CCp5lVUVZQ0Ewo8bWa0sPttCcLg86EXmdAVgJixldIeBHN+IY6t910002xiidhTcuwYTEE38xq2obO+IJoXZyqJEmH0ZAYa9kHJ74BEiHxDX7AWYx2zRJOa3/iq6gy3kDydIUUUs/cqadzetkVzC9aqXUocSdJUnjWV8z4ColuzDO+Xq+Xe+65hx//+MdYLJZxP2AytiwO/f+8kixq2vvo6u2jyG5gXo6Ffe0eFGBbXSuXzS3QMNrjKysrC1/WYvw9Hk/4stfr1ew5oPU4TJSi6JBlGUVRCKhezVtw9ro6kWUZg2TWbDx1sjHcyrmju4VMW2SvQdHONHrEWIIRO0adfcKvh2QcyymOchS7TJo5J6HeX5NxLIXYGnPL4kcffZRjx47x85//HGBStywe7DvvHmZHq5szCx08do6oIzqaqqoqbrnlFgAef/zxpOje51fdBFQvJsmGDmPCnEKv9X6EgkymfgbZhvjXZB6s3vc5PtWJQ1dAvlGbf1NZ9XHE9wkGyUyuYTY2XY4mcQiCIKSaVC1gEPfObcmQ9IQMb3X47x9W8esvDpFpNfLedy/kjre2UtsdHIejTiUh/7auri42b94MwPLly8nMzIx7DAUFBTzyyCO0trayYsUKioqKTn6jKIt0HI607+RQ+y50kp6zy65NmMS3t/YAvZ4OZJ9X8xac7TU7MMgq07NLmJWrzXNfVVUq1AXox1l1Q7QzjZ7JPJayEgCkcT8Ph5vMYxltYiwjJ1oW94tW57ZkbBkYanWYk5HG/k4PdHrwSQbyMtPp9gVPs9Z1u/BJBjKtiVW/0Gazcfnll2sewzXXXENVVRVFRUWaPAciHQd/uxu9Xo/dnBmV1qPRYrdm4PR1IePXtAVnQPGjEAi2Z7VnJ+XrejDRzjR6JuNY1nfsZ/exD7Ca0jiz7CsY9Mao3O9kHMtYEWMphIw58R0+SxdKBiZL5zaA8ryByg7Vbb3MH7bBbXdjFytn5cc5KiEWQs0rEq0e58JpX8Kb6+fg/mpN4xjcmnRwKSNBmIxCFR0Csj9qSW+ycXq7qG7egsfvZMG0L026ts1C8hhXA4vJamgt354Rie+uRtHBLVWEmlckUqtiCFZQMOpNmi+9MBvtLJt5KQunnUOGNVfTWAKynx53G809tZrGIUxeocR3Mid7iirT2F1Dp6sJt69X63AE4bjGnfj+9Kc/HfPGtlRRmG7Dagyu4apu62VWjiNc4gwSs6TZvn37WLNmDWvWrGHfvn2axfCVr3yFf/mXf+HAgQOaxTDWcfAFPPjlYLmwyfxBdiIGnZEcRxFFWbMxG7U9fdjQdZBPqv/AtiMbCcg+TWMRJqe+/sR3srUqHkw0sRCSRcQNLCYznU6iNCeN3U1dHGzrQa/TMW9KBlvrOwDYnYAzvn19ffztb38LX9Yqhs8++0zzGMY6DqHZXgBbAia+iirjV939G2qEUBMLAJevl3SrqOwgxI+iyrj7OwfaJnHiG2xiYURW/KKJhZDQxFKHCJXlBZc71LQFT+XMK8gM/25XUxdjrA4nJLDQ+l5IvBnfXk8HHxz8L+p8m+j2TK7uicczOPF1i9bFQpy5vD2oBN/3J/OMb7CJRXDvj5jxFRKZSHwjVN7fuvhgazDxHdzBrcfj52in+Kab7EIzvgadEZM+scrfWAwDFSa8fu2KxG8/+h4fHfgdB5o2axZDiMVkRyK45tkl1hYKcTb4DFGibYaNt4HubeJzUEhcIvGNUFn/Brd2l5dOl5d5U4bOCO5MwOUOQmTs5gxy06aT4yjSfBPZcAa9Cb0uuEJJyxa9fZ5OnN6uhGgTrJP0WEzBD1yXmPEV4iy0sU2SdFhNaSc+OMUNzPiKxFdIXGKNb4TKBld2aOsdMuMLwZJma+ZPj3NUQjQVZc2mKGu21mGMSpIkzAYbvfTgDWj34RI6lZkopcxsxjTcvl6x1EGIOxUFo96MyWBFJ03uuSSx1EFIBiLxjdDwWr7LpufgMBvo8wY3GokZXyHWzIZgFQWtZlsDso+A4gcGPui0ZjWlg7NBzPgKcVeafyql+acSkP1ah6K50PtBQPETkH0Y9InV0EkQQCS+EStMt2Iz6XH5ZKpbe5AkifkFmWw62gYEZ3wFIZbM/et8tUp8PQnYvMJmDn4hdfv6UFUFaZLPvAnxN1kbVwyW65jOkpLVWIx2dDqRXgiJSXw6REiSJMpy+je49Vd2GNzIYn9rD96ArEVoQhT0ejo42PQ5xzoPhGc1E43WM76DT2MmyoxvmiWbLPtUCrPKRZk3QdCI1eQgL62YNEvOpF/2ISQu8ZVsHMry0tjZ2El1W/C06vxBG9xkRaWquZtTirK1Cm+I2bNn88c//jF8WasY/vd//5cjR45QXl6uWQxjGYdOZxM1rdsAyE8viUdoEQvN+PplD7ISCG92ixd3As745qUVk5dWrHUYwiTj9vXR62nHbs7EZkpPuM2wgiCMJBLfcSjLCW5wC5U0G9m6uCthEt/09HTOOOMMzWM47bTTyMjIIC1Nm13PYx2HUA1fk8GKMUHXp5kNNvQYSTPnEJB9cU98QzO+Bp0xYcdIEOKhrfcoexo+BuD8eddh1Js1jihxqKoqvggICUkkvuMQamLR6fbR4fKOkviKDW7JKlST025KrMYVg+U6pjPDfCYVMyo0aRfs7Z/xNSfIMgdB0IpzyBdlkfRCsMZ3R18D+eklLJh2ttbhCMIIIvEdh1ATC4CDrT0sL84ly2qi0+0DgjO+QnIKJ74J1rEtkcwvOouygqUJt4u9ve8Y3e5WjHoz07MrtA5HmAT6+mv4TvbGFYP5ZR8+2SNKmgkJS6w+H4fyvKG1fCVJGjLrm0gzvrt27aKyspLKykp27dqlWQxnnHEGX//619mzZ49mMZxsHBRVxt3f+csmPsiOS5J0WIx2HJZMrUMZoq6jigNNm6nrqNI6FGGSCDWvSOQzRPEW2vDqFomvkKDEjO84TEmzYjcZcPoCVA9a5/vx4RYAGnvctDu95Ni1P/Xl9Xo5cuRI+LJWMRw9elTzGE42Dm5fHyoKkPgfZD7FRbuzHq+aQZa9QOtwEoLNFDwT4/KKWr5C7MlKIPxFOdG+BGoplPh6Rfc2IUGJGd9xkCQp3MEtVNlheAe3RJr1FcYmtMwBEn+pQ1tgPzuP/ZnDbTvi+riKKuPxO1FVNa6POxahxDeg+PAHtPmCJUweoY2wIJY6DDa8iYUgJBqR+I7TQOIb/MY/b8rQREkkvsnH5esKXw4lUYlKLwXPJnjiPKvi9Hbx/r7fsHHPC3Q4G+P62CdjHfRvJjq4CbE29ItypnaBJJjBJQ7j/f4kCGMhEt9xCrUuPtjWi6qqo5Y0E5JLjmMaFVPPYFZeJTqdXutwTsjQn/h647yOLvRBpqoKJr0lro99MjaR+ApxFFrfq5P0WBOknnUiGNzURmxwExKRWOM7TqX9tXy73D7anV7yHBbyHRZa+jyAmPFNRmmWbNIsiVF/+WQMkhk/4A24UVQZnRSfRD0R2xWHWIw2JEmHqioi8RVizmHOYmpGKSqqaJE9yNDEV8z4ColHvFrHaXBlh+r24HKHwet8dzd1oSiJtw5SSA0GBjZOev3xa13s8YWaV5gw6I1xe9yxkCQdVmPwdekWia8QYwUZM1lcfD6nFF+gdSgJxaAzodcF3xt8AY/G0QjCSCLxHaehtXxHrvN1+WQOdfTGPS5hcgit8YX4zqqE2hVbErR5hc3cX9nBJ157gqAFSZJYWf4VVs2/nln5p2gdjiCMIJY6jFNBmgWH2UCfNxCu7DDaOt+y3MTeJCUE9Xk62VX/PnZzJmUFSxJ+c5tBo8Q3tGbPYkqsZQ4hhZllZNmmJM2SFUFIRVaTNq3pBWEsROI7TpIkUZ6bzrZjHeEZ3+ElzXY3dnHFwmINohuwcOFCtm/fDkBBgTb1XhcuXMinn35KdXU18+fP1yyGE41Dn7eTbncr3e5WygqWxDm6yOkxISEB4A3EM/Htn/E1JOaMb2FmudYhCJNAj7uNY537sZszKcwsx6A3aR2SIAhjJBLfCSjNTWPbsY7wjO+8YYnvzgTY4GY2myku1jb5NpvNTJ8+nb6+PsxmbZp6nGwcQqWJgutEE3M2czBJkshxTMdismCLU7MNVVXDia81QWd8BSEeulzNHGkPdqEUX7ZGUlWVgOLH4+8TZ1+EhCMS3wkoH1TLV1VVMq0mpmXYqO8ObjbaLUqaJY1Q4mszpSfNDu2Fhedis9ni9niyEsBqtOP2OzEn6BpfQYiHUCkzs8EuZntHcazzALuPfQDABfO+KcZISCjJ8QmfoELrd7s9ftqcwU5Rg2d9D7b14PIFtAhNiFCoC5MoRH98Br2Rs+Z8lVXz/4miBJ3lUlWV3fUf8vmhP9LQdVDrcIQU1df/RdmR4B0etWI2Dnwhd4tavpOC1+vljjvuYOnSpaxcuZIXX3zxuMfu3buXq6++msWLF3PVVVexe/fu8O9kWeaRRx7hzDPPpLKykv/3//4fbW1t4d+rqsojjzzCaaedxvLly3n44YdRFCWiWEXiOwGDS5odbB3ZulhVYW9z9/CbxdUXX3xBXl4eeXl5fPHFF5rFMGPGDC666CK2bt2qWQwnGofQDI49TssGkpkkSQk7Ky5JEq29R2h3NtDjbjv5DQRhHELvFzbxRXlUg6u+eEUt30nh4YcfZvfu3bz88svcc889PPHEE7z99tsjjnO5XKxdu5alS5fyhz/8gcrKSm644QZcruCZ8meffZYNGzbwi1/8gldffZXu7m5uv/328O1feukl/vjHP/LEE0/w+OOP8+abb/LSSy9FFGtifnoliVDbYgh2cIORrYt3Nmi/zleWZWRZ1jyGSL+VxSKG0cbBF/Dgl4Mz9vYkmsFx+bqpbdvFvsbPUFVtxzaRhFoXiyYWQiyE1q4COETiOyrRtnhycblcvPrqq9x5553Mnz+fVatW8e1vf5vf/OY3I47dsGEDZrOZ22+/ndLSUu68807sdns4SZZlmXXr1rFs2TLKysr4+te/zpYtW8K3/8///E9uueUWli5dymmnncatt9466uOciEh8JyDfYSHNHCzUXdN2nMoOTdonvsKJhZY5ANiSKPHt9Xawr/FTatt24g24Y/54Pe52OpyNuBO8Rm6oFF2ixykkJ5d34P1CLI0anUFnDDexEEsdUt++ffsIBAJUVlaGr1uyZAk7duwYMeG1Y8cOlixZgiQFqxJJksSpp54arrr0ve99j1WrVgHQ3t7Oq6++yvLlywFobm6msbGRZcuWDXmcY8eO0dLSMuZ4ReI7AZIkhZc7HOyv7FBRMDRxEhvcEp9z8AdZEi11MOsH1tHFY1altm0nmw+9ydYj78T8sSYiVEPU5etBVUX3RCG6QsscQCS+xyNJUni5g1jqkPpaW1vJysrCZBrYxJibm4vX66Wrq2vEsfn5+UOuy8nJoampach1jz/+OGeccQZbt27lX//1X8O3BYbcPjc3F2DE7U8k7lUdQus4koHb7R7y/9GcMS0Dp9OF1+PG5XKhA84ryeJYd/A2bV09PPbedm44Y3Y8Qh5VWVlZ+LJW4x+KQZIkzWOAoeOQYSpkyfQ1uH09BHwqchxbAI9H6PmoBnThpRvdfe2YiG2JsV53F7Iso8ec0K9jvWoOL2vp7u3AZLAe99ixvMaFsZksY9nR2xJ8HegMKH4JVyD6r4VUGEsDwddhr6tL0/eLVBjLROd2u4ckvUD4Z5/PN6Zjhx932WWXce655/L8889z/fXX89Zbb+HxeIbc94ke50TinvhWVVXF+yEnrLa29ri/+8YsK9+YNQsY+Nt+esbUYUfJmv3dkiTx9NNPh3/WIo5kiqGVffEKacIa61tw+YIfKDW1B2jTx/bDpcXXSEB1Y/D2UdWTuK9jj9KNq//Ly579O7DoTj6Lf6LXuBCZVB9LnyJjV4tRCLBvX2zfL5J5LLv9fbgUF353A1W92r9fJPNYJjqz2Twi8Qz9bLFYxnTs8ONmzJgBBDfNnX322WzcuDE8eeXz+cI9AUL3ZbUef4JjuLgnvhUVFfF+yHFzu93U1tZSUlJy3EF9c08d976zE4CNN5xPtt3CEx9V8avPD4049junlcd95nfv3r3cdNNNADz11FPMmzcvro8/PIbHHntsyDogLWLQahyiJfS8nDlzFp0Nu/HJHvKysinNi91rS1VVWqq3oKg2inNnMSM7cV/H3oCbrkP7AZg6JY8p6aXHPXYsr3FhbMRYRk8qjKW13U9jt4zNlEHFNO3eL1JhLOMt0smpgoICOjs7CQQCGAzBtLK1tRWLxUJ6evqIYweXJwNoa2sLL1/461//yrx588IdVkMNsDo7O8PXtba2Mm3atPBlgLy8vDHHG/fEN54F96PFarUeN+7puVns7wxOvx/pCzAtz8amht7wdYPd+qdd9MgS91y0OKbxDlddXR2+rNX4h2JQVVXzGGBgHIIdhnwY9dp0lJsIq9WK3ZKB7PGjSL6Yjqs34EbSgR496fashH4dW1UrRoMZRQ2MeVxO9BoXIiPGMnqSeSzn2U5j3vTTtA4jLJnHMtFVVFRgMBjYvn07S5cuBWDLli0sXLgQnW7oVrLFixfz3HPPoaoqkiShqipbt27lxhtvBOChhx7iiiuu4IYbbgCgr6+P2tpaSktLKSgooLCwkC1btoQT3y1btlBYWDhi3fCJiM5tE1SeN/Bt5mBrL+8daOT13XXHPf7fNgZnh+Od/Aqj8wZcvL/vN5j0FhZNP4/ctGlahxQRi9FOj6ct5pvbBm9QsSR4S2dJkqiccQFGvUVsPhIEQYgxq9XK5Zdfzvr163nggQdoaWnhxRdf5MEHHwSCs7JpaWlYLBZWr17No48+yv33388111zDK6+8gtvt5uKLLwbg2muv5T/+4z+YO3cuhYWF/PznP6e4uJizzz4bgK997Ws88sgjTJkyBYBHH32U66+/PqJ4ReI7Qbl2MxkWI90ePy9tPsjHh1tPept4Jr9LliwJn1YIlQ+JtyVLlnD06FGqqqo0W2JwvHEIVXTwyZ6knPUNtQ72BGKb+A4uSWRN8MQXIC+tWOsQhBTU3neMvcc+xm7JZH7hWUM6lAnCZLZu3TrWr1/Pddddh8Ph4Pvf/z4XXnghACtXruTBBx/kyiuvxOFw8Mwzz3DPPffwu9/9jjlz5vDss8+GZ+OvvfZa3G4369evp6OjgzPPPJOnn346PHP8rW99i/b2dr73ve+h1+v5yle+wje/+c2IYhWJ7wRJkkRZbhpb6jvGlPSGxCv5DXbZ0ibhHRyDTqdDp9NpFsvxxiFZa/iG5KUVYzJYwiW8YsXjG0h8xYe9MFn1eTpx+rpx+rpZPP18rcNJaKqq0u1uxet3YjNnkGbJ1jokIYasVisPPfQQDz300Ijf7d+/f8jPixYt4rXXXhv1fnQ6HWvXrmXt2rWj/l6v17Nu3TrWrVs37lhF4hsFZbnpbKnv0DoMYRxCM74mgxWj3nSSoxNPfnox+emxn920GB3kp80goPjR65LnbUNRZSS0+8IlpJa+/hq+FqMjqV4HWpAkiS8Ov0VA8VOaf6pIfIWEIV65URBqYmHUS/jlsRXM//GFi+Ky1MHn84VP8efm5o6onxcPPp+PxsZG2tra8PliuwnrRDGMNg6hLkzJ1LhCCwUZJRRklGgdxph1uVrYcfTPuP29nFn+FfGhK0RFqHmFaFU8NmajnYC3SzSxEBKK6NwWBWW5wQ1uflnlh186edmWeCW9ADt37mTBggUsWLCAnTt3xuUxR4th2bJlfO1rX2P37t2axTDaOIQ+yJJxmYNwfEa9Gbc/2LJYtC4WoiX0fmEX7xdjEtoI6xaJr5BAxIxvFJTlDqyv/PKC6TjMxvAa3uHimfQKJ6aoCq7+pChZP8hUVWVvw9/w+p0UZpUzJWOW1iElhMEb8Fy+Hg0jEVJFQPbh7e/SJqqFjE2obbFn0OZYQdCamPGNgvJBiW9124lnl3o8Y2+rJ8SW29eLigIk71IHSZJo6q6hpfcIPe72mDyGqqocbP6Cuo6qpEkidTp9eLYpWWIWEltoPwCIxHesQomvWOogJJKIE98jR47wrW99i8rKSs455xyef/75WMSVVHLsZjKtwTWjL22uPu5sL8AvPtzHve/siFdowgn4ZW/4jTmZlzoMzKrE5sPFF3BT07KVPcc+osvVEpPHiAVbf6ULkfgK0RBa5gAi8R2r0JfPgOInIItJHyExRLTUQVEU1q5dy8KFC3nttdc4cuQIP/zhDykoKGDNmjWxijHhSZJEeW4an9e187cEq+MrHF+mLZ9z5l4brFQg6bUOZ9zMRju9ng68MTqdOLiGbyjJTgZWUzo4G3F7ReIrTJyzv/ShQWfEbBAl/cZi8PuFx+/EkYSVc4TUE1Hi29bWRkVFBevXr8fhcFBSUsLpp5/Oli1bJnXiC+DyByI6XiS/icOgM2odwoRYDLGd8R3atS15El+bKbjp1OXvDbfHFITxKstfwvTsCjx+p3gujdHQxLcPhyVLw2gEISiipQ75+fn84he/wOFwoKoqW7Zs4fPPP2f58uWxii9p5NiSr+uXkBosg7q3qerYyulFwpO0iW9wqYOqKjFv6SykPkmSsBjtZNrytQ4laViNDnIcRRRlzcFosGgdjiAAE6jqcN5559HQ0MC5557LRRddNObbuVyu8T5k3Lnd7iH/P5GbT5vJnoZ22j3ymO77m0tKuO2s8riMR1lZWfiyFuPv8XjCl71er+YxeDweXC4XbX11WIx2rMb0pCpGP/x5KSkGZFlGlmV6+rqj3oij29mBLMuYDFY8bm9U7zuWJMWELMsYdEa6+zpQLSO/50fyGhdOTIxl9KTSWM4vODd4QdXm8yeVxlKIDkkd5xTRrl27aGtrY/369axatYq77rrrhMdv2bJlXAEmm2d3tvD87raTHnfpzAzuOb0oDhFpr7q6mrvvvhuA++67b0girlUMs0pnUuv7CIAcQxkZ+mlxjylaXEoHTf7g0plpxmWYdNGdlW3278WptGCW0igyLYnqfceSqiooyOgwiFPTwoQoqoyCHz1m8VwSJo0lS5Ln/T4S4058Q95++21uvfVWtm7desKuYKHEt6Li5A0eEoXb7aa2tpaSkhKsVusJj+12+zj/6XcBmDc1m9f2Nox6XGVhJtsaujAbdFTdegl59smxRCKSsYyHPm8nnx95A4BFRReQY0+eLyHDx9Lp7WLzkf8DYHHRBWRH+W/ZWvcnut0t5DmKWVB4blTvW2uJ9rxMZqk8lu3OenYe+zN6nYGlxWvC68djJZXHMt7EWEauqqoKSN3EN+LNbdu3b+eCCy4IX1dWVobf76evr4/s7JO3BdWiXe1EWa3Wk8Zts9lo8Sh0un1cXpnFj6fljihrtmx6Ds9/9XQWP/JHvAGFV3Ye40fnL4hl6AlnLGMZDz3+JvT6YCWHnIwCbCbtY4pUaCzNFhOVJauwGO2kWXKivtQhoHrR6/Wk2TIT4t8uFhLleZkKUnEsW1ye/vcLlaz03LgtjUqFsexyNdPR14iiypQVaJdIpcJYCtER0au3vr6em2++mWXLlrFnzx4yMjKorKwkOzt7TElvqivPS2Pz0XYOtvXy6nVfAhiS/Db2uJk/JZNzSgt4v6aZX356gH85Zx4GvegjEm+hYvSSpBvS5SsZ6XUGCjNjt3xkZt5i3L5esu1TY/YYsaKoMm5fH76Ahyx7gdbhCEmqz9MFBCuFJNN+gETQ2ltHTctWDDqjpomvIIRE9AqeP38+JpOJ2tpafvGLX7Br1y6eeOIJvvzlL8cqvqRSlpvO5qPtVLcGu7eFSpXtbuzkD7vqqO928UVdOzevnMv7Nc0c7XTy5t56rlhYHLOYent7w6ctKioqSEtLO8ktYhPD9u3bqa2tZfr06Zp86x4+Dq7+mpw2UzqSJL54nMiMnPlahzBuB5u+4HDbDox6M+fPu07rcIQkFWpekcyNbrQyvImFQdTyFTQWUeLb2dnJmWeeCcAPf/hDrFYrpaWl4vRBv1Dr4ur2nnDd0HsuWkyPx8cf976KT1Z4bddR/m31KUzLsFHf7eKpj/fHNPHdv38/q1evBmDjxo0sXbo0Zo91ohguu+wyAN544w3y8+NfDmj4OASygomvXXyQpTSbObgW0y978cu+qC8DESaHUOLrEB3bIja4BKLb30eaXpwdFrQVcR3fX/7yl/zyl7/kiy++4N///d9pa2sTdXz7leaGWqTKNPQMlE5Jt5g4f3bwNPFru+rQ6yRuPGM2AH+pbmJvU1fcY53sQksd7KZMbQOJkkOtO/ho///wafXrWoeSUKymgTMcbtG6WBgHf8CLTw6WQxStiiM3OPH1inraQgIQdXxPINL6f+WZZuZkBYt0H2pqJ2tQQ7B/WFjIoaZ2CPjYU9fCPywq4t827sQnKzz+wR5+vqYy6vGHiDq+QaFxkFU/Hl/wDViPOamekzD689Ll7qPH3YFBZ4rq39PSW0tr3xEsBgezck9NulJOkmxEloO1tTt7WjGoQ89OiRqf0ZOqY9ntbgk/h/SKJS7vF6k0lqqsC49fV187Nn1OXB8/lcZSiA5Rx1dD93xyjD/VdmM1SLx1+WwcJr3WIcVEVVUVt9xyCwCPP/645iXtAqqPzsBh/KqLbEMpFl1sSxPFQ4/cQFvgAAAlprPQSdF5LrUHqumW69FjYob5jKjcZzypqsph34eASrZ+FpmG2C0rElJTr9xEa2AfADNMZ6CXxHKZSKiqSq3vY1RksvQlZBlKtA5JGCNRzmyYhQsXAsEZvFtvvZXbb7/9hHV8Q7ROeiIxnvp/5z+1kW6Pn28sncUtZw/9W2/43adsqe9gbkE6/3XtWdyeVsCfnvkr7oDKFreFGxdHf2f+3r17uemmmwB46qmnmDdvXtQf42QGf9OeOnWqJs+B4eNw9qLL4x5DtIz2vGzrc+BqqAdgZsl0bKborF3e3dCMv89GuiWPiuLkee0O1nN4H25/L9kZ6cwpGPo3iBqf0ZOqY9nUY4KOHvyKl/kzF8XlrEeqjWVf7UGcvi6y09OZOyW+7yOpNpbxENoInqpEHd8xiKT+n2Q0s7+xl8+bekfcZnlpIf+9q4H9nR5aPApnz57G8uIcNh9t57nNh/nncxai00X/TbW6ujp8WYvxt1gGerSbzWbNngNaj0O0DX5eZko54brEkkGJ2t+nSD70ej0Oa0bSjlmaLRtfn4sA3uP+DaLGZ/SMZyxVVaXT1YTX78RstJNlm5Iwy2pm2RYya8rC8IbleEqV56XdmoFH7kWW/Jr9PakylsLERZT47ty5k5tvvpm0tDSsViuXXHIJ5eXloo7vIGV5aWw62kZNW++I3122oJh/fv0LAP5vdx3/7+wKbjpzLpuP/o0DrT28d7CRC+cUxjtkIQVYBtUi9kRxA4m7fy201ZS8tY5tpjTaIVzCTkgszd2H2d+0CdegzYc2UzpzpqygIGOmhpENlSiJeDIqyiwnx16Iw5KldSiCMPaqDqqq8stf/hKHw0FZWRn/8i//woYNG/jJT37CjTfeGMsYk0p5bnC9aHVbL4oydPl0cZadpdODC/tf23UUgKsXzyDPEWxb/OTH++MY6eTVKR/hUOsOulwtWocSNUa9ObyuN1qJr6IqeAPB+xq8MzvZpFmySbfkkmnNZ4Id2lOSqqp0OBtp7Kqmw9kY1zFq7j7MtqPvDkl6AVy+HrYdfZfm7sNxi0WIncKscmbln0J++gytQxGEsc/4Hjp0iB07dvD666/z5JNPct9996HT6dDpdHzjG9+IZYxJpay/pJnbL9PQ42Ja5tCE4YqF0/mirp2PD7fQ3OumIM3Kt1eU8+Cfd/NWVT2H23uZmRO9JhN2uz1cbs5u1yZ5sdvtLF26FJfLpWkMoXHoo4EDTe2U5p9Kpi3+NYVjQZIkLEY7Ll9P1BJfr39g97rZkLyJb3HOfIqTuAlHLGk526qqKvubNp3wmP1Nm8hPL9FsttXrd9HSewS7OZMMa57o2iYIKWDMr+K8vDyef/55KioqeOKJJwD44x//yN133y1OAQ1SnjdQIeBgW++IxPfyBcXcuWE7qgpv7KnnO6eVc8Pps3noL3tQVJVffnKAh9ZEbydlRUUFb7/9dtTub7wxvP7661RVVTFnzhzNYnj77bfx+J28v+83ANijtAEsUZj7E9/QLO1EDU6gk3mpgzC60GzrcKHZ1sriVWNKflVVRVHlIdfJSoD2vgZkxdffsctPQPEh91+WFT/egHtIwu2XfTi9nViNaZiNtnAsna4mzdpld7tb2XPsIwBWlv89DkumJnEIghA9Y05809PTOeuss8I/K4rCf/3Xf3HaaadF9IDJVDN1PPX/Cm0DZaT2NrSzonBoqaziNCNz8tLY39rL77cf5tpFReSYJf6uYipv7G3ghU0Hue2scmym1JpZSJRaip2u5nBNSZ2afDV84fhjWZazHF2uAZM+OrVGu/vawmOlBvRJOVYnkyjPy3hTVZU99X8b+PdVFWQlgIqKqioYDRb21H+CwxA8I7Kv+ZNwEisrAWQlmLwGFD+y6kdVVVZMuxoIjqU34OLzQ2+dJAZlSLtwVQnG0OftxC/7sfavW+/p68AiafMltaMn+H4hSTqQDXF7DaTa89IX8FDTtgVvwElJzmIyrQVxe+xUG0th4sadXf3sZz9j7969/O///m9Et0vGMhm1tbURHZ9p1tPlldl84Ain2T0jfn96vpn9rb38taaZz3fsxmHSc/FUI2/shU63n8c3buay0tTcBBDpWEZbj9yAKxD88Dp6qAG91KppPBMR67GUVR/paikB1UvNgdqkPrPjVrrwq070WLCPUkBf6+dlvLnkTlr89SgEUNQACkNnbM1SGm7Jzba9n2HVZXLYuwd12DHDHa6tQScZqK2tRVEDuHxDk0QdBnSSHgk9OvSoSPjUgbMKKgqKoqKi4pJ78PrcGCUb9UebaNeNfB+Nh1b/QVyKC6NkZf+++O/BSJXnpaIGqPXtBMDbZSBd3xH3GFJlLIWJG1fi+7Of/YyXX36Zxx57jNmzZ0d021Sv4wswO7+JzXUddGEe9e+9Pn0Kv9rzFwIKHCadv68oZu5clcd3dVLV0sObR1z86NLTo5JodHZ28tFHwVN1Z511FllZ8U+oOzs7+fOf/0xrayuXXXYZhYXxr1wRGoeAvY20qSZsZgcLShfFPY5oEHUpI7fl6AZcnlbyHDOoKBx4TU7GsdzX9Dc6uvYiy8EZMAnQD9vnbDVb0OuMTJs6hfy0mXjr61BVBb3OgF5nxKAzDbpsRK8zkm6YSt3RekpKSrBYLMz0zwj/TifpR7yfqarKptrXcPsHKuDYVBtOXxcBxQfISHqZivKFmi21cdfVIrtt5NqnU1EUv8+uVHxedlTvIqD4yc/JZmaOGMtElowTlJGIOPG97777+O1vf8vPfvaziFoVhyRjHb1I6//NKchkc10Hhzudo97ujDIrxVl2jnY6eetAM988fS4A3zurgpt/v4mdTd1sb3Fy5syJb7wa3Lhh48aNFBUVTfg+xxPDP//zPwOwYsWKIS2U4xnDTTfdxMX/uIzLr7mQgqzspHwuDjba81JVFbwBN0a9WWzEGSTdloXT34FfdY/6756KNT4Dso/2vmOYjfYhmziNJiM6nQ4JCSQJo96MUW/GoDOhk3RIkoSEDiRIdwRfJ2fMvvykjxdaBhAaSzsn3xA5f9qZw9YZ60nX5+L0duELuDEbLexofIdTZ1xIpi1+p8chmJh75T70ej2ZjjxNnh+p9Ly0WdJxertQNKrlm0pjKUzMmMuZATzxxBO88sor/PznP+fSSy+NVUxJL1TZoaatb0RJMwjuwL98wXQA3t53DLc/AMA/LplJusUIiNJmsZKZG/wwtpsztQ0kBnrcbWzc/QLv7/sN3e7kXcIRCzZTcK2929eTsiXNVFWl291KTcs2NtW8wZ/3/ifbjr5LXcfeIcdNzSijPH8ZeenFZNmmkGbJxmK0Y9Ab0en0wfWsUnDMsmxTYhpzQcZMKotXhf99IPj+mJ8+g7lTz8BksOILuNl86I+09h6NaSzD+WQPftkLpOb7RbyFao1Hs864IIzHmKeEampqeOqpp1i7di1LliyhtXXggzUvLy8mwSWrUOLrCcgc63YxPWvkzMcVC4t5/KN9uHwyG/c3ctmC6TjMRr65rJTHP9rH73ceoaF7CYUZ4htqtEg6ifTs4HimWkUHALPBhkowqYvGh8vfDv4vEjqKc+YzLVubahzRYjUHE6uA4scvezEZLCe5RXLwyz5aempp662jve8YPnnkWthu19AvQblp08hNm0aWvWDUqg4hc6asiMu67oKMmeSnl/R3bnNhNtrCnduauw+zo+6vmAwW0q3x/ZxxeQcanojEd+JCtcA9/j6NIxEmuzEnvn/+85+RZZmnn36ap59+esjv9u8Xs5ODhZpYABxs6xk18T1zZh55DjOtfV5e33WUy/pngG86cw6Pf7SPgKLy3GcHueeixXGLO9VJwHu/28Z5y64g25F6HfJMBisSOlSUCSe+iirT6wluQAmut0xug2cUXb6ehEl8I23Vq6gKukGVELx+J7vq3x9xXKatgFzHNHLTppNhzR31vkKzrYnQNU2SpFFLlhVkzOQ0UxqSJGE2xHd9Zp+3K3zZbk69L8rxFkp8vWLGV9DYmBPftWvXsnbt2ljGkjJCM74QrOV7XvnIN3S9TseX50/nhU3VvLmnHr+sYNTrKM9L56K5hbyzr4FnPz3IuvMXYDLoR9xeiIyqqhQUZyHpJKxSBhlxnj2KB0mSMBttePx9eCc4q+IZ1LzCakz+Gr7DE99EaFwy1uYRLl8Pbb11tPXV09HXwFlzvorZ0H/mwpwZPoUcTHSnkWMvwmgwjymGE822Jor0YYm7qqpUt2xhevbcIa26oy3NkkVJ7kI8fmfCfFFKZqF/q2BdZx8GvUnjiITJSux+iYEMqyk8m1vd2nvc4y5fWMwLm6rpdPv4sKaZ82cHE+Sbz5zDO/saaOp184ddR7mmMnH61Sej5u7D1Ps3c8W3zwCgMbCDjw60xX1WKx4sRjsef9+EZ3wHn440J3G74hCzwYZO0qOoMm7f8V+T8XKi5hFbj2xkZt4iFFWhrbcel697yDFtvfUUZQWr6UiSxOlll2PSW8edrB5vtjVRHWrdTk3LVuo7qqiccVHMvsRk2grivqEulVkHvY+4/X2k6bM1jEaYzCLa3CaMXWi5Q3Vbz3GPOb98Cmnm4Ga213YNbNxYPbeQWTnBb8dPiU1uExJKMAIMXfsY6k7V3H1Yo8hiY2Ad3UQT34HbW1Ig8ZUkCaspeCZm8AyrFk7Uqtfl66XT1cT2o3/mSNvuIUmv3ZzJjJyFpFmGJgxmgy2hZmjjxRtws/nQmzR2VWsdijAG6dY8KotXcVrp5UPOwAhCvInEN0ZCyx2q244/u2Q26Ll0XrC82Ou768IVIPQ6Hd89I7iZ6G+1rWyrj3+x71QwPMHIyneQMzWdgOoNX7e/aVNK7fKPXuIbnPGV0IVPqye7oszZzMo7hYL0Ek3j6HQ1HTf51kk6UFUUJRBcnpM+k/lFZ/GlOf/AWbP/norC00ec+p9sSvMrOaX4AnSSAUWV2VH3Fw42f5FSr+NUZDJYKMiYSaYtX5RaFDQlEt8YKc8LfqOtae8dtaRZyOULiwFo7HGzua4tfP03l5diNQbX9j75t33jjiM7O5srr7ySK6+8kuxsbU4tZWdnc9lll3HOOefEtYHG4ARDp5dIz3TgSLcxaG8QLl8Pna6muMUUa+ENJAEXinriTlsnEkqczcbUmU2clX8Ks6csJz99hqZxhDb3yEoAl68XBr09mPQWLKY00q25nFJ8PpUzVjE9u0KzBg6JakrGLFbMWhP+UlbTspUddX9GVgJRuX+nt5ttR97lYNPnovyWIKQYkfjGSGjG1xtQ+Jc3vjjucRfPLcRsCP4zvLZzYLlDts3MtUuC609/u7WWdqd31NufzKxZs3j++ed5/vnnmTVr1rjuY6JmzZrFk08+yZ133snMmfFbUxtKMLx+F161F7vdht1mw2ZxDDvONdrNk5LZYMegM2I3Z+KXx1+NITTjmwob2xKN2WhHVgL0uNvx+HqHzP7qdHpspjQMehMWkeyeUIYtj9PLrgjPgDd1H2LToTeikqj2eTpo7jlMTeu2qCXTwgAxOy9oSSS+MTK4ssPjH+3j3nd2jHqcw2xk1exgaa3Xd9cNeUO46czgcgdPQOalzWIdW6SMegtObxdObxeoKkgSNnMmJv3QHdpmY2qcyofgTNgF8/+Js2b//YTKP4WSh1RY35to9JIBp7cLtX9GXqcbWbUlHs0jUoHFaGfFrC9TkB78Qu329aIo4z/TERIqZSZJuvDacGHi9jV+yvv7/putR97ROhRhEhOJb4z8744jQ37+t407j5v8XtG/3KG6rZfdTV3h6xcXZnPWrOCO5ac/2Y+sKLEJNgW5vD3sa/wsPOup0+lJt+RiMdqCBX37pVqCEa1lCStmfZmz51xD+ZRlUbm/ROCXvexr/IytRzbS6dRmeUuXq5nPD78V/kIRLEc28stFvJpHpAK9zsApxRdQmn8qpxSvwmae+MYpZ3/iazOlD6mbLEyMX/bh8fdpvsFUmNzEKzoG7n1nBw/9Zc+I64+X/K6ZPw29LvghN3i5AwzM+tZ2ONlQdSziWBobG3n88cd5/PHHaWxsjPj20dDY2MjTTz/N7373O5qaYp9wyEqAzw79H33eDmymNIwGCxZ9Bk2NzdTX1+P1DiwBEAnG6PQ6AzZTekrtvtZJemrbdtLSU0uPu+3kN4iy9r4GPj+8gYDiw2ywcUrxBWTZh37pspnSqSxelXJl9mJNkiTKC5aSM6wxTVtv/bhOq4cSX4fo2BZVoomFkAhE4htl976zg3/buPO4vx8t+c2xm/nSrGC9yNd31w353RULiylMD56yfmIcpc2OHTvG+vXrWb9+PceORZ44R8OxY8e4//77ee6552hoaIj54+l1BsoLliIhsXDaOZxV/veoPgO1h2upPVyLz+dN6QTD5euhve/YiFa1k51eZwhvhnLFuZZva28dW2r/hKz4kSQdp8xYxbyilZw1+6ssn7WGxdPPZ/msNZw1+6sp+ZzUQn3HPr6o3cDOur9EtE5XVdVw4itaFUfX8CYWQurwer3ccccdLF26lJUrV/Liiy8e99i9e/dy9dVXs3jxYq666ip2794d/p2qqjz77LOcd955nHrqqVx33XVUV1cPue2cOXOG/HfllVdGFKtIfKPoZElvyGjJb2i5w46GTg61D3woG/U6bjgjWKz+vQON7GseWsxeCBr+wTYtay5nll/NzLzFTMmcxTTjMl57/hM2/s8WphoWp3SCsePon/n88Fscbht9ac3JBBQ//oA3JTeghGaw3XE81SorAXbVv4+iyugkA0tmrA6XVAs1j5iaWUq2fao4+xAlqqpQ1xGshtPYXcPmQ2+OedObL+AmoPgBkfhG2/AmFkLqePjhh9m9ezcvv/wy99xzD0888QRvv/32iONcLhdr165l6dKl/OEPf6CyspIbbrgBlyu4yfyVV17hxRdf5O677+b3v/8906ZN4zvf+Q5utxuA6upqKioq+Pjjj8P/vfDCCxHFKhLfKBlr0hsyPPm9bOH08OXXdw2d9f32inKM+uA/1dOfiIYWw7X3HePD/a/Q3jcwoy1JEg5L5pCfG2s7qN7ViEWXmdIJxkRr+TZ3H+bPVS/z3t6X8AfGV00kUVn7E994rjHU6wycOuMizAYbS2deTG7atLg99mQlSTqWzbo0/AWj293KZzWvj2mJS2hjG4jEN9oGd4EUyx1Sh8vl4tVXX+XOO+9k/vz5rFq1im9/+9v85je/GXHshg0bMJvN3H777ZSWlnLnnXdit9vDSfJrr73G9ddfz7nnnsvMmTNZv349XV1dbN26FYCamhpKS0vJy8sL/xdpmVSR+CaIogwbK4qDZXkGd3EDmJJu5SuLgjPCL39+iF6PP+7xJSJVValp2cbnh9/CG3Cxs+4v4ZmayWyiiW/odoqqYNCbohZXIrCFu7f1xnVGO9OWz9lzrkmq1sDJzqAzckrxKmblVQLB5/VnNW+ctFujUyS+MTO4PKJbJL4pY9++fQQCASorK8PXLVmyhB07dqAM25S/Y8cOlixZEp58kiSJU089le3btwNw++238+Uvfzl8vCRJqKpKb2/wTHhNTQ0lJSUTilckvlFyz0WL+fGFi8Z8/I8vXMQ9Fy0ect3l/bO+n9S20tgztLbszSvnAtDr9fNfWw5NMNrk5wt42HLkbQ42fw6AUW9mftGXMOiMGkemPXP/h4vX7xpXcje4lFmqzYyHdvwragBvIHb1m2vbdlHfMfTsjOhWFX+SJDF7yjIWTT8XnaRHUQNsO/ouNS3bjvvaKMiYydKSi5lXuBJjin3x05pBbwq/R3vEUoeU0draSlZWFibTwOslNzcXr9dLV1fXiGPz8/OHXJeTkxPe+L506VKmTBnY9Pvqq68SCARYsmQJEEx8q6qqWLNmDeeccw4//vGP6euL7LkU93fi0DqOZBBaUxL6/8ncdlY56XqV5z47eMLjvnNaOTecUT5iLNbMyedXnwRrzL675whfWTzQYWpRno3L5uazr7mHP+48xDdOmTbmpKSsrCx8WavxD8UgSdKEY+jxtLGn4X08gWCClm7JZd7UL2E1OE5434kwDtFwsuelJOuRZRmQ6ertiLieb6+rE1mWMWBJ6nEajSSb+scGOnpaMNO/5neMr/GxONKxi0NtW5GQkAMKeQ5tO8XFS6Tvl/GUaSpi4dQL2N3wV3yymwONn5NhmnrcqiU2fQ42a45mz/9EHsuJMkgWvLKHPldPXMY3lccyUbjd7iFJLxD+2efzjenY4cdBcHb4oYce4lvf+hZ5eXn4/X7q6uqYNm0aDzzwAD09PTz44IPcdtttPP3002OOV1LjdL5vy5Yt8XgYIYWpqkqP0kBHoBq1v89rur6IHH0pkqi1GeZWumj0bwegyLgEsy6yAvz1vi/wqX04dAXkGytiEKF2ZNXHEd8nAOQZ5pKmj14NZ1VV6ZQP0yUHlyoZJAtTjYsxSuNvJCJEV0D10OTfTaa+GIc+/+Q3EKLOr3rQY0AniTMgiS40y3oyf/rTn/jJT37C3/72t/B1NTU1XHLJJWzatInMzMzw9WvXrmX27Nnceuut4et+9rOfUVNTwy9/+cvwddu2beM73/kOZ5xxBr/4xS/Q6YKf8X19fZjNZozG4JmD3bt3c9VVV/Hhhx9SUFAwpnjj/syrqEieD1K3201tbS0lJSVYrZF9eD3zyYFRZ34vWzCdu0+wJOKXn+zn+c+q0esk3r3hAtKtA9+MPP4Alz73F7o9fs4pK+CRLy89aRx79+7lpptuAuCpp55i3rx5Ef0d0TA4hscee2zIOqBI9Hk7+OLIF1hNVvQ6A3PyT6cgfWxtmBNhHKLlZM9Lt6+X7toDABQVTiHPURzR/bfX7MAg25iWXUJpbvK8XsdCVVVyemxYjA4c5mwCPmXcr/Hh91vd+jm+rjZs2LCZ0llcdOGk6nw3kffLeJqvLh7RlMIvezHqzSiKQrenBZ/sxqy3kWHN12S5T7KMZTIQYxm5qqqqiI4vKCigs7OTQCCAwRBMK1tbW7FYLKSnp484tq1t6CbTtra2IcsfNm3axI033siZZ57Jo48+Gk56ARyOoa3cS0tLAWhubk7cxNdmi097WFVV6XQ14fU7MRvtZNmmjPsNzGq1Rhz3Dy44hR5ZCld6OKUwi+0NnTzycTXfPKOCOfkZo97uvIoZ3PanYE27dw938PWlA4mdDThnbjEP/3UPB784yo8uPJUZ2Y5R7ydkypQpXHLJJeHL8Rr/4TGsWrWK9vZ28vPzxx2DzWZjtm8Zjd01VBavwmEZ+07ORBiHaDve89JsMaHX97fB1QUi+ltlJYBCAL1eT4Y9KyXGabhS+8Da+tCp1vG8xkNUVWHPsY9p7D2AXq8nzZLN0pmXhGsGTzYTGUsttPQcZWfdnynKnktD5wFaemrR6Qw4zJmkWXKYM2WFZqUPk20sE5kYy9ipqKjAYDCwfft2li4NTsht2bKFhQsXDklaARYvXsxzzz2HqqrhjWtbt27lxhtvBODAgQN897vf5ayzzuLnP/95OJGGYCmzq6++mjfeeIPp04N7oqqqqjAYDMyYMfYlZSl5rqG5+zD7mzYNKVlkM6XH/Q1s8Oa1f1pexpwHX8cnK9zz9g5e+cbZo95mcWEWJdl2ajucvL776JDEF+CGM2bzyPt7UVSVZz49wAOXnnrCGKZNm8b69esn/LdMxLRp07jzzjupqqqiqKgootu6fD1D1uGV5p9KSd6iiDexJcI4xIteZyDHUYRBZ8RqimyZw+BKEBbjib9UCcHKF7vq/kpjdw0A6dY8lpZcjMlg0TgyYSwCip9d9e/j8vWwrfYdjHozqqoiy35AF7z+6Lsp2+xGK7ISwON3YjU50El6rcMRJshqtXL55Zezfv16HnjgAVpaWnjxxRd58MEHgeDsb1paGhaLhdWrV/Poo49y//33c8011/DKK6/gdru5+OKLAfjxj3/M1KlTWbduHZ2dneHHSEtLY9asWcyYMYO7776bO+64g56eHu655x6uvvpqMjJGn0wcTcotjGzuPsy2o++OqNMZegM7WSmbaLvnosXcc9FiirPsfPfMYCOKV3ccYVt9x6jHS5IUbmbxzr4GnN6h5blKsh383bxg8vj8Z9V4/HIMo9eOrATYc+wjPj7wKj3u9vD1kiSJyg1jsGzmpVTOuJD89Mg2VgUUHxajAwldyp+mj8b2hi5nUzjpzbJNYdnMS0XSm0QMOiOVxavCX/j8cn/daklCPygh29+0KSUbumihra+ed/e8yEcH/genVzRkShXr1q1j/vz5XHfdddx77718//vf58ILLwRg5cqVbNiwAQguVXjmmWfYsmULV155JTt27ODZZ5/FZrPR2trKtm3bqK6u5pxzzmHlypXh/zZs2IBOp+Ppp5/G4XBw7bXXcvPNN3P66adzxx13RBRrSs34qqrK/qZNJzxmf9Mm8tNLNFm39a/nLeD5z6px+gLc9adtvPWd80c97vIFxTz2QRVuv8w7+xu5ctHQNZo3r5zLG3vqaXd5eWVbLd9cXhqP8OPG5eth+9H3wsXm9zd9xrKZl2oc1eSQYc3jnLn/gKoqQGqVMgtp7T3KgabNuHy9rJgRWavL4bIdhSwo+lJw+c2MVeJLWTKSwG7Oos/THu4AqZcMQ57+Ll8Pna4mUYc5CgYvAfL6naRZsjWMRogWq9XKQw89xEMPPTTid/v3Dy3tuGjRIl577bURx+Xl5Y04dripU6fyxBNPTCjWlJrx7XQ1hWd6VVUlIPvw+IeWSwm9gWkhP83KP58d3Cz09r4GPjrUPOpxp5fkUpAWnDV6fffREb8/v3wKc/ODp/+f/Nu+E85EHD16lNtvv53bb7+do0dH3lc8HD16lDvvvJP/+I//oK6u7oTHtvQc4ZODfwgnvXlpxZwy/YKoxKD1OCQTSdKlXA3fEAmJXk8HsuKPSi3RadlzWFpysUh6k5TX70Sv05NuzcXYP1tvHGXW3utPrdJ+WhFNLAStpVTiO7gFojfgosfdhsvbhaIqw47T7g3sX86ZR1Z/pYa7NmwfNWnV63RctiC4cPuPe+rxBYYuZ5AkiZvPDDa02Frfwaajx2/D2dLSwvPPP8/zzz9PS0tLtP6MiLS0tPDyyy/zxhtv0NraOuoxiqpwoGkzW4+8Q0AJ1vMrL1jGqTMuwmgwRyUGrcchnpzebo627+Vg8xfiFO0w1kFrxt3+3ohu6w94+fzwBrpcQ59DqfolYTIItdGVJB1plmwybQXYjCPXxpuNYmNUNIgmFoLWUirxHdwH3KAbKAMWkH3DjtPuDSzDauJH5y0A4OPDLby9r2HU4y5fEFze0O3x837NyJnhry+dRZo5+Obx5McnPjWQ6Lx+F58ffotDrdsBMOktLJt5KaX5lSKhGKcuVzN7Gz6mpmXrwLrFMeh0NtHlasEbSN1i71bTwIxTJB+83oCbzYf/SHtfPVtq/4TLF1nSLCSmLNuUIRtodTr9iFU+NlM6Wbbo1Xye7MwTbKsuCBORUonv4Dcwvc4A/UnT4MQ3Ed7Abl45h6npwXqCd/9pO4oyckbu3LICMizBxPa1XSNPzadZjHyjv+LDqzuO0NybvIlKu7OBTmcjEPw3PKP8KnIckVV/EIYavDEtkg+XvQ0f81nN6+xv/CwWYSUEnaTH2j+j5/b3nOToII/fyeZDb9LrCW60nJJROuSUrZC8JElizpQVJzxmzpQV4kt4FIUqxojEV9BCSiW+g9/Agrv/g7O+oVPnkBhvYDaTgTtXLQRg27EO/nfnkRHHmAx6Lp03DYD/212HrCgjjrnpzDkA+GXlpG2StaSqKlNLsilbVIiXnhGn3gszy5ieXcHM3MUsm/V3KV9NIB7Gm/i6fX39t0/tpC5U5s09hhlft6+XzYfexOntAmBm7mLmFZ6p+fuIED0FGTOpLF41ooWxzZQuSpnFgCU84yuWOgjxl1KJLwx9AzPoQ4mvH6sxLaHewL61vIyZ/c0n7nl7BwF5ZGIbKmvW3OvhsyMj1/HOLcjg/PLg7PUznxzAP8p9aK25+zD1/s1c8e0zuPDvT6WNPXyw77+pbtk65Lh5hSuZM3XFiI5KwviYDQOJr3eMHy4B2R/+kpjqXz5CCY7nJGt8nd5uNh16M7xptix/CbOnLBdJbwoqyJjJWbO/yvJZa1g8/XyWz1rDWbO/mjCfGanEMmipg9iDIMRbSmYZoTewU6afj92SRZolm4XTzk2oNzCTQc/61cEGFwdae/jPLw6NOOaiOVOxGIK1JEdb7gDwvZXBTW4NPW5e333iignxFqqpHMATvk5BpqnnEJ8f+iNH2/eGrxeJRHQZ9MbwGY+xzvgOnn1J9RnfgcS377gfvL2eDjYdeiM8LnOmnEZZwRLxXE1hkiSRbZ/K1MxSsu1Txb91jFiNaZgMVuzmDBQ1NWvRC4krJRNfCL6BFefMw2ywYtSb6XaPXjpMS1+rLGH+lGC3kX/buGNEMwq72chFcwsBeH1X3agf0JfOK+L/t3fe4XFUV///zPZd9V4s23KTLHdjYxuwwabYpgZISAh5Ewg1oeVHSADDGzqYGhLgpYeEBAKh99jYVFNsg3uRZcmyLMnqvWzfmd8fq13tSitpV15pV9b9PI8e7czemTl79s7Od+6ce874JPfd81Nf7xtii4MnUE5lU7weB53IsgtFkdld+aW42x9CvKMqzuCymPgKZKPu6B7x9a1o58IesE1Nayn2rkl+07IXMyFt1rDYJhAc7eQk53NywS85fvL57vk4AsEwctQKX3CnTfEkx242R5/wVatU3L1yDgAVLWae+25/rzaecIeDTR3sqGru9b5apeK3x7tjfb8qrWNngDaRwD+nMiSmxZCYGgsoIEnE6BNRqdQRy6k8Ggh1AolfuWLN0T3imxY3lpPyf86Jk/8HjRQ4Xd7k9HmMS57GzJyljEuZNswWCgQCgWAoOOpvtcYk5WF1mEmN0iwBP5oxlgXjUthc3sj9n+7i1wsmE2foToR/1rQxaFQSTlnhnV3lzBnTu8rNpQsnc+faHVidLp76pohnLljkfW/cuHE89NBD3tfDhW9OZZVWJiUtEVlRUKu0JBhTUXflcRyunMqR8kMkCXUCiaedStJ44+OPVjRqHRq1DnOP0XBFkZG64swlSWLamMWRME8gEAgEQ8RRPeILkJs6i6lZi0iNGxtpUwIiSRL3nj4XgPoOG49vKPR7P8mkZ+lk9wS2d3cFjuFNidFz4dxcAF7ZWkqzuTtva3p6OpdffjmXX3456enpQ/AJAuPJ0+h0ObDLZnR6HXqtgQRTmlf0utsNT07lSPkhkqTFjWVC2mxyU4N7RO8RvkZtzKiIbVQUhRZzLR2uOlrMte6qgSVviwpdAsEw0G5toq6tnFZz4KJGAsFQcdQL35HAKXlZnNwlbh/5Yi9NZv+CA+fOdIv23TUtFNcHzjt6zWJ3uIPZ7uIf3x8YQmuDI8mUiUEbS4etGRQFCQmtZELyyQwfDTmVj2YyEiaQn7mQsclTg2ofa0gmJTaHpJij/zupbT3IV0WvsbXiY2qdu9h86D0+K/wXjR2H2XroExF7LhAMMdvL17P10BrKm/YO3FggCCNC+EYJ954xB4A2q4OHPtvj9965M8Z6anH0Oep7TE4Kx+emAfDUN0UBi2IMJ5IkkZe5AK3aHT9p1MWjktR+baIhp7Kgm9zUmRw74Qxm5JwUaVOGFE+2kfr2clqtddjkDjrtLciyk05bK2lxY0W/FAiGGFHEQhApRoXwrW0rY0vZGjYdeD/SpvTJwvFpnDPdXbDiya/3UdXa/bg1K97EcePdoravtGbQXdCitLGDNUXuUsjFxcVcdNFFXHTRRRQXD2+Ri+zEySye8hNi1GmUFh/i4MGDWCzWiCSFj6QfBNGDb7YRlcp9I6agAAqSpCLOkEJVS7EY8RUIhhhRxEIQKUISvrW1tVx//fUsWLCAJUuWsHr1amw228AbRhiLvZ369nKazTU4nNFr7z2nz0GSwOJwcd/6XX7vnTvDHe6wqbyBw62BYxB/PGscGXEGAP6vK7VZa2sra9asYc2aNbS2tg6h9YHJSJhAtrSAFx/6iDef+5wkV35EksJH2g+RQFZcFFZ9x7ZD66hr610dcDTim21EJXXP7ZVQE29MQaPWYra3iWwjAsEQI4pYCCJF0MJXURSuv/56LBYLr7zyCo899hiff/45f/nLX4bQvPDgG0cajWnNPMzISuKiY9yC8IWNxZQ2dleVOndmdyaC9/oId9Bp1Fy5KA+ANfuq+owHHkpcspPdlV9htnfbLkkS1WVNlOyqRk+8eIw8TEioqGwupLbtIG2W3pX/fLE6OjlQt43DzfuxO639th3J+GYb0an1SKiQUBFnSPabdCkmuAkEQ4sn1MElO3DKjghbIxhNBC18S0tL2b59O6tXr2bKlCnMnz+f66+/ng8//HAo7QsLccZk7+hOS5SP5NyxfLY3fdlda3d6109KjWNWVhLQf7jDlcdNQaNyC8unvy0aWmMDsL9mE5XN+/i2+C06baNjZDVakSQJg6Z7VKU/2q1NFNd+z67KL7AFWfBiJKL3KcWsUqlJMKZjUPWOPx+ubCMCwWjF6HMuinAHwXAStPBNS0vjhRdeIDU11W99R0f0d1iVpCbR5I6RjeYRX3AL3MsXTQHcqcl2V3cXpDivK7vDl6W1NHYGDtnITjBx/iz36PA/Nh/A7JCH2OJuatvKONTonpiXGJPhLQsriBzd1dv6F75+xSuO4nLFSabMAfulyDYiEAw9ej/hKya4CYaPoIVvfHw8S5Ys8S7LsszLL7/MokWL+tkqekjsupC1muujvjb4bafOxKBRoyhw+5od3vWecAeXrPDBnso+t7/mBHf6qlargzWHWrHOWYl1zsohtdli72B35ZcA6DUmZuYsFSENUYC+S8TaBriweEZcNCot2qO4eIUkSeRnLuy3jcg2IhAMPUafG2whfAXDyaArtz388MPs3buXN998M6TtzObIPEY1qhNwuVy4cFHXfJh4Q+qA21gsFr//w0WiFv53WT7/+qGUfYfr2XzgMDOykpiUoGNicgylTZ28teMgP52RFXD7uRkxzMxMYFdNK8/trMc293QAnt9Vz7Rp4fe/rMjsqPwEq92MhERe1nG47Apmu/tYVmt3zKjNZotIH/C1wWq1RqwfhoNQ+qVK0eJyuei0tvX7mds7m3G5XBjUcSPaN8EQp82gIGMJB+q30uloAdw38kZtPJPSjiFOm3HU+2AoiNTv5dHIaPFlgj4DrVqP5NIM2Tk3WnwpCJ6QhG9tbS333XcfX3zxBTabjaVLlzJ+/PiQDlhYWDhwoyHApTi8QmxvyVYS1MFXcisrKxsiq/pmeRosP32ie6GlhsIWd2zy8RkGSps6Wb+/hi0792DSBh60P3uciV01rTTbuke3X9jdAHzJlbPCW7ms2VlGs6sMgET1eGoOtVBDi/d9X/9VV1dHpA/42lBWVobRaBx2G8JNMP2yzdXYVZbXzJ69u3vFsnqodlRgkc0oVn3EztHhJl7JR6e04tLYUbt0GCwJNFSYaWB0fP6hIhK/l0crR7svdbhTeNa2tFLL0M4JOdp9KQieoIWvJ6tDXV0dDoeDa6+9lg8++IC//OUv3HzzzUEfsKCgYFCGhgNz2UE67S0kJyaQlz6wHRaLhbKyMnJzcyMilF7YWMwz3+4H4KkfL2DB+DQuiUnn5cIvsMsK5aoEzivICbjt65W7gere+9zdQFpaGreePC0sNraYa6it/B4TJhKM6czJWYFK8hfjvnfaWVlZEekDvjbk5uZGtB8eKaH0y4aOWMxVhwGYkDuuz/jWtrIiJLuJrIRxTM0Yub4JlUif40cTwpfhQ/gyfAhfhs7RPvgRtPD1ZHVQq9U89thjrFy5kgkTJvDggw+GJHxNpsjNlp43cTl6TQw6jSGk7YxGY0Ts/vXx07j/yyLqO2ys+mQP315/Oifl5ZAVb6S6zcLH+2v5xYK8XtvdtXYHj3zVd0aH1Z8XotVquWPF7CO2sbSpEpVahUalY96E5Rh1vSdGzZgxg3/84x9UVFRQUFAQEV/OmDGDV1991fs6kv0wXATTLxOlFNRq9yivpHEFbK8oCk7FilqtJt6UdFT4JlQidY4fjQhfhg/hy/AhfCnwELTw7ejoQKVSceWVVzJv3jzq6+tpa2ujvb194I2jhDhDSqRNCIk4g5ZVp8zk9+/9wObyRt7fU8mPZozlRzPG8sy3+/lo72FsThd6Tffj67vW7uDuT3b2s1c3njZHKn6nj1lCnCEZgzYGoy4uYJvExEROPfVUCgsLSUxMPKLjDZbExERWrFgRkWNHEpMunhljTsKgjekzrt0p23HJTuDozuggEAiii3ZrE40dldgcFvKz+p90KhCEi6CF76ZNm5Blmaeffpqnn3560AccSZNGoiEo/lezc3h3awm1HVZe2LCHk3OT+Mm0TD4vdOfy/aqoghMmuGN27/9sL6s/D/4Rxd2f7MThcBxx2EOayR2L3N93Gw2+PFoI1ZfJBnc8u8PuwmHv/R05XXZyk+ZgdXaiJWZEnaNHiuiX4UP4MnyMFl/WtVawr/ZbALJi89EMQUaZI/Gloii0Wuqwuczo1e5wPpHxZeQjKYOsFfjggw/yyiuv8Oabb5KX1/txe0+2bNkymMOEHUVRcChmXDgwqhIjbU5YeW5nXdcEtuC5fEZqyJPd7LIZtaRFLWkHbiwQCAQCQQDMchM1DvfTxxztsehUMQNsMXx0uuppdJXiVLoFs0YykqKeSIw6LYKWDR/z5s2LtAlDwqDSmT388MO89NJLPPbYY0GJXl8iPalob/VXNLUfJFafRMH44/ptGy1B8U6XzE9f+pLyFjNjEoy8efFJ3Lt+Fx/tPUySScuaK09FrVLxWEEBaWnBj/quWlYQ8mivU3awpfxDZNlFQdYSEo0ZA25TWFjIddddh91u5/HHH2fOnDkhHTMclJaWcv/99wNw6623MnHixGG3IVxES788GhC+DB/Cl+FjtPiy09ZC26ESAHLGZJESMybsxxiML+s7DlFbVYYOCR3+ccEdlDE+ezxpsaFltBpJiMltPbjnnnt49dVXefjhhwcVMxnp4PKU+GwazOVYnG1o9Wq0av2A20RDUPyvT5jORS9voKjZyr93V7E4byx//uYANFvZVtvJiZPcAvTes+aj1WoHjPO9ffmsQcX37qz4HJvLnWxclmxB+UVRFPbt2+feRpYj4kur1cqaNWsA+P3vfx/x7zMcBNsvS+t3UN1SjE5t4NiJZw2DZSOPaDjHjxaEL8PH0e5LnV7jnXyLOvDk23ARrC8VReFQxQ5Uand2Ill24VKcaFRapK6MRYeadzAubaoIexihBF25DeDJJ5/ktdde489//jNnnnnmUNk0pCTFdI9QtpjrImhJaFwwezxzspMAuG/dLhZPSMOkc/9gvLOr3K/tHStmc/vyWX3u6/jctEGJ3sPN+6lqKQYgM2EiY5LyQ96HYPhxOK20W5totzUHfL+0fgc7K77wlpsWCASC4UCj1qFRuUPmPNUjI02zuQazvQ1wi95WSz3tlkaaO2totdRjtrVhtrXSbK6JsKWCwRK08D1w4ABPPfUUV1xxhTerg+dvJBFvTPUm8W8x10bYmuBRqSTuOWMuANVtFv6++QArp7ofC727u4Keodr9id+NhxrYXB5aLHCnrZW9VV8DYNTFMX3MieJud4Rg0Lrj5uxOS8By3Q3tFVS17Ke+vbzXewKBQDCU6Lt+n6KlbLFveXeLox1Fkb3LLpcDu8sKkoTN0VWZ1NFJfXs5Tpd92G0VDI6ghe+nn36Ky+Xi6aefZvHixX5/IwmVpCbB6A5Mb+4cWXdsp0/N5oRct+0PfrabFXnuksXlzZ1srWzq1f6OFbO5fEZ3CqsL85KI02uRFYXLXvsWq6O3CAqELLvYUf4pLtmJhIrZY09BOwSzbwVDg0f4AlgdvTM2eC44Bk30TCwRCASjA08KxWgRvh4h7pIdXnGr1Rgw6uLRqvXo1Iaudu6wifq2Q2wpW8P6vf/gu5J3KKreJIRwlBO08L3yyispKioK+DfSSIrJBKDVUofsczcX7UiSxL1do75NZjvFDe1ou+KQ3t0deLTuiplp6Lf9F/22/3LDvEweOcc9S3NvbSv3rBs43y9AUc1m2qzuEeIpmceSaApvyWPB0KL3Eb62HhcXRVG8jxgDFR8RCASCocToHfGNjlCHJFMmJl28N9wBSSJGl4BRF0ucMQWTPh6TLp4kk1tHNPs8OW611HOwYUcvIdxmCe0Jq2BoCSnG92gh0eSO83XJTtqtjRG2JjROnJTBiqnZADz97X4WT3CPAL+zq6LPbQzb12DY7p7YddnCyZzaNVL88Od7+KGi/8/f2HGYQ427AEiNzWFCat+xw4LoxH/E1//i4nDZvOEPvgJZIBAIhoP0+FwmpR/DpLS5kTYFcA8wZSVMwuG0Ae4RaZVK7dcmP3OhN9RvRs6JLJr0I/IyFpAam4Na1Z0zwCOE263+T2TbLI04ghwRVhSFps5qqltKaOqs7hXWKAidQaUzG+l4hC9AS2etN/RhpHDv6XNYu6+KTrvTe/IV1rayr7aVqRkJ/W4rSRLPXbCIWY98QIfNyWWvfcvmG87wq/7mS1JMJhNSZ1PVUszMsUtFXO8IRK8xIiGhoPR6nOgrhI2iaptAIBhm0uPHkx4fXanBJmUcg8XRzv6aH7wj0uCuhJmfuZCMhAnedSpJTaIpg0RTBhOZg6y4aLM00NRRTVNnFc3mGpJjsvz2v/XQWqyODuKNaSTHZJEck01STGavEMLa1oMU1WzqHn3uwwZBaIxK4avTGEiPG49OYyTOkBxpc0LmmJwUfjJ7PG/uOMSGA7VIgII73OGWjJkDbj8+OZaHzp7H1W9uYndNC/et28Xdp88J2FYlqcnPWsjE9DlBpX4TRB+SpEKvjcHq6AggfLuXRbligUAgcF/3Zo09mRljltJiqcXmMKPXmkgyZQ44+BNICHsm1AOY7e3eAYc2Sz1tlnrKGtxhh75CWJadbK9Y32v/Znsb28rXMXfcaUL8DpJRKXwBjskNPQdxNHHXitm8vbMch6yQEWugtsPKO7squOUUf+E7bdo0NmzYAMCECd0nyZWLpvDm9kN8VlLDA5/t5tyZYzkmJ8X7vqIofif4kYjeadOm8cknn3Dw4MGIFTDpyw+jBYPW1Ifw7fBpI0IdBAKBwINKpeo1WhvyPiT/p6kGbQyLJp1LU2cVTR3VNJtrcMkOoFsIVzUX+4VMuMMbFG8eYYCimk2kx+eKp7CDYNQK35HO1IwEfjV/Iv/4/gB1nVYAfqhopLy5k3FJPo9mTCamT5/ea3tJknjup4uY/ciHdNqdXPbad2z6f6ej06hp6qxmX/V3zB57MjH6xCO21WQyMW3aNCRJilgVor78MFqYMWYpapXaOxPZg0cIa9V6vx9agUAgGA5kRaaw6husjk5ykvIjOop5uHk/Bm0sKbHZQ3YMlaQi0ZROoimdiWme0IhGPyFs0sXRYumuM2B3WZFll98EZLO9LWAYhWBgRuXktqOF25fPQqdW4Rvr/l4f2R0CMSEljgfPOgaAndXNrP50Nw6njZ0Vn9NmaWBzqbs0sWDkE2tIxKiL6zX6kJM8lbnjllOQfUKELBMIBKMZlaSiuqWE+vZy2iI42dzmtFBY9Q3fH/yQ4tofhu247tAItwieP+F0Tpl2MdlJeX5tnC5bwKeutgDpKQUDM6qFb1VzMTsqPqOkdkukTRkU45Njuep4/xOkv+wOgbjquDyWdpU7vn/9TtbvW+N9/D0167hes1kFRxcmXTwZCblkJ06OtCkCgWCUEg1FLEpqt+DsCjlIj4vcZDuVpCLWkOS3Tq+JCfhErucTPEFwjGrhW9NaSnVLCXVthyJtyqBZdcoMYnTdJ8SG0jrqO6ze5W3btjFx4kQmTpzItm3bem2vUkk899PjMOnUzMxoY0v5XhRFISdpKlmJk8Ji47Zt25g+fTrnn38+O3bsCMs+B2NDf34YDSiKgt1pDVi9TSAQCCJFpItYdFhbqGwqBCArcTIJpshmevLkEvagUWt7xfL65hIWhMaoFr6JXYUs2qwNI7bKSkackd+dONW7LCsK7+/pHvV1uVy0tLTQ0tKCyxVY8ExKjeOBMyazbEITHTYHpU0SBdnHh81Gl8tFa2sr7e3tfdow1ATjh6OZVnM96/a8yGeF/xTJ1AUCQVQR6SIW+2s2oaCgktTkZRwbERt8kSSJ/MyF/bbxzSUsCI1RLXyTfPP5+gSSjzRuXDqdBIPWu/xuiOEOTtnBzPSDJMdoccoS93+hZW9te7jNFEQQncbgHen1jKrYnBY+L3yFjQfepamzOpLmCQSCUYxvqMNwF2ho7Kiirt391Hd8ygyMurhhPX5fZCRMYO640/xGfsE90itSmR0Zo1r4xhtTvelBWjprB2gdvSQaddx88gzv8idFVbRZgx/BLqz6FrO9lfy0eL4+lEZNu4ZLX/sWh2vklHMW9I9vLJhX+Do6sTk7aTHXiWpAAoEgYniK57hkhzfOdjhQFIWimo2AO7PNxPQ5w3bsYMhImMCSvJ+xYOLZzB57Cgsmns2SvJ9Fpei12WzceuutzJ8/n8WLF/Piiy/22Xbv3r1ccMEFzJ49mx//+Mfs3r3b+56iKDz33HOcfPLJHHPMMVx88cWUlJT4vf/II4+waNEiFixYwEMPPYQsh6ZVRrXwVas03qptvvW2RyLXLs4n2eSe9emUFT7aezio7WRFRpadAExIncLP558IwNbKJh75fM/QGCsYdlSSGr3GnUrOI3wtomqbQCCIAvorqz6UVLeWeEO/JqfPi8oiTZIkkRyTRVbiJJJjsqI2vOGhhx5i9+7dvPTSS9xxxx08+eSTrFmzplc7s9nMlVdeyfz583n77beZO3cuV111FWazO0PFa6+9xosvvsif/vQn3nrrLXJycrjiiiuwWCwA/P3vf+fDDz/kySef5PHHH+eDDz7g73//e0i2jmrhC93li1vNtSjKyB3hjNFruWP5LO/yk18XBbWdSlIxa+zJ7io1OSdy7eKpHJ/rvhm4+5Od7KlpGQpzBRHA8zjR1iV8rfYOn/fE7GCBQBAZ9H7Cd/gmuBm0scQZkjHpEhibEpniSkcDZrOZN954g9tuu43p06dz2mmncfnll/PKK6/0avvxxx+j1+u56aabmDRpErfddhsxMTFekfzOO+9w6aWXsmzZMiZMmMCdd95JS0sLW7duBeCf//wn119/PfPnz2fRokX84Q9/CHic/hj1wtczK9IpO2i3NkXYmiPjyuOmEKd3Z3jYVF5PhzW4R0aSJJGdOLmriIGKF352HAaNGrtL5rLXvsUpQh6OCgw9UgZ5/uvUBlG8QiAQRAyTLp5ZY09m4cRzvINRw0FyTBbHTz6fYyec2SvHuSB49u3bh9PpZO7cud518+bNY8eOHb3CEHbs2MG8efO8I9eSJHHMMcewfft2AG666SbOOeccb3tJklAUhfb2dmpra6murubYY4/1O87hw4epqwt+ntawX+08w9nRgl6K987yr2upRKN0j3x5htY9/0cCq07K46XvSwF4dP12zsyUmDy5O0erx//VrcUkx+R4H3/7MjZWy2NnzuIvXxXS1tHJ8xt2c/GCI8vz6rFBkqSI9YFAfhiJDLZfqhQdLpeLDmsrZrOZdnMzLpcLjcYwov1xJIzEczxaEb4MH6PRl4k6d7U0h82JA2fY9hucL1WYnaPzNzAc1NfXk5SUhE6n865LTU3FZrPR0tJCcnKyX1vfazFASkoKxcXFAMyfP9/vvTfeeAOn08m8efOorXWHpKanp/sdB6CmpsZvfX8Mu/AtLCwc7kMOSJxrAjpVLC2HnbRW9bavrKxs+I0aJKemwqmnT/Rb9/TTT3tfFxYWYpabqHHsRI2WDO1MDKr4nrthXgz8y7sfxxF9b5Ik9bJhuIkGG8JNqP2yxdmC2WXGgoW9e/dS7ajEqpjBajoq/HEkjKRzPNoRvgwfwpfhw9eXVrkVvRQftfGyIw2LxeInegHvst1uD6ptz3bgHh1+8MEHueyyy0hLS+PQoUN+++7vOP0x7MK3oCAa42gC22SxWCgrKyM3NxejsffIaLTymzc28kOFu/TjwpwkNh10p6q6/IRp/HrReH44tBOT1oRObWDa+JnoNYHjOw82tvOLlzdgdynMyEzkbxceh1oVenSM0+mkubmZ8vJy8vPziY0d/olUTqfTe8dvNBrRaEbuo/3B9suaNh322nr0GhNTxk2mtbwQlcPEmMRx5KVH43k59IzUczwaEb4MH8KX4aOnL832NjYf+gGTNp6pmScQb0iNtIlRR6gDIXq9vpfw9CwbDIag2vZst23bNq644gpOPPFEfve73wH+Ilev1/sdJ5TzZNiv/ibTyJtEYzQaR5TdP5k3hVd2urM6FDV352f949o9aLQ7yUt1oFarmZN7KklxfZ/0000mfrGwgFs+2kpRcw0Lvz/EjcumD8omjUZDQ0MDsbGxEfNlfHzvke2RTKj9Mtc4nQkZM7wxU07FhlqtJj4maUT176FgpJ3j0YzwZfgYTb48WL+DiqZ9aFRajp9yftj37/FlUf3XqFQSNrmT+NhETLrR4d+hJCMjg+bmZpxOp3dQqb6+HoPB0Ou6m5GRQUODfxGlhoYGvzCFTZs28Zvf/IYTTjiBRx99FFXXgFtGRoZ33zk5Od7XAGlpwVfbG/WT23yx2Duw2CNTOSacLM/PRqPyPMJRyIm3MjW1g9OnNFDVUk5ZUwe5qbNIixs74L5uOKmAY8emAPCnNdspqmsdQssFQ4lKUvlNKDil4FcsnnIB2YlTImyZQCAY7ThlB2Z7K532liHLK97cWUNtWxngLlbRsziEYHAUFBSg0Wi8E9QAtmzZwsyZM72i1cPs2bPZtm2b9ztWFIWtW7cye/ZsAPbv389vf/tblixZwl/+8he02u7iXBkZGWRnZ7Nlyxa/42RnZwcd3wtC+Hr5pvgtviz6N2UNOyJtyhHz4Ge7ccoKU1I6uWJeJT+fWcWPp9Vwel4DWXF29taa+c/O4PIVatQq/nbh8ejUKmxOmcv/8x2uEJNFu1wuOjs7sVgsES1Z3NHRQUdHx6gsWRwIjVpHrCHJL4emQCAQRILuIhZOnHLw8ZrBoigK+6q7i1VMSps7wBaCYDEajZx77rnceeed7Ny5k/Xr1/Piiy/yq1/9CnCPylqtVgBWrlxJW1sb9913HyUlJdx3331YLBZOP/10AG6//XaysrJYtWoVzc3N1NfX+23/85//nEceeYRNmzaxadMmHn30Ue9xgkUI3y48F/9m88gtXQxw19od3P3JTqakdPKjgnoSjU7UtnZS9WYkRUYtQZzOxatbNnHX2uBE/vTMRO5Y4c4R/G1ZPU9s2BeSTdu2bSM/P59zzjmHHTsic2Oxbds2xo0bx7hx49i2bVtEbIgGrI4Omjtrabc2RtoUgUAg8GIY4ly+9R2HaLW4r++T0uei1URfsYqRzKpVq5g+fToXX3wxd911F9dddx3Lly8HYPHixXz88ccAxMbG8uyzz7JlyxbOP/98duzYwXPPPYfJZKK+vp5t27ZRUlLC0qVLWbx4sffPs/1ll13GGWecwbXXXsvvfvc7fvSjH3HJJZeEZOvIneETZhJNGdS3l9NuacApO9CotANvFGV4RC8oLJ3QjIT7UUJMggm1zomiKDRZNLgUiZNym7n7E7cIvWPF7AH3/Yel03l7ZzlbKpu47ePtnDkthylp4jHRSGNL2RrarU2kx41n9rhTRP5egUAQFRh8qkdaHZ3EGZL7aR0aiiJT2uAugGDUxTEueXBzVQR9YzQaefDBB3nwwQd7vVdU5F9Qa9asWbzzzju92qWlpfVq2xO1Ws2qVatYtWrVoG0VI75dJHUlzVZQaB3ho7458TYSDd3FK9psGlqtGjocGswOd5LuJKODnHhb0Pv0hDxo1SqsTheX/+c7ZHlo4rAEQ4fn4lLXfoh1e15kw/7XI2yRQCAQDG3Z4jb5MBZHOwB5GQtQqUSxitGMEL5dJJjSkbrc0WKujbA1g+OOFbO5ffksYnW9k3+32TQ0W/xHsU+ZksStp84Mev8zs5L402nu9l8frOP/vgkt5EEQeXqmrhuJTzYEAsHRh0at8/4ehTvUwS67i1MkmtLJTJg4QGvB0Y4Qvl2oVRrije7sBc0jVPiCW/zmBzm78dPiZmY89D7/2VYW9OjtTSfPYO4Y9yOoVR9t40BD+6BtFQw/PSeyiYltAoEgWtD3KKseLtK0+Rwz9nSmZS8WRSsEQvj6khSTCUBLZ+2QpVMZau5au4P39nbSYtWiUyvo1IEzMDRbtFS26SlpaOeilzew4C8fs3Zf1YCfW6tW8bcLj0OjkrA4XFzxugh5GEn4xtG5l4XwFQgE0YEns4PNEf7ywQnGdOKNoliFQAhfPxK74nydsp0OW3OErQmd7sltEl8cTCLB4CAj1k5ajH9qGAWJL8uSAIlEo/vR0rbDTZzx/Kec+vQ6Nh6q7/c4s7OTua0rROLLA7U88+3+ofg4giGg94jv8FfREwgEgkBMH3Miywp+ybzclWHZn0vuHfYnEAjh60OSKRODNuaoiAGqbtfTbtfglCVsru6vudmi5b3CNIob3QLomhPyefL8BWTEucsFfnGglhMeX8P5f/+CPTUtfe7/llNmMCsryf36o62UNoqQh5GAQRuDoig4XDZsTgsOl23EPt0QCARHF0ZdLHqNMSzhCC3mWr7Y9woVzXtRlNByzwuObgYtfO12O2eddRabNm0Kpz0RRa81sXTqL5gz7tSwplIZLjyT2wCmpXVidaiobtfxyvYs3t+Xzqs7s3hhyxiv6AXYUFpHsknPnj+ezb2nzyHe4B4Bfm93BXMe+ZBLX/uWQ029Z9jqNGpevPB41CqJTruTK/sJeVCr1d5SxWp1ZGbTemyIjY2NmA3RQJulnlZLPe2WRjqtzeyv2cyG/f+htvVgpE0TCASCsOApVuFw2Shr3IGMKFok6GZQwtdms/H73/+e4uLicNsjOELc4ncmMzLcYrWyzci+hliKGmKobDMA7jtpT0Xjr0rruOjlDUx/+APMDidfXL2cPyydhkGjRlYUXvr+AFMfeI/fv/c99R1Wv2PNzUlm1SkzAPi8pJbnNgbuD3PnzmXfvn2899573rKEw83cuXMpLy+nvLycuXNHZ8We2taD7Kz8Atnn8Z9KUmO2t7GtfJ0QvwKBIOLIiozF3oFTdgzcuA/q2sq82ZnGJ89ELYnsNYJuQha+JSUl/PSnP6W8vHwo7BGEgRtOzGFejg6APXW9YzhvXz6LqjsvYPWZc8lNdo/+1rZbuX/9buY/9jH769t4/qeLuGzhJNQqCbtL5q9f7WPy/e9w99odtFu7f5BuO3UmMzITAbj5wy2UBRgdFkQeRVEoqnE/nYkxJCFJKkDq+u+mqGaTCHsQCAQRo9PWyie7X+DLon/T3FkzqH3Iisv7W2fQxjImsSCcJgqOAkIWvps3b2bhwoX85z//GQp7Io6suKhqKWbP4a9pNldH2pxBcbh5P7nJsYxPjqeo3j9v6+3LZ3HHitmkxRq46eQZ7F91Lh9cfjJnFIxBkkBWFN7fU8kv//0NX5TUceNJ0zhneg4AHTYnd32yk8n3v8NfvyrE5nSh06j5W1fIQ4fNHfIgxFP00WyuwWxvA0CvMZIUk0lSTKZfLJ3Z3kazeXAXG4FAIDhS9Bqj9/Vgi1hUNBZ6f+vyMhegFsUqBD0IuV7pRRdddEQHNJvDn6YknCiKwq7yr3DKdjJjrEASFosl0mYFjazIVDYW4XK5mJ+Tz3XHJfLI1yUA/GHxZP64ZEqv72Dp+CSWjl9EWXMnf//+IC9tOUij2c6BxnYe+nwPBo2K0/Mzaei08X1lMw2dNn7/3g889sVebj25gJ/PGc8Ni/N45KsiPi2u4akNe/n1/Ane/VssFoqLizl8+DAZGRnD6g9fGzxPKcaNG4fRaBxgi+jF0x9D6ZetHU24XAPHubV1NGGQEgZt20hjML4UBEb4MnyMZl9Kigqn7KCtsxmzITS94HDZKarejMvlIs6QSoI2a1T7UhAYSTmC4bn8/Hz++c9/snDhwgHbbtmyZbCHGXaqHTuxyE3opXjG6I6JtDkhYZYbqXHsAiBTO5NDRXVc+eLHADx36RkUFAz82MfukvmsvJ03i5vY2eD/YzEuTodTlqnq7I4TnZCg54oZqTy/q56DbXZiNCpePXMSmTHuuKrCwkKuv/56AB5//PGgbAg30WBDJLHILVQ7tg/YLks7B6MqccjtEQgEgkBU2r/HrnQSp8okTTs1pG0bnQdodVUA4rcsHMybNy/SJgwJIY/4HikjQXAYG+0cbNyOojiRXS4mTpg0YkYIFUWhxTKJ+o5DTE5bgGTbjmH7GgByc68O2v+zZ8ANwK7qFl74vpT/7Cin0+6ivN2dE9ikVaNTq2ixOjjYauPWbw4zNT0eVbudTqfMX/e08s6v3FVynvl6r3e/n9Y6OP/84e8Dvnf7ubm5I6If9oXFYqGsrIzc3Nyg+6WiKNjLqr316gNh1MYzN3fRqKpsNBhfCgIjfBk+RrMv7ZWVNJmriDfFUJAT/O+0U3bQULodk2wiNWYsM8ccB4xuXw6WwsLCSJswpAy78DWZTAM3ijAZ8jjKW3bhcrmwKe0YjcYRYbeHmJhJjEmdBIDBYPCuNxgMIX+OhZNMLJyUzSM/svPyllKe/nY/hbWtmB0uzA73o3O9RoXNKbOvrs273acldfxndzUVLZ28tKUMzxS7V3ZUkruhmDtWDG92hyP1QzQSar+cnnMC28rX9fP+8cTEjM5KbiPtHI9mhC/Dx2j0ZZwpkVZbLS7sIX/2kwp+RnHtFiakzsZk8N92NPpSEJhhF74jgQRTOlJX2i+b3DZA69FBglHHNYuncvUJ+XxVWsfT3xTxzq5ynLKCzelODq6SwDeV71VvfIesQM+pBe7qcgy7+B3tZCRMYO640yiq2eSd/AFg0sWTn7mQjIQJ/WwtEAgEQ4+nmqTV0YGiKCE9gTJoY5mZc9JQmSY4ShDCNwAalZY4YwrNHbVYldZImxM0DR2VJJkyUauG7muVJImTJmVw0qQMqtvMvLiphOe+K6ay1UzP+hV91LMAhPiNFBkJE0iPz6XZXIPNYUavNZFkyhxV4Q0CgSB68ZRVd8lOnLIdrVofYYsERxuiZHEfJJnc2QescuuISM9ltrXxw8GP+bzwZRraK4flmFnxJm47bRYHbjuPty45iVPzskLa/u5PdnLX2h1DZJ2gLyRJIjkmi6zESSTHZAnRKxAIogaDNhaNSkesPgmHyz5g+7q2Q+w5vAGbI7ozRgmihyMaGiwqKgqXHVFHoikT2ImME7O9NepjHw+37AfAKduJNSQN67E1ahXnzhzHuTPHcf3bm/m/b4LvF2LkVyAQCAQeUmLHcOr0S4JqKysuiqo30mlvpamzmsVTLhA38oIBESO+fZAcm0Ve+iLGaOdj0kV3XlNFUahqcZcLTo3N8T4qigS7qptD3uaLElE0QSAQCASEJFwrm/bRaXeHI05MmyNEryAoRIxvH+g1JsYk5tNWXRj1J1OLuRaL3Z2mKjtpit97RqORqVOnel8PNUsnZ/JVaZ3fOkWtxZWY6X3dE7PdSXlzJ+OShk6wD7cfBAKBQDB0OF12Smrd9QHiDClkJ04ZYAuBwI0QvkcBh5vdYQ5qlZb0+Fy/96ZPn863334bAau6kZPH0HHeqj7f/6GyibzV73LxsRO55eQZTEiJC7sN0eAHgUAgEAyM2d6Gxd6OSlKTFJMZsE1p/XbsLisAU7NGV/5xwZEhQh2CwOGy4ZKdAzeMAC7ZSU1rKQCZCRPQqHqPqI4EHC6ZFzaWkP/Ae1z62rcU14s0cgKBQDAa2Xv4a74/+BEldYErvlodHZQ1uCuUpsaNJSV2zHCaJxjhCOHbDzanmUr793x94DUaOoYnU0Ko1LUdwim7Z75Gw6OeO1bM5vbls0LeTqdWIQEuWeGl7w8w7cH3+eUrX1NYO3LSyQkEAoHgyPHMU7E6OgO+v7/mB2TFXUApP3PhsNklODoYtPC12+2cddZZbNq0KZz2RBVatQGH4n6U0tJZG2FrAuOZ1GbQxpIck93r/dbWVtatW8e6detobR0eEdlL/NrMaCr3oqncC7bAKWfsLhkFiNNrugphKPx760FmPvw+F/7zq0FNmvMlEn4QCAQCQej0LGLhS5ulgaquLEY5SVOJMyQPu32Ckc2ghK/NZuP3v/89xcXF4bYnqlBJKgyqeACazdGZeWBq1iImps0lN3VmwBin4uJifvazn/Gzn/1sWL8vX/GrbqsjZt2zxKx7FnWbe+Lb7ctnsffmc7h9+Swy47onm7XbnMgKaFQSKgkUBd7YcYg5j3zIj//xBdsqmwZlT6T8IBAIBILQ6FnEwpcYfSJTMo5FrzExJWN+JMwTjHBCntxWUlLCjTfeOCKKOoQDg5SAjTpaLfXIsguVqmcB3sgSo08kL/PYSJsREE9u3vteKfNbf/vyWd73PAJ5/f5qrnlrEwcaOwBwBij79u6uCt7dVcGZ08bwv6fNYsG41KH9AAKBQCAYdjwjvuAe9fWt3qZWaZiUPpcJabNQSdF1PRaMDEIe8d28eTMLFy7kX//6FwCFhYVhNyqa0HeN+CqKTKulIcLWjDzuWDGbyxZO9i5fPC+3V7EKSZI4LT+bolXn8o+fH0+srv/7sY/2Hua4v/6Xlc+u55uDdf229cU6ZyXWOStD+wACgUAgGFZ8c9H3FecrRK9gsIQ84nvRRRdhs9m48cYbB3VAs3nklBW0WCwYpHhaZAVwUdt8CL0U/lRbg8HmtACg1wyck3by5G7hGQn//2L2WP7T9frCGdn92vDjaVkcn7Oca9/byif7u8NLNCqp1yjwlyU1bCuv54TxKfy/k6YyLyelz5Q2T2+rxjb3dO/rJ6aNnH7YE4vF4vdfMHiEL8OH8GX4GO2+lGUVLpd78lprRxMx6lQaOyvRqY3EGVJC2tdo96WgN8Me6jDSRohVkgbZpsaqdHCgspDO2ui4y2x0HqDVVYFJlUqGZnqfgk+SJJ5++mnvciT8X1ZW5n1dXV0dlA33zEtiYZKKP2+todMh45QV0o0asmN17G4045TBLis0WJ28V1RLSUMry8cncNr4eFKN/indnttZxz/2tXiX/7GvBc1/vuTKWenh+ogRwdevgiND+DJ8CF+Gj9HsS6vNhoyLg+UlNKvtVNg34cJOono8yZoJIe9vNPtS4E/IwtcT6nDDDTcwZ86ckA9YUFAQ8jaRwmKxUFZWRnbqBOo6D6BTy0ydODXiibIVReG7g7sxOU2kxqYyLXtan2337t3L1VdfDcBTTz3FtGl9tx0qfO+0s7Kygu4D06bBzxebufbdLXx2oI46i5NGm4trj8tjQnIMb+ys4NtDDSjAnkYrexqtPLa1ljSTjovmjuf3J+bzzMYDvLC7d4jKC7sbSEtL49aTh98fR4qnX+bm5ooqdEeI8GX4EL4MH8KXIFfXoSgyabHjMTva0DdqAA0FY2aTHBN83l7hy9AZaQOUoTKoUIfRRpw+lSZLBbGGFFyyA41aF1F7ms3V2JzuR/WZ8RMjastQMzbRxLsXL+btXeX85ctCLA4Xa/aWk58WxxM/mkuMXstr2w/x4vcHOdTi9km92c5fvynmr9/0n71h9efuk3skil+BQCA4mpmWeSKtljo67M2UNmxFQkVKzJiQRK9AEAhJOYL0DPn5+axatYpLLrlkwLZbtgSuwDISUBQZkCI+0uuhzlFIh1yLCg3jdccjSdFdh6SwsJDrr78egMcff3zIRv3L22ysO9TG2kOtlLXZB96gi8tnpI74sAeBQCA4Wuh01dPoKsWpWHAoZpyKHQkV2do5JGrGRdq8UcO8efMibcKQEPKI75EyEkMdJkyYGDWPSJyyg/rSrZhkE2MS88lLn95v+/Lycp566ikArr76asaNG/4fDZ1Ox0knnYTFYiE/P/+I+oAsK7y+vYwnvt6HzSkDMC0jgTtXzGZFQRwrFkLcul088tX+oPf5wu4GHPpYHjpjNqYBMkocKfd/thc4slFm8egufAhfhg/hy/Axmn1Z33GI2qoydEioZR12WztqVOjURmy6WlKzp5IWOz7o/Y1mXw4WEeoQZkwm03Af8ogxGo1RY/fh5v0gKajVanLTZwxo19SpU3n88ceHybrAzJw5k1deeYXCwkIKCgqO2JeXLp7OkvyxXPrat3xbVk9Rs5WPS9Zz98o53HBSAZsrW0Le50tbyvjn1jImp8QxIyuJWVmJzMxOYmZWIhOT41Cpjny0/661O7zhFVqttldat1CJpn450hG+DB/Cl+FjtPlSURQOVexApVYhyy46bI24f3klYvQJqFQqDjXvYFxa6HNtRpsvBX1zxMJ3JI3gHglOl4OmziqazTVMTJ2DVqMfeKMh4HCzeyTTpEsgwZgWERuigSlp8XxxzXL+8mUhf1qzHZtT5uYPt/Le7grmjknmq9Lg8/t6UBQobminuKGdd3aVe9fH6DTMyExkRlYis7KSvII42RR8H7hr7Q7u/mSnd9nz+kjFr0AgEBwtNJtrMNvbAHfVNg96rclbPMpsb6PZXENyTFZEbBSMfIZ9xHek0mlrYeuhtQAkmTJJjw/+UUu4sNg7aOqsAmBM0pSoiTmOFGqVihuXTef0gjFc+tq3fF/RyLdl9Ww73MSK/GzWFlWFtD+9WsWYRBMScLjVgtXpziPZaXeyqbyBTeX+2SHGJJi6xXBWIjOzkpiaHo9O45/yrqfo9SDEr0AgEHRj8ylWoVHr0HRVbDPp4nu0G7l52AWRRwjfIIkzJrtz+ipOWsy1ERG+WrWO6dmLOdxSTFbilKC2qaur4+OPPwbgjDPOID19+Cdx1dXV8e6771JdXU1qairjx4fXd9MyE/n6upU8/Pke7vpkJxaHi7VFVYxPiuFQc+CqPx7m5SRT3tJJfYcNm0umtKtkcqxOw1nTxjA1PQGNSsXe2hZ2VbdwsKnDu+3hVjOHW82s3dctsDUqiYKMBGZkJjIrO4mdVc28uq2sz+ML8SsQCARu9D4V2yRJIt4YuFiFXitCFgSD54iEb1FRUbjsiHpUkppEU7o73KGzZuANhgCNWsfYlGmMTQl+YlR5eTm///3vAZgxY0ZEhG95eTm33HILAKecckrYhS+ARq1i1akzOXNaDr9+9Ru2VzVzqLkTlQRyH3lLTpyYzufXrMDpkvmqtJY3d5Tz9q5D1HfY6LA7+XDvYT7ce5g4vZazp+fw5x/N57jcNEoa2tlZ3czu6hZ2VTezs6qZVqsDAKessKvaLZL7E7y+CPErEAgE7qepJl28N9whECZdPEmmzGG0SnC0IUZ8QyDJlEFTZxWtlnpkxSVqhUchs7KT2Pj/zuD+9bu455OdXtErdbagxCT6vf6qtI671u7gjhWzOXlKFidPyeLx847lq9Ja3thxiHd2lVPfYaPd5uDfWw/y760HidNrOWdGDj+ZNZ6L50/CoFWjKAqVLWZ2Vjezq7qZXdUtfLq/mvpOW9B2C/ErEAhGO5IkkZ+5kG3l6/psk5+5cNSH+QmODCF8QyAxJhPqQVZctFkaSTQN3+ip1dGJXmMSJ3wQaNXuvMa+A70qcwua/d8B4MwpwNUlgnsKTo1a5RXBT5y3gC8P1PLmTn8R/MqWg7yy5SDxBvdI8E9mjWfF1GzOTMrhzGk5QN9xvf1R0tCO0yWjUUd3XmaBQCAYKjISJjB33GkU1WzyG/k16eLJz1xIRkLo5YoFAl+E8A2BRFOG93WLuWbYhK+suPim+E30GhN5mQsiEl88kuhLdBq2rwGgI8c/E0lfo60atYpT8rI4Jc9fBL+9s5yGThtt1t4i+ILZ41men+3dVyji999bD/JZcQ0Xzs3lF/MmMHdMsrjREQgEo46MhAmkx+fSbK7B5jCj15pIMmWK30NBWBBDSyGgVeuIMyQDDGucb317BQ6XjQ5bc9RXaRupyH0FAnfhEcFP/2QRh+/4CZ9cdSpXLJpCaox71rFHBJ/74hdk3vEGF//7G47JSebWU2cMeOx5Ockkm9xlsGvaLfzlq0KOfexjZj78AQ98uotDPhPqBAKBYDQgSRLJMVlkJU4iOSZLiN4ox2azceuttzJ//nwWL17Miy++2GfbvXv3csEFFzB79mx+/OMfs3v37oDtnn76ae/8IN9t8/Pz/f7OP//8kGwVI74hkmjKoN3aRLO5FkVRhuVkrOrK3avXGEmJFXXKB2Iwo60vbi5BAS5dOJnc5Nh+2/qOBD95/gK+OFDLm10xwZ6R4Je3lPLyllJ0QYQtnDkth1WnzOC/+6p4ZUspH+6txOaUKaxt5baPt3Pbx9s5cWI6F82byAWzx6ML+lMJBAKBQDD0PPTQQ+zevZuXXnqJqqoqbr75ZrKzs1m5cqVfO7PZzJVXXsnZZ5/NAw88wKuvvspVV13FunXr/AqMfPjhhzzxxBOcc845ftuXlJRQUFDA888/712n0YQmZYXwDZHMhEkYtLEkxQzPrFKH00Zdu7uYQlbiFFRixDcoghW/sToNHXYnVW0W7lu/i/s/3cVpedlcvmgy50wf640X7guNWsWpeVmc2kMEv72znEazDbtLHtBW31CLH80YS4vFzps7DvHvrQf58kAtAF+V1vFVaR3Xv72Z0/OzOCFFYtIUGZHURyAQCASRxGw288Ybb/D8888zffp0pk+fTnFxMa+88kov4fvxxx+j1+u56aabkCSJ2267ja+++oo1a9Zw/vnn43Q6ueeee3jnnXcYO3Zsr2MdOHCASZMmkZY2+AJeQkWFSEpsNpPS5w7bo5fq1hIUxS2exiQFl7tX4OaOFbO5ffmsPt+/ffksGu/9GW//eimnF4xBktzV2z4pquKnL33F+HveYtWHWylp6Du1ji8eEfzMBYv47fF5Idl69yc7uWvtDgASjTouXzSFz65eTult53HfGXMoyEgAwO6SeW/vYW7aUMnkhz7i6jc38c3BOhSl/1CNnty1dof3eAKBQCAQDJZ9+/bhdDqZO3eud928efPYsWMHsuw/+LNjxw7mzZvn1U+SJHHMMcewfft2wC2ii4qKeP311/325+HAgQPk5uYekb3DPuJrNo+ciisWi8XvfyQob9iHy+UiVp+MWjaG7L+kpCRvHt+kpKSI+D8pKYnf/e53tLW1DbsNf1wyhXi1wgufWdGd8hMA7DmZXH7yTK46fgp2m5XTJqZw2sQUqtssvL+7gvd3V1DbYQXgve0HeG/7AY4dm8K5M8eybHJmr8psgUjUQn6SISRb49VKL9+kGVRcf9wkrls0kaK6Nv677zBrCg/TaLYD8MW+cr7YV86YBCOnF4zh9IIxjE/qP1Tj2W/385/vi73HvCpEkX40EQ3n+NGC8GX4EL4MH8KXQ099fT1JSUnodN2BeKmpqdhsNlpaWkhOTvZrO3nyZL/tU1JSKC7uuibFx/Paa6/1eawDBw4gyzJnn3027e3tnHjiidx0003ExvZ/3fNl2IVvYWHhcB/yiCkrKwu4XlHkIZ1s5lDMVNvdxzbaswbtu9NPPx2AlpYWWlpawmRdaJx11lkAWK3WYe8DJybBiT8+BjjGZ60roB0nJsGJS7ID70hp40BxcKO/JybBiadPDNHSwDb5sjJdYmV6Th/vyphrKigcYN6lv20DH3M00Nc5Lggd4cvwIXwZPoQvhw6LxeInegHvst1uD6ptz3aBcDgcVFRUkJOTw/33309bWxurV6/mj3/8I08//XTQ9g678C0oKBi4UZRgsVgoKysjNzcXo9HoXd9irqW0cSvt1kaOn/hTtOqhmW50sHE7pkYTEhJzJy5BrzEOvFGU0pcvh5Nnv3VPEgxlhLO+3cL7eyt5d1cF1W3+IwZzxyRx3qxxnDw5E4M28Kn07Lf7eX5jcdDHM2rV/HjWeH5xTC5pcYH95OtL1Bo+P1DLfwur2HSoAdkn5EGlkjhufCpnFIzhxEkZ/PP70j5tuWLRlGEf+R3M9xFuoqFfHi0IX4YP4cvwIXwZOqEOhuj1+l7C1bNsMBiCatuzXSC0Wi0bN25Er9ej1WoBeOCBB/jxj39MbW0tGRkZA+zBzbALX99ZeyMFo9HoZ7edGDqqG5FUYKeNBNO4ITluppyLQzGjKDJJ8YFrlo80evpyOLnh1DkhbzPeZOK6jBSuOWkW64ureX5jMe/vrsApKxQ1V/Pa7moSjTp+OX8ily+czIyspF7HbHNJfU6y+9NpM1k2JYvV63exbn81ANvX7+Wez/dx8bGT+OOy6UxKjQu4rceXP5mXwE/m5VHTZuH17WW8vKWULZVNABQ2VvDi1gq0agmHq+844D/8dxdtLmnYKse5cy3vAhjW4/ZFJPvl0YbwZfgQvgwfwpdDR0ZGBs3NzTidTm+Ghfr6egwGA/Hx8b3aNjQ0+K1raGggPT24ugg9QxomTZoEEJLwFZPbBkG8McVbrri5s3bIjpMSm82ccacyZ9xpg95HZWUl9957L/feey+VlZVhtC40Gx588EFefPFFqqqqImbDkfhBpZJYnp/NGxefRPntP2b1mXOZ3CVIWyx2ntiwj9mPfMgJj/+Xv28uodPm8G57x4rZnDix90l94sR07lw5h5MmZbDmqlPZ/P/O4PxZ45Ak9yS25zcWM/WB9/iflzewq7p5QBsz441cf2IBm284k903ncOtp85gfFIMQL+i14PvBLuhpGeBkeE6rkAgEAjCT0FBARqNxjtBDWDLli3MnDkTlcpfZs6ePZtt27Z5J2QrisLWrVuZPXvgwY+SkhLmzp1LRUWFd11hYSEajYbx44Mv7CXSmQ0ClaQmwZhGs7mGFvPQCV8PR5I9oqamhj//+c8ArFy5kpycvuJDh46amhqeeOIJAH7+85/3CmwfLhvC5YeMOCM3nTyDPyydzhcHanhhYwnv7CrH7pLZeKiBjYca+P17P3DRMRO4fOEU3t9TwVeldb3281VpHXet3eEd7Zw3NoU3Lj6JfbWtPPT5Hl7ZUopTVnh1WxmvbivjrGk5rDp1BrPSYga0sSAjgXtOn4takrhn3a6gP9vdn+zk+Y3FHJOTTGac0fuXEW/wWTYQo9cG7zAf+qqq11f1PIFAIBBEN0ajkXPPPZc777yT+++/n7q6Ol588UVWr14NuEd/4+LiMBgMrFy5kkcffZT77ruPCy+8kNdeew2LxeKdi9QfEydOZPz48fzpT3/i1ltvpa2tjTvuuIMLLriAhISEoO0VwneQJMVkdgnfOmTF5R0BDgey4gII6z4F4Uelkjh5ShYnT8miocPKv7aU8sLGYvbVtdFmdfDMt/t5piuOtS8CCb6pGQm8eOHx3LF8Fo9+sZe/bSrB6nTx4d5KPtxbyYkT0rgg18jUqQOP4g7mpqm6zcJHew/32yZWr+kWxXFdojje53XXcnqswZsLuS/R60GIX4FAIBiZrFq1ijvvvJOLL76Y2NhYrrvuOpYvXw7A4sWLWb16Neeffz6xsbE8++yz3HHHHbz++uvk5+fz3HPPBRWGolKpePrpp7nvvvv4xS9+gUql4uyzz+amm24KyVYhfAdJosldwEJWnLRbmkgwDT6Zck9qWg9SWPUt2YmTmJKxAI16cKNrguEjNdbADSdN4/+dWMDXB+t4YWMJr249iCuI/Lp9Cb7xybE8fv4CbjttJn/9qpCnv91Pm9XBVwfr+eog/H1/O7eeNosfTR+LShVY4IZaxW7R+FQmJMdS226lpt1CTbuFJnPv2bYdNicltnZKGtoH3GdqjB4JqO+0Ddh2uMXv/Z/tpb6+nsdG0KRbgUAgiDaMRiMPPvggDz74YK/3ioqK/JZnzZrFO++8M+A+H3jggV7rsrKyePLJJwdvKEL4DpokU3cQdbO5JqzCt6q5GIfLSl1bOVOzjg/bfgVDjyRJLJmYwWfFNUGJXg93f7ITs93Jg2fP6/VeRpyR+888hptOnsHT3xTx2Jd7aTTb2Xq4mZ/840sKMhK4+eQZXDg3N2CluWDF7+3LZwUUnDanq1sIt7nFsK8wrm1zv65us2B1unpt3xCE4PXl7k92sv1wEzcunc6UtDjSYw1DUizmrrU7WP25e/ZyWtpe7j1rftiPIRAIBILoQgjfQaLV6InRJ9Jpa+mK850Zlv1aHZ00dLgDt7OTpgxLdThBdPDIF3t5ZetBZmYlMSsrkZnZSczMSmRqegJ6jZpEo45Vp87kivnjeejjjfynpI3KVguFta1c8uo33LFmO39cNp1LFkzC2CO92kDity/RC6DXqBmXFMO4pP5jixVFod3moKbd6iOQLbyx4xDfHKwPyRfv76nk/T3uSYhxei2TU+OYlBrHFO//eCanxpERNzhR3DPsYvXnhWi1WhFmIRAIBEc5QvgeAUmmTMz2Nm9J4XBQ3XLA+zo7UZQoHqmEGmLgobrNPXL6SVF39guNSmJqegIzsxKZlZ1EXrKJpWPjWXXmcbxbVMtDn+1hf30bh5o7ufbtzdyzbif/78QCfnN8HvGG7hzTd6yYzRclNb0m2p04MT0sgk+SJOINOuINOvLSulPYXLekYMD4Xl90ahV2V/c51W5zsO1wE9sON/VqG6vXMDkljslpbiHs+ZuSGt+nKBYT7AQCgWD0IoTvEZCXuYCC7ONRq8LnxqoW92SoRFMGMfrgZykKoo9gxe8tJ0/nnBlj2Vndwq6qZnbXtLCzqplmizu21ikr7K5pYXdNC69uK/Nul7S2jFnZyZyWl8XSyRl8UVLL/vo2atutrPpoGw9+todrTsjn+iVTSY01cNfaHUFllxgKQgm3uH35LBo6bZQ0tFPc0MaBhnaK69s50NhOcX0brdbuVHEdNifbq5rZXtU73ZtHFE9KjWNKWjyTUuL4+mAtL31f2ufxhfgVCASCoxshfI8AnWbgSiOh0GZppN3qHtUSo71HB6GEGCwc3x0nrigKh1vNXjG8s7qZ3dUt7KtrxSm7Y4ebLQ6+PFDLlwe6U+pJuEMTrE4XLRY7963fxaNf7mFWVhKbyxv7tHM4BF8ovkiLNZAWa+C4XP/YeUVRaOy0UdzgnlhX0tDW9T80UdwfQvwKBALB0YsQvlGEZ7RXklRkJUwKyz7HjBnDn/70J+/rSDBmzBhuueUW6urqyM7OjpgNkfJDX4Kvv7haSZLISYwhJzGGMwq67bU5XWw/VMsn2wppUsVQWN/B7poWbzllBXpNMLM65H5Fr4dIit/+fOGLJEmkxhpIDVEU76pqxuYKPiRJiF+BQCA4OhHC9whxyU5aLfV02loYmzz4lEiyIlPVUgJAetx4tBp9WOzLysrihhtuCMu+jsSGa6+9lsLCQjIzMyNmQyT90FPwBSv0eqLXqJmZlYimJZGCggJv7sP6Diu7qpvZVe0Ok9hd08Lu6paAWRb6IxLid7C+6El/ovjONdtDKuQB8O6ucmZkJbIiP5vYQRbsEAgEAkF0IYTvEXKocQ/7azYBkJUwCY1aN8AWgZFlJ9mJU6huKWZMUl44TRRECb7iLtzCMi3W4C2m4cElyxz/+H/5oaL3pLD+eOrrfaTFGDh+QhozsxJRq3qnSDtShtIXgbhz5RwkSQppsuHO6hZ++tJX6NQqTp6SyTkzxnL2tByyEwZOtC4QCASC6EQI3yMkydQ9gtliriM1bnClcDVqHVOzFpGXuQCRwOzoZTgfnatVKs4oyAlZ+DaY7Vz3zmYA9BoVs7KSWJ6fzYmTMlg0PjVso59flNQAw+eTYCfY/WzOeGL1Wj7cW0ltuxW7S2bNvirW7KviajZx7NgUzp6ew9nTxzIzK1GkHBQIBIIRhBC+R0iCMRWVpEZWXDSbawYtfD2opPCOrpWWlnorqdx8881MnDgxrPsP1ob77ruPtrY27rzzTqZPnx4RGyLth0gw2LRqHmxOme8rGvm+opH71u9CAsYlxXDChHTOKMhmycQMchL7z+8biGX/t9abYWLZ/63l82tWDMq+UAllgp0sK2yuaOD93RV8sKeSvbWtAF5/3L5mB7nJMZw9fSznTM9hycSMgAVEBuKutTv8bBMIBALB0CGE7xGiUqmJN6bSYq7tKmQROoqiDNmoUVNTE2+88QYAV1xxRUQEX1NTk7c84e9+97thP77Hhkj7IVIEK35vPWUGZ03P4fvyRjaU1vFtWR1VXZPmPCjAoeZODjUf5N9bDwIQr9cyM9sdC3tGwRhmZSf1Gx7hK3rBnU4tGsRvz1hjlUpi0fg0Fo1P4/4zj6GkoY0P9lTy/u4Kvj5Yj6wolDV18sSGfTyxYR+JRh2nT83m7OljWTk1mwTjwGFPPXMKR0r8CvEtEAhGC0L4hoEkU2aX8K1DVuSQR21/KPsvapWG8SnTSYmNTOYFwdFNqGnVrl0yFYAWi50fKhr59mAd6/dXs6OqmQ6702/bNpuDbw7W883Bem5fswONSmJ8UizH5aZy3sxxnDIliziDOzyip+j1EGnxu2pZwYCib3JqPDecNI0bTppGY6eNjwor+WBPJWv3VdFpd9JisfPqtjJe3VaGVq3ipEkZ/Gj6WM6anhOw6l1P0RupTBLRIr4FAoFgOBDCNwwkxWRysGEHLtlBh7WJeGNq0Nua7e00drhLsyYa04XwFQwZg0kllmjUcWpeFqfmZXH7itne/MKbyxtYu6+Krw/WUdLQ7s0tDO6CGwca3QUnXt7iHhVOMupwyTJtNmfA48Dwi98jISVGz6/mT+JX8ydhdbj4vKSGD/ZU8sGeCqraLDhcMuv3V7N+fzXXvbOZuWOSu+KCc5g7Jpm7P9kZFdXjokV8e2yJ1LEFAsHoQQjfMJBgSve+bjbXhiR8q1uKva+zEieH1S6BoCdHmkrMN7/w+bPGA+5Y2KL6Ntbvr2JNYRXbq5qobbei+GznqUI3EF+V1nHSk2v48tqVQds0GHoKvtWfF6LVagclugxaNacXjOH0gjE8ef4Cth5u8sYF76x2F8/wlFy++5OdxOk1tPdzAzBc4jOaSjeLUWeBQDBcCOEbBvQaIyZdAmZ7Ky2dNYxPCW7ylqIoHG52C9/kmGyMutihNFMgAMKfSkylkijISKAgI4HrlrhzWducLjaXN/DOznJe2FRMpz34fMJfH6xHc+O/GJcUw7jEGDLjje6/OAMZcUYyu/4y4gykxxrQhDihbCgFn0olMX9sCvPHpnD36XM42NjOh3vdIRFfHqjFKSv9il5fW0ob27liUR4GrRqDRtX1v+uv63Won91DXz7wPT4MjwCNplFnjz2RPL5AIBhahPANEznJU3G6bCGFKrRa6jDb3TPFRe5ewXAy1Bd1vUbNkokZLJmYwbbDTQHjevujexJdZ7/tJAlSY/RdQrhbEPv+d4tmI0lGHfesCxxi4CHcomtCShzXLSnguiUF3PLhFh7+fG/Q27685aA3VKQv1Cqplxg2aFV+6/S+72nU7Kxu5oeK4Cr5tVjs3L58FnF67aBFdn9E06hzIHuE+BUIjj6E8A0TE9NC/4H0jPaqJA0Z8blhtkggiA4+v2ZFn5PaAiGBX5hEfygK1HfYqO+wsau6JSz7vfuTnThcMveeMTdIK4LDqA3/z61LVui0O+m0DzyKPBge37CPxzfsA8CoVROn1xJv0Pr9j9NriDfoMKjB2tbMxBYNKXExAdu6/2tQq1RRNeoM0TXyfP9ne6mvr+exgsFXAxUIBIERwjdCyLKLmtYDAGQmTBh0xTeBYCQQrPg9cWI6n129nKo2C7urW9hT08Ku6mb21LhfW51yv9urJHfhDqdL7iVygxXTAKs/3c3Dn+8hO8FEaoyeFJOe1Bg9abEG93KM+7/nLy3WQLJJ328e31BzKv/2+DwuXTgZq8OF1enC6pS7Xztc2Jzdr/3+O11YHbLfOlvX60PNHdR12ELwRDcWhwuLw0Vdh7X/hjvrB9yXRiX5TYjsi7s/2UlRXSu/PSGfJKOOJJOeJKMOo1Yd1hSQ0TTyfNfaHaz+vBCAtLS93HvW/GE7tkAwGhDCN0LUt5fjcLkvQNmJU4bsOBMmTODZZ5/1vo4EEyZM4PHHH6eqqorc3NyI2RBpP4x2BhK/J05M92Z0GJNgYkyCiRVTs73vu2SZg00d7OoSxB5hXFTfhqtLRMkKyK7e4linVmEPsL4/nLJCeXMn5QOEW/iSaNT5CGKD3+uUGD1Fda1B7yst1sAxOSkh2RwMA420+vLT2eM5fdoYOqxO2mx22m1O2qwO2qwO2m0O2rv+u9fZabXYMQ9wcwIEJXo9/Gf7If6z/ZDfOp1aRZJJ5xbDRj2J3tc67/pEo55kU/dyX6I5mkaewznpMhy2gAj3EBx9COEbRqpbDnC4eT+K4uLYiWf121aS3IUvbA4zKbHZ/bY9ElJSUrjggguGbP/B2nD++edTWFhIcnJyxGyItB8EfYtfX9HbF2qVismp8UxOjee8meO8621OF0V1beyu8R8hLmvqFqyhil6A+WNTmDsmiU67k0aznYYOKw2dNho6bX2GFrRY7LRY7JQ0tId8vJ7c/clOdlc385vj870jzakxenQa9RHtN9iR51AzfpjNZgoLC8nPn4qs0fqI5G7B3G5z8Pq2MtYUVR3RZ7C7ZGrbrdS2DzD6HABf0dxhc1LZah5wm7s/2YmsKNy1cs4grA2OaBt1joZYZyG+BUOBEL5hxGJvp6GjAgkJp8uBRq3ts216/DjS48dhd1qRwlymWCCIZnqK32BEb3/oNWpmZScxKzvJb3271cHe2hZ2Vbfwt03FbC4feEKXLz9UNPJDRSMqSSItVk9GrJG8tHiWTDSSYtIRq9ei16jQqFWocI9iWh0uGs026jttNHZ2C+WGThuOQYjvt3dV8PauCr91CQatjxA2kBarJy3GQFqse1Q5LdZAmk9YRoxOM2SVIQOhUknEGnTEG3SMSej9/sXHTgpp1Pm6xfn8cv4kmi1295/ZRovFTrPZTpPFRrPZfbPR3LWu2WKn1WpH6WNQebCi+d51u3jk8z3kJMaQbNKRbNKTEqN3/+/6SzLpSOkKjUnueh2n1w7o/2gedR7tEw2jQXxHgw1HE0L4hpHEmAwAFBRaLXVBZXjQaQxDbZZAEHV4xK/n9VAQZ9CycHwaC8encfmiKSGJLV9kRekWStX9t1WrJNJju7NKHJOTQmZX2rV4g5ZHPt9LUX3bID+Rm1arg1arI+hRZYNG7RbHsQZSTHqq2yzsrmkZcLu7P9mJoijcOQSjnHesmM0XJTVBxXz/5bwFIe/fJcu0WR1+Ytgjmj3L6/dXse1wc0j7tTrlkEfztWpVt1DuEsQe0Zxi0vPNwTo+Kjw84H6GQ4BGy6izEN/RZcPRhhC+YSTBmIYkqVAUmebOmqiowrZv3z5uvPFGAB599FGmTp0aERtuuOEGzGYzf/3rX5kzZ05EbIi0HwT+DHeFtmAf8f9h6TR+dewkatos1HZYqW23UNtupabrv2e5rsOK3GNY0SUrVLdZqG6zhMXmC+eM56J5E5EVBbPdSUOnO4NFfaeV+g4rjZ2e1+5R5Z72AFidLipazFS0DPxIvyf3rNvF6k93E6fXYtSqMWo1GLQq9/+uNGnGrlRpWhVY2tvIPmgnzmTAoOl+z9uuax+vbzsYVJaPr0rruGvtjpAv9mqVyh3Ta9JDn2HSx4R0M7Q8P4tjx6bSaLbRZLbR2GmjyWx3vzbb6OgjP7PjCMIyenL3Jzt5Y3sZi3LTujJqdP11Zcvoft2dQSNOrw1q1D9aRp2F+I4uG45GhPANI2qVhgRjKi3mOlrMtQHbdFhb2Fn5GWMS8xiTlDfk2Rw6Ojr47rvvvK8jQUdHB5s2bYq4DZH2gyDyDCR+feNap2cm9rsvlyzT0GkLKIrdy13rOiw0dNr6fPTeH69tP8RrXRO7dGqVX2aJtFgDM7OTfCbP6TBo1KglFbKiYHO6wy7coRZucbyxrJ7SptD6v1NWukZMg9ygJLRR1IG4+5OdvLCxmKnpCZh0GmL1GmJ8/+vcwi7Gu17btb5HO722V9aNUEae/3vlqf22sTldNJvtfsK4sWuE2fPaK5Q73W1q2y24QuwXhXVtFNaF9tRAkvARypoeglnLvtoWfqhsGnA/d3+yk2azjZtPmdGdJ1qtRqUKTyiNEN/RZcPRihC+YSbRlOEVvooi94rfrWrZT5ulgXZLI5mJk8QXIBAMM32J31Anc6lVKjK6CmfMIqnftk6XTH2nlbvW7uT5jcX9tu0Lu0umqs1CVZCjySpJItmk88b8psQYODU/izWFhykPcvR3Ykosly2c7E1lZvX8d7q61jmxdb022xy0mi3IkgabS/a2G0xsc09C+dz9oVWr/ARxq8VOdRAjsV+V1nHW859y3qxx6DXuoiB6tQqdRuV97V6vQqdRMy4xhimp8ei73tepVQELgCiKwv9+vI0HPtsTlP0TU2LJjDN2Z9WwOWi3OQf0saLgzcZxpDzxdRFPfF3kt06rVgUsnuJXRMX7OnCbrw7Usm7/ALFEuM/b2nYLvzuxAK1ahValcv9Xq9CqJe86tUoaVGx7NIjvaLDhaEborjCTZMqkjF04ZQcdtmbiDN3P2RRFoaqlBIDUuLHoNcZImSkQjGp6it9VywqG9CKiUavIijfxzAWLyIo3Dvh4/aZl07ls0eSu4hxW6jutNHSFM3jCHHxHcgNlmZAVxTuxrnCQdpc2drClookbTipgbGIMWfHGPiu4ebI6FBQUYDKZvOudru6cwh4x/NiXe3n2u+BuAOaOSSIvLaGrUIeDTruTDpvT77/VGVxJbIdL9sb7hsp/91Xx332Dz0ahkiQ/Iex53RqCLWkxBhZPSEenUaFTq9Cp1eg0KiTApSg4ZQWXLOOSFewuGYdLweFyYXfJPrmfZe9NS6fdSWlj+6BzO3twuGQcLpn2I9tN0Dz7XXFQ/cctgiVUKOi1Jeg0ah+xLHUL5i7xXNnSSVkQ6Qvv/mQnnxZXc8qULL/96dRqNF371al9BbnPssp9w+Rrg2/bx77cG1SFRyF+B48QvmHGM8ENoLmzxk/4NnVWYXW4HzMOZe5egUAwMHesmI3D4aC+vp5bT542rMeF4MItJqcGt0+Lw+kVyR5x3NBhpb6ze11Dh5XCulaazKGJvrd3lfP2rnLALd6y443kJJrISYxhbKKJsYkx5CSaSDOosVgcyD1y9GrUKmLVKmL13VlunvrJIjLiBr4BCHYU3umSMTt6C+IOH6Fs7rH+ywO1bA3i8X64kBXFO3I+WDaVN7CpvCGMVg2OFJOOjDgjkuTuExL4lEaUUFBQFPdEb1lxf3ZZVnDJCk7FLc6dLgWH7BbnZrsT12BigQbALcjdrzscod/s9Mc3B+v55uDAxVqGEiF+B4cQvmFGrzFh0sVjtrdhsfvH0lW1uO9QNSod6fHjI2GeQCDw4daTp1FYONjx0METrnALD0athnFJGsYlxQzYNpQJXT3LPMuKQmWr2Z379lBgAaZ9v4QxCV2CuOv/2MQYxiSavEI5NUYf1PGDRaNWEa92p1ALhVB8cdupM/jjshnYXTK2rmp4Nqfss9z13yVj9yy7uto4Xb3a2V0yG0rr+KEitDR7sToNeo0au0vG3rX/4abRbKcxxBuocKMC9Fo1GpWERiWhktzhDWqVhFqSUEkSapX7SavT4UCv17vDH5DojoCQuvq44p4sGuJn0qkld6VIWQlLSI9geBDCdwiYO/40DJpYtJruH3en7KCm9SAAmQkTUauE6wWC0UxP8TtY0Xukx+2L25fP4n9Pm0l1m4XKVndWiMqWTipaOn1em6lpt/hN3HO4FMqaOv0KiPRELUlBjfAN9YjWUBXzCIVQxHcgOxRF8YY22F3dItv9Wva+dvTz/ps7yvhw78Ap1QCmZyaQn57gFu/O7v16xLzd2WO5a53N5RrUBM++kCG00fOOI49v7ondpYArOBvUkjv0QqNSoVG7xbmma1kl4f1/uNU8YGl2DydOTBejvYNAqK8hwDe8wUNdWxku2X3ijUnKG26TBAJBFOJ70RrOC1go4RY5iTHkJMawqI+HVHani6o2C8U1TWwuLEGJSaLW7KCipZPDrWYqWjqp7xFDGspj7bs/2ck/NpewYHwaGbEGMuLcxToyunIlZ3S9NukGdzkbKLPDUIuLIxXfkiShUbtFlCnAdsHwy/kTgxLgR3ID0FOge4SzZ/nxrwp5LsiJn6flZbFscqZ31NvhUrC7/PfneW21O2hua0NnMOFS6H7f72ZApsViC1pwDgaXAi6njFuyh4fBpvsb7QjhO0wcbnaf0EZdHImmjAFaCwSC0UKkLlrhCrfQadTkJseSblCRbKmnoCDfb3IbgNXhorLVPUL8xIZC3ttdGZKt5S1mylsO9dsmVq8hI9YthtPjDGTEGknvEsqe5Yw497JvNbW71u7oN53ZcIiLSItvjw0Q3M3QYBhIoD99wSIyg5j4OdhS2j0nXQYilNH3KxZN5tcLJvsJ6J7/7U7ZHcfs7KeNz+utlY3sqWkN+rMJBocQvkOEosi0W5twyU4STeloVFokScWYxLxhLR+an5/Pxx9/7H0dCfLz83n77bc5dOgQeXmRGe2OBj8IBNHGcIVbGLRqJqfGMzk1nmWTM0MSGHPHJJGTGEN9h9WbF9ls7/14ucPmpMPWzoHGgSurGTRqMuIMOLpSxA3E3Z/spMls44/LpncX5tCqUavCU24+GsR3NDDU4vtIjz8cdhxp6ItgYITwHSK2l6+ntq2MBGMax00+j7njT8PuPPLKPaESFxfHokWLhv24PW1YsGABcXFxxMbGRsyGSPtBIIhGIhFucaQCo8Pm6C4Y0iWI63q8ruuwUtthDZi71up0cSiItFW+PPl1EU/2yF+rUUneXLS+Veo8y/oeuWq9bXzWf3mghrVFweWvreuwuvPXqiQ0XSm4NCqpx3/VoApKiNyxboT4PvoJWfi2tbVxwQUXUFZWhkql4qSTTuKZZ54ZCtuOCFmWOdS0m05rCzGGRMYnz0AVprvzYIg3plLdUkpVSzHf7H+TeFMa07IWo1arh80GiLwfPDZUNO2l3rGf2CaFKYZjImJDNPgh0jZEix3RYoPol24bfjVPotPawsGGncNmg/8FXmZedjspRjuNFh1bquK4ffmcPi/ssXotsXotk1LjBjyOxeGkrt3qV366rsPK+7sr+L5XRoXedrjzBwTGKStdI82ByxUPDpm8FDOJBicuRfKz4Zlv9/PMt/sH3INKkgIKYq06sGCuabdwuNV35DuwDXd/spOvDtRy5rQcnxLU7jLURp/XpgDrtWpViGWTZXLi7cTqnMgK7G80RUB8K8TpXOjUMkatTGXb0FZa9eB/bvS0Qc/ty2cL0XsESIoS2jzLc845h7KyMu69917279/P888/z69//WtuueWWfrfbsmULAPPmzRu8tUFSWPUtew5vwO7sPpF1GiPTxyyhIPv4oPcTSmxQT77c9yplDTtRULoSpkioVRqmZBzLwklnh7SvwRIuP4TDBpvTjMslo1ar0GtMEbEhGvwQDhuOpF8ebb44UhtEv4x8v3z009dRnLswarvDF/QaAydMPnXI/eArtJZNaGTllEY/OywONWuKU/j8YAoXzs3l/FnjvBXsbF1FOTxV7Kw+y1aHC4vTt53c1c7Z9b57ud3q8JvoN5ANw8FQ2aCSJB9x3FMsq6loMVPS0O5ng93lFsoJBqefDedMz+Gnc3K9hTw8RUG8r33Wu+w2ykpLmFEwlcS4WHQDCHBPn1g2oZEFOW140lLH653o1AprilNYMmXZsJRN/mj3Bo7JbifR0P3UQiVBStxUbjzlp0N27OHUa5EgpBHfxsZGioqKWLVqFeeccw4Au3fv5s033xxQ+A4XhVXfsu3QJ73W250W7/qh/jHddOADr+gFusQvuGQn+6q/Axhy8evxg8vlotPsLk8aYzJhZ/j84LGh4kAdz9/7EQpwxf+eybhJ6cNug8Vio/JgLQA5EzLAyLDb0JPh7JPRYoewQdjQ04Ys014sTvBEJBi0aowaeVhs8IiXDcWfc9603jG2Rq2L86bVcXpBNjeesmRIbLhzzXbuWbeLZRMa+7UBYEzyfC6cOwFnV+EH93/Zm0fWKSs4Xe4JVZ4CEb2WvW3d+9ha2ciu6haAoGwYrPiVFaWr+l7/o+O+Nhi7a5742fD+Hnh/T2gTJKF7pFzrFcnd1e/0ahUtFjv1nTY/G1qtbpmUYHDbfd60Ot7Z+zkry+o5b9Y4nxLYWm8pbN91Rq065Hk9d63dwYbiz7l4bh2tVg1tNrcN8Xpnlx3befRThlT8Hs2EJHzXrVsHwAUXXOBdt3TpUr777jucTicaTWRDhmVZZs/hDf7rFP9JEDsqPsWkS0AldT++GptS4H3tdNqpbj0AgM1mo81ZRVWLGr2lOyevWqUhO6m78prV3kF9ewUALtlFUc3GXrZ1j/xCce33TM08njZr35MZwJ0BIjUux7vcaq6nzdJ/1Z5YQzIJxjSvHxQUb7JuGRlJ6e2HxJh0vxRs9W3lWB39x7+lxI3BpIv3Lle3HsDp7E7+LSsyO8o/RVZcOBwOmurcd/Iun7yLOyo+6/Vd9GRM0hRUXTmPnbKT6ub+091IkoqcZPfkNVmW2VX5JbLiQlFkutyPosjefrGj4lMSjGl+36fZ1kZjR/85LQ3aGNLix3mX262NtHT2/j59/QAqVD4/gIqioCAH7JMe4o2pJJjSvMsN7ZW0tDcE7JcekmOyiDEkepdrWg9ic5h97OiNJKnYc3gD+ZmLUKlUVDUX45L7v0BlJU1Co3I/+pNlmcPNRf22lxX/81MBlAHOz/7Otb7QaYxkJOR6lzusLTR3Vntt8PWDAijIKIrkvTjtObyBzPhJdNj6r+oVa0gmyadSY2NHFWZb/zOyE2MyidEleP0gKzL+JSLc+PphoHMtEBkJE9BpDN7liqZ9+CZR7ekHAElSe04RFAL/VvoiqVTkJHVPFLU7rf32SwCNRkdWwiS3DbLMrsovkBUXejXe30edGr/zMzlmDBkJ3bnU2iyNtJr7/+006RNJic3yLjd31tJhDfx9XjJPwxhjMw4X+BadU0nuGmQ6jYoUXRGHGvb08kWgc80xwFyOtLjxGHTdI+JXLozBqE7CIO1DLQV+AOtSJH42q53LFrtvAgY615BUjE2e6l20O63UduWR700S/956kH/9cJCVU7pDPyRA1cOes6fWc1r+ZH5+zEScsgKKHpNhDBaHE4vDRauliTZzbXcRj66Syb45fc0OPa22eMx29wi4pLRS21bbNclQ5uyp9b38oCB5v5sVUxopbjSQbOw/LVhlm54mS3dowsSkTmJ1/W9T7TACKq8f1JJCsrF3jPjZU+v5x9Z9PLNhP/sbjVid3dpnRno7viHWEqDXqrpiuzUYNCoarGnE6HTE6DXE6yQyY5u9Md/7alvZXtXIJcfUe4+vVSs4XJJXfAPIzl3ctXYKd6yY2+9nEvQmJKV66NAhJEkiJqa7OtD48eO9702aNGnAfTQ2hlalJhRq2kqwO2z4xmQ5Zf/8kU7ZyYai11FJ3bG2K/Kv8b5utzbx7aE3upbcZRary7biVU2ARq3nlMmXdx+3vYQdVWsBcMkOZPpPaO2SnXyz/x1aLP3XfU80ZLFw/Pne5T01X1LZ2n8N78y4yWTETvL6QUFBb9B6Pg1O2X3i+/phQvIx5KUd593Hd2Uf0GHr/3ualrGUsYnTvcvfHHgHu9PsXZYVF07F3vV5fS6uqEBxfz9WR2ev76InyyZfhk7tvoBbnWY2HHijz7YAKknDaXlXAd39wak4UWkkMnOS3G00Es4uUef2wxucOuUq7z7Km3dTWPdlv8eJ06dyfO7PvMtFdd9Q1ry9VztfP6hQo1J1/xC7FLv7/QB90kNOwnSmZy71Lm869DGt1uqA/dJDXtpxTEg+xrv8Xel7dNqbvXYEQiPpsDtsFB76nsz4yXxd/BZOuX9xtXjCRcTo3D5VFIUN+/v/bmTF1fUZPeen7P0ePPT0hVZt4OTJl3nfr2krYUf12n6PY9ImsmTiL7zLBxq+p6Rxs9eGQH6QZbw3WHaHje/2v0+Ltf8JR5lxU5idvdy7/EPFWhrN/YvyicnziNOnes9Pl+xACZDX09cP0zNPJieh++b8m5J3sLvMvbbxZcHY80kydQu/r/e/6b7583zeAH7QqTTgI32tDnO/56dKpeE0n/OmurmUw44tffZLAIMmlpMmXQx4zk8rTsXdBzxiwfMb5fHD10VvsbRrG4B9dd9wKMC55ktaTC7H5JzpXd5+eD21HQcCtpUVFxqVHY1KjcPZfe3QqJy4da7cpy/y0o5nQnK38Piu9D0sjrZ+bZubfQbpcRO8y18Xv8UYkwWnIge6B+pCi06tUHjoe9LjJgx4riFJrMi72rvYZq3nu0N9bzM2Bv6w2C2uPLJAJcmoVf7XMoNWJkX6nq+LtgIQo0tk8YRfoAXitdDRup/G1s3dZgA6QKfCfdprISkpmwXjzvO22V39KYfbKtzlhWUnGlXv80FWJFyy2/c6Pdy5tAOd1ozHYT0DNhUgTjcdk24WVpuDhsZGtHE/oNDmfd/zwvPaJStsqRiPU1ZI0Lv9oFE7AvZkg0bmmoU1KIqKL0um0mju1kTnzSpB6vuLBOCD3XE4bA7MNlA0do7P3uV97/gcOGGs7OcHg8aJw6XFV7Lp9FBcvoPnP4fzZ41DEDwhCd/Ozs5ekx48sVydncHNkC0rKwvlkCHR4WpCi3/JTie979Y0GFDTLUB8bXIqVv99BBjs0MgGv22scqd3GwUzLnwv5p4TQIVE94+mwyL3srUnkt3odxy7UzXgNi6zlgaLjx8kCSeBBYzHD9Y2hbLO7uOoHSa09D9q0d5kpaylexutK7YroKPLDuzIXRd038+twei1zYWz13fRk8ryw96LjUtxDvj5VYrG6zN3fzAh40KlBo1JG3AbtWzy83OnyzbwcRz+21hdBNzG1w8aSY8Wo+9ecOK+MevLD44Old9xJIcRLbH9zbehs9lJWVv3NmpnDBosXjsCocWECg0N9U1Ym8rQyLFI2PpsD1B9uA6N5B7hVBRl4L6JAzXd34GCjCvATaKvL3qeaxa5Y8DjqJ0xftuYXbJPn7MH9INa0qH1yS4q27RBnWu+x1Ec+gG3sbTJ2Og+PxVJwaUEHln3+KGt0UJZc/dxNHKM37kWiPqaJlpV3d+fVolF8fF1ID9oiPGOuiooA56fKtn/89tkM3pV/5PN1K4Yv/NTgwmZ/q8dKqd/H7D1ca75Ilt1ftu4nH1/nx5faCUjMbrukWq70olL6b5+BPJFZ7Oj17mmHWDgo6m+HXNj9zYaOQYZxf199PG1GlSxSKhoqG/C0qge8POjSH6f36FYBtxGq5ZA7ftUwIlN6ejVztcPKkfPc801sG02/+uaw6lBSwxaNbhUduxK75s6ncqA1ucJho447PQYVu1BgmIg3tkOahiTHkO1IxGL3I8gVcPP88ciK07qnO6BH5vc1ufvZqzGhFrScc3ssehU3b8dB22lAW9mffnTohyf65qDQ/Zyv/ddir8fJCRidAm99vOLqRnEquUh1VVHIyEJX6PRiCz7f6HmrvjRhITeX0ogcnNzQzlkSNS0OTlc7f8jGugx3bik6SSZsr3L6XHdNrkUB/Ed7h8/h9NBY2MTKSnJaDXdF2yVpCY1tvsOy+6ykGyO77KhmPK27jQknguUux549w9ialImycbuUblA6LQmEg3dj1LT7Al02vq/szNqE+i0N3n94FKcOOzuH2+dTucXa+TxQ5w+GaPPSZVoMfhNdglEvDEDg6b7ZI8za3G5ugV2s7mK0mZ3gLzvd+DEgqPrQidJUq/voidpsblem2XFRVzHAFkxJIn02FzA0x8sv0lQkAAAGb5JREFUqFBhtzmpr3Y/6kzLSkan7+76Ocl55KblepetzjTSLMn9HkanMZJozPQuW+xJtNt6fw5fPyiS0/vZ3csyqi4F25cfYvSJ3lFVgESrkU5La8B+6SHOkIZR2502LsGso679oNeOQDglKxISqWnJZMbnEtuh6jMswkNK7DjUXT/eiqIQ0/sa6UezuYqylu1+6wY6P1UqDakxY73v2V0WUsz9/9Zo1Qa/0U6LI4UMa7rXhp5+UBQFRXL5fTcTU+Zg0s3o9zhGbQJxhu5+kmyNwero3wlx+lRarbXdv1OS4u0DPfH4YaBzLRBJpmy06m4RZ+rAb1gskB+c+AsOlaTq9/xUSSpSY7tDEDrMbdiqOvrslwBqtY4U0xjAfX5WVtv6/PweslMmkpua613utCeRFeBc88WgjSPekOpdTrHGY3FMDNjW4wtZcuDAicPVdaOqxs+2QL4IdK45XP3fMCaasrxPsQBiO1Q0dlZ4vw+XouB0ub8rtcqdncGJ+/c4NS2ZjLjcAc81399BAKfsIKHT0Hd7oMVSw8Hmrd5iCpJ7NwDeErvg74de55o9hQxb/wWa9NpYEgzd4Vu+17VmcxXFTT94P78HO1YUxYZO7c5IkZs6k1hd/7/RcfpUjLo4bDYb1dXVTEyfi6Tq/zctwZjJfwu3I+O+oZekwLeYGnX3tWugcy0Qvtc1l+IirqP7evRNWR3F9QfJS+8+HxUUrM7eYVRtdhfnzszt91iD4WgX0iEJ3wkTJqAoClarFYPBfRJ5HDRmzJig9pGSMnQzU5OSkihs+MJPtKl6BJXrNEYWTT2r33Q96aluQWM2m3G0FjI5e+BZylm4Y3HzXHN5dVOhNz4y0EmjVmlYlHdmyKnNUgjOd7Ise/2goGCzu3+ItTqtN+F6f34I9jh+2/T4XmVZpmpLIXanxT+uFRkk94XFoDUN+F30JC01Pei2vv1BVmTaW91iIyUz0ZvnUqcxsiBvZQ8bUhhDqI+OUoDeF1ZfP3St8b7nvrBIQfXJ7qOkhNQvwf3dTJSn97CjJwo6jYGC8ceiUqkGdZ6mpqb2+35vXwzu/PSca8GTAuQGtEFBQXYpXbGMsteGuZOXhZzSK9jzJlse5+2Xnj7Qk37Pz0F8N/2dnz5r/dqEen4ajUYa6pqC7peBfq97otMYOXbKcj8bUvo41/qjv+/G3xcKWp+roue7CfYcHex3I8uzu38vkXDK7nkJWo2maxReRqcxes/Pgc61QGSkZfb7vizLHN6yByQLThSsXfMxDF2pyCAYP3Sfa8Hi+914votWa4f3+B4MWjVaDeg0euZNPjXofmk2m6muriY3s3dFwUD8Oi2bF7/eiq2PWG2DVk2MPias52e6z3WtIBfuWruNZuvbfpk1eqLTGPn14jOGJPXg0S58Q/LY8uXueLa33nrLu+6LL74gLi4u4hPbAFQqFdPH9D/zdvqYJUOao1KtVjMl49h+20zJOHZI8/lGgx+EDdFjQ7TYIWwQNkSbDdFiR08bDFp31oFI2WD0FNjQqjFquq9Vw2WD5/gefO0YDhtOmHyq3/F72jHUNtyxYi6SZmaf7xu0ahZPPiUieeD7wmazceuttzJ//nwWL17Miy++2GfbvXv3csEFFzB79mx+/OMfs3v37oDtnn766V4ZwxRF4ZFHHmHRokUsWLCAhx56qFckwkCEpFaTk5OZNGkSDzzwAEajkYMHD7Jx40Yuu+yygTceJjypbyKZH9OTqqy49nu/mfHDmcfX8zm3lq73Wz+cfvAco7LkPxG34bu9/424DZHO2RoNdkSbDTafCZmj2Q+j2YZosSPa+iVE3g/gjukwatQRseHrkk+9/cGgVZNgiB02G2485ac8+qk7e4PJZ+RXpzFy/KRThu3cCJaHHnqI3bt389JLL1FVVcXNN99MdnY2K1eu9GtnNpu58sorOfvss3nggQd49dVXueqqq1i3bp3fiPyHH37IE0884U2d6+Hvf/87H374IU8++SROp5M//vGPpKSkhKRDQy5g0dTUxE9/+lMqKipQqVQsW7aMp556asDthjshcndFpFZiDAmDqkZ0JIUCAFwuF3urv6bd0kScMTkilds2b97MTXf/lsTUGK77zQ0sW/CjYb9L/P7771mxYgUAL7z8V85d+Ytht2Hz5s38+jcXEROn5+777mb58edFsErX4PskHHm/DJcdR0K02FBctZWDlfuZkJPHlOxIVm4b+d/FkfTLaPBDtNgh+mV4bTjSfvnIpx+hUZk5b3ZBRPxw19ptfLT7G5KNDk6eMpk/nHLmkNsQql4zm80sWrSI559/noULFwLw1FNP8d133/Gvf/3Lr+2bb77J008/zfr165EkCUVRWLFiBb/5zW84//zzcTqd3HPPPbzzzjtkZWUxd+5cHnjgAe/2S5cu5frrr+f8890Zr9577z3++te/8tlnnwX9+UKOT0hOTmb9+vUDN4wwKpWKCamzImqDWq1mZs5JEbVh9uzZvPzMewCkpaVF5GIya9YsNm3aRElJCYsWLYqIDbNnz2bt+18AkfNDNPTJaLEjWmwYmzyNjlqJsckFo7ZPCBuiyw7RL6PLhptOG55Kq33hztPr7gM3nRadZYr37duH0+lk7tzu1H7z5s3jmWeeQZZlvz68Y8cO5s2b542flySJY445hu3bt3P++edjNpspKiri9ddf5x//+IffcWpra6murubYY4/1O87hw4epq6sjPT24OUAhC1+bzcZdd93FJ598gsFg4NJLL+XSSy8NentPFoiRgMVi8fs/UklOds9+dblcEfN/cnIy6enpyLIcURsgsn4IB0dLv4wGhC/Dh/Bl+BC+DB9Hgy//uMRdxCdar1v19fUkJSWh03Wn+0tNTcVms9HS0uK99nraTp482W/7lJQUiovdxani4+N57bXX+jwO4CdwPRM9a2pqhk74BhvH0ReFhYWhHjLiHO0zHIcT4cvwIXwZPoQvw4fwZfgQvgwfwpdDh8Vi8RO9gHfZbrcH1bZnu0BYrVa/ffd3nP4ISfiazWbeeOMNnn/+eaZPn8706dMpLi7mlVdeCVr4FhQUDNwoSrBYLJSVlZGbm4vRaBx4A0GfCF+GD+HL8CF8GT6EL8OH8GX4EL4MnVAHKPV6fS/h6Vn2pL4dqG3PdoHwFbl6vd7vOKF8tyEJ31DiOPpiMJNxIo3RaByRdgP88MMP3olla9euZf78+RG14b333mPx4sURtSFSfgg3I7lfRhvCl+FD+DJ8CF+GD+HLoSMjI4Pm5macTqc3tW19fT0Gg4H4+PhebRsaGvzWNTQ0BBWmkJGR4d13Tk6O9zW45+4ES0jCN5Q4jr6I1hiVQBwNsUFWqxVP4g6r1RoR//vaYLPZIm5DpPwQLo6GfhktCF+GD+HL8CF8GT6EL4eegoICNBoN27dv9w4qbdmyhZkzZ/YaEJ09ezbPP/88iqJ4szps3bqV3/zmNwMeJyMjg+zsbLZs2eIVvlu2bCE7Ozvo+F4IUfiGEsfRFyLGd3jxtb2srCwij3p8baiuro5IH4gGP4Sbkdwvow3hy/AhfBk+hC/Dh/Dl0GE0Gjn33HO58847uf/++6mrq+PFF19k9erVgHvQNC4uDoPBwMqVK3n00Ue57777uPDCC3nttdewWCycfvrpQR3r5z//OY888giZme5KhI8++mhICRYgROEbShxHX4gY3+HF9y43Nzc3Iv73tSErKyviNkTKD+HiaOiX0YLwZfgQvgwfwpfhQ/gydAYzOLVq1SruvPNOLr74YmJjY7nuuuu81X4XL17M6tWrOf/884mNjeXZZ5/ljjvu4PXXXyc/P5/nnnsu6DCUyy67jMbGRq699lrUajU/+clPuOSSS0KyNSThG0ocR1+MxBibkRwb5HtDYjAYIvI5fG3Q6/URtyFSfgg3I7lfRhvCl+FD+DJ8CF+GD+HLocVoNPLggw/y4IMP9nqvqKjIb3nWrFm88847A+7Tt3CFB7VazapVq1i1atWgbQ0pM7ZvHIeHvuI4BAKBQCAQCASCaCIkteobx7Fz507Wr1/Piy++yK9+9auhsk8gEAgEAoFAIAgLIRew6C+OQyAQCAQCgUAgiFYkxZPjaYjZsmXLcBxG0IOeX6+nPvZw2+ByuQB3fE6kbPAlEjYIBAKBQDBSmDdvXqRNGBJCHvEVjCyiQeBJkuSdDBlJGwQCgUAgEIxuhm3EVyAQCAQCgUAgiCQiFYNAIBAIBAKBYFQghK9AIBAIBAKBYFQghK9AIBAIBAKBYFQghK9AIBAIBAKBYFQghK9AIBAIBAKBYFQghK9AIBAIBAKBYFQghK9AIBAIBAKBYFQghK9AIBAIBAKBYFQw6oVvbW0t119/PQsWLGDJkiWsXr0am80WsO1vf/tb8vPz/f4+//zzYbY4elm3bl0v/1x//fUB23777becddZZzJ49m1/96ldUVFQMs7XRy9tvv93Lj/n5+UydOjVg+3POOadX2/379w+z1dGH3W7nrLPOYtOmTd51FRUVXHLJJcyZM4czzjiDr7/+ut99fPjhh5x66qnMnj2ba665hqampqE2OyoJ5Mvt27dz4YUXMnfuXFasWMEbb7zR7z7mz5/fq592dnYOtelRRyBf3nvvvb188/LLL/e5j3/84x8sWbKEuXPncuutt2KxWIbD9Kijpy9vueWWgL+dv/rVrwJu39ra2qvtwoULh/MjCCLAqC5ZrCgK119/PfHx8bzyyiu0trZy6623olKpuPnmm3u1P3DgAA8//DDHHXecd11CQsJwmhzVlJSUsGzZMu655x7vOr1e36tdVVUV11xzDddddx1Llizh//7v/7j66qt5//33RWlh4IwzzmDJkiXeZafTycUXX8zSpUt7tXW5XJSVlfHyyy+Tm5vrXZ+UlDQMlkYvNpuNG2+8keLiYu86RVG45ppryMvL46233mL9+vVce+21fPzxx2RnZ/fax86dO7ntttu46667mDp1Kvfddx+rVq3i2WefHc6PEnEC+bK+vp4rrriCn//85zzwwAPs2bOHVatWkZaWFrCf1tbW0t7ezvr16zEYDN71JpNpOD5C1BDIl+C+ttx4442cd9553nWxsbEB97F27VqefPJJHn74YVJSUli1ahUPP/wwt99++5DaHm0E8uVtt93GjTfe6F0+fPgwv/zlL/sUviUlJSQmJvLhhx9616lUo3488KhnVAvf0tJStm/fzjfffENqaioA119/PQ8++GAv4Wu326msrGTmzJmkpaVFwtyo58CBA+Tl5Q3onzfeeIMZM2Zw6aWXArB69WpOOOEENm/eLO62AYPB4CcOnn32WRRF4Q9/+EOvtpWVlTgcDmbNmhXwJmM0UlJSwo033kjPauwbN26koqKC1157DZPJxKRJk/juu+946623uO6663rt5+WXX+b000/n3HPPBeChhx5i2bJlVFRUMHbs2OH4KBGnL1+uX7+e1NRUfv/73wOQm5vLpk2b+OCDDwIK3wMHDpCWljZq/BaIvnwJbv9cdtllQV1b/vnPf3LxxRezbNkyAO666y4uu+wy/vjHP2I0GsNudzTSly/j4uKIi4vzLt9yyy2sXLmSU089NeB+SktLmTBhgrimjzJG9a1NWloaL7zwglf0eujo6OjVtrS0FEmSRvUP90AcOHDAb9SxL3bs2MH8+fO9y0ajkenTp7N9+/ahM26E0tLSwvPPP8+NN96ITqfr9X5JSQlZWVlC9PrguYH6z3/+47d+x44dTJs2zW+Ucd68eX32u579NCsri+zsbHbs2DEkdkcjffnSExbWk0C/neDupxMmTBgSG0cKffmyo6OD2traoH47XS4Xu3bt8uuXc+bMweFwsG/fvnCbHLX05UtfvvvuO77//nvvzVkgSkpKgvK74OhiVI/4xsfH+z1SlmWZl19+mUWLFvVqW1paSmxsLDfddBObN28mMzOT6667jpNOOmk4TY5aFEXh4MGDfP311zz77LO4XC5WrlzJ9ddf30uw1dfXk56e7rcuJSWFmpqa4TR5RPDqq6+Snp7OypUrA75/4MABtFotV111Fbt372bChAncdNNNzJo1a5gtjR4uuuiigOtD7Xd1dXWjvp/25cucnBxycnK8y42NjXz00UcBR87B3U8tFgu//OUvOXjwIAUFBdx6662jSgz35csDBw4gSRLPPPMMX331FYmJifz617/2C3vw0NbWhs1m8+uXGo2GxMRE0S978Nxzz3HeeeeRlZXVZ5sDBw7gdDr5yU9+Qm1tLfPnz2fVqlW9znvB0cWoHvHtycMPP8zevXu54YYber1XWlqK1Wpl8eLFvPDCC5x00kn89re/ZdeuXRGwNPqoqqrCYrGg0+n4y1/+ws0338wHH3zAQw891Kutp50vOp0Ou90+XOaOCBRF4Y033uB//ud/+mxz8OBBWltbueCCC3juueeYNGkSF198MdXV1cNo6cgg1H5ntVpFPw0Cq9XKddddR2pqKj/72c8CtiktLaW1tZXf/va3PPXUUxgMBi655JI+R4hHE56niRMnTuS5557jggsu4E9/+hPr1q3r1dZqtQKIfjkAFRUVbNy4kV/+8pf9tistLaWjo4NVq1bx2GOPUVdXx29+8xtcLtcwWSqIBKN6xNeXhx9+mJdeeonHHnuMvLy8Xu9fffXV/PKXv/ROZps6dSp79uzh9ddfZ+bMmcNtbtQxZswYNm3aREJCApIkUVBQgCzL/PGPf2TVqlWo1WpvW71e3+tH2m63Ex8fP9xmRzW7du2itraWM888s88299xzD1ar1TsR5s4772Tr1q289957/OY3vxkuU0cEer2elpYWv3V2u90vnrpn+0D9dLTEUQZDZ2cnV199NWVlZfz73//u0zd/+9vfcDgcxMTEAPDII49w0kkn8fnnn3P22WcPp8lRx7nnnsuyZctITEwE3NeWsrIyXn31VU477TS/tp6QJtEv+2ft2rUUFBQwefLkftt99NFHSJLk/Q14/PHHWbx4MTt27OCYY44ZDlMFEUCM+OIWD3//+995+OGHWbFiRcA2KpWqVwaHiRMnUltbOxwmjggSExP9sjJMmjQJm81Ga2urX7uMjAwaGhr81jU0NIgJBj3YsGED8+fP7zdziEaj8Zv97Rk5Ev2yN331u74ea4p+2j8dHR1cdtllFBcX89JLL/UbK6nT6byiF9wCLicnR/RT3OesR/R66OscTkxMRK/X+/VLp9NJS0uL6Jc+bNiwgVNOOWXAdkaj0e/GNyUlhcTERNEvj3JGvfB98sknee211/jzn//c78jaLbfcwqpVq/zW7du3j4kTJw61iSOCDRs2sHDhQr98koWFhSQmJpKcnOzXdvbs2WzZssW7bLFY2Lt3L7Nnzx42e0cCO3fuHHDU4Ze//CVPPvmkd1mWZYqKikS/DMDs2bPZs2eP93ExwJYtW/rsdz37aXV1NdXV1aKf4u5n1157LZWVlfzrX/9iypQpfbZVFIVTTz2Vt99+27vObDZz6NAh0U+Bv/71r1xyySV+6/q6tqhUKmbOnOnXL7dv345Go+kzz/doQ1EUdu3aNeBvZ0dHB8ceeywbN270rqutraW5uVn0y6OcUS18Dxw4wFNPPcUVV1zBvHnzqK+v9/6BezKM5yJ58skn88EHH/Duu+9y6NAhnnzySbZs2dJv/OVoYu7cuej1ev73f/+X0tJSvvzySx566CEuv/xyXC4X9fX13sdzP/7xj9m6dSvPPfccxcXFrFq1ipycHJHKrAfFxcW9HtX19OXJJ5/MP/7xDz799FNKS0u5++67aW9vDzgxZrSzYMECsrKyWLVqFcXFxTz33HPs3LmTn/zkJ4D7cXF9fb03vu/nP/857733Hm+88Qb79u3jpptuYunSpSKzC/Dmm2+yadMm7r33XuLj472/m55QEl9fSpLE0qVLeeKJJ9i0aRPFxcXcdNNNZGZmisnBwLJly/j+++/529/+Rnl5Of/+97959913vekerVar95oE7oldf/vb31i/fj07d+7kzjvv5Kc//akIdeji8OHDdHZ2Bgxz8PVlbGws8+bNY/Xq1ezcuZM9e/Zwww03sGTJEvLz84fbbMFwooxinn32WSUvLy/gn6IoSl5envLWW29527/++uvK8uXLlRkzZijnnXeesnnz5kiZHpXs379fueSSS5Q5c+YoJ5xwgvLEE08osiwrFRUVSl5enrJx40Zv2y+++EJZvny5MmvWLOXiiy9WysvLI2h5dDJz5kzlq6++8lvX05eyLCtPP/20snTpUmXGjBnKL37xC6WoqCgS5kYlPftdWVmZ8otf/EKZMWOGcuaZZyrffPON972NGzcqeXl5SkVFhXfdW2+9pZx00knKnDlzlGuuuUZpamoaVvujCV9fXnrppQF/N//nf/5HUZTevrRarcrq1auVE044QZk9e7Zy1VVXKVVVVRH7LJGmZ79ct26dcvbZZyszZ85UVq5cqaxdu9b73ltvveW9Jnl49tlnleOOO06ZN2+esmrVKsVqtQ6b7dFGT19u375dycvLU2w2W6+2PX3Z0tKi3HLLLcrChQuVuXPnKn/4wx+UlpaWYbFbEDkkRQmQTVsgEAgEAoFAIDjKGNWhDgKBQCAQCASC0YMQvgKBQCAQCASCUYEQvgKBQCAQCASCUYEQvgKBQCAQCASCUYEQvgKBQCAQCASCUYEQvgKBQCAQCASCUYEQvgKBQCAQCASCUYEQvgKBQCAQCASCUYEQvgKBQCAQCASCUYEQvgKBQCAQCASCUYEQvgKBQCAQCASCUYEQvgKBQCAQCASCUcH/B8cWr7fe27DqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x550 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "import copy\n",
    "\n",
    "NUMERICAL_FEATURES = [\n",
    "    \"tloc\",\n",
    "    \"tmcCabe\",\n",
    "    \"assertionDensity\",\n",
    "    \"assertionRoulette\",\n",
    "    \"mysteryGuest\",\n",
    "    \"eagerTest\",\n",
    "    \"sensitiveEquality\",\n",
    "    \"resourceOptimism\",\n",
    "    \"conditionalTestLogic\",\n",
    "    \"fireAndForget\",\n",
    "    \"testRunWar\",\n",
    "    \"loc\",\n",
    "    \"lcom2\",\n",
    "    \"lcom5\",\n",
    "    \"cbo\",\n",
    "    \"wmc\",\n",
    "    \"rfc\",\n",
    "    \"mpc\",\n",
    "    \"halsteadVocabulary\",\n",
    "    \"halsteadLength\",\n",
    "    \"halsteadVolume\",\n",
    "    \"classDataShouldBePrivate\",\n",
    "    \"complexClass\",\n",
    "    \"spaghettiCode\",\n",
    "    \"functionalDecomposition\",\n",
    "    \"godClass\"\n",
    "]\n",
    "\n",
    "list_target=[repository1, repository2, repository3]\n",
    "\n",
    "tmp={\n",
    "    'repository': [],\n",
    "    'local_model': [],\n",
    "    'X_target': [],\n",
    "    'y_target': [],\n",
    "}\n",
    "\n",
    "    \n",
    "for target in list_target:\n",
    "    print(target)\n",
    "    tmp['repository'].append(target)\n",
    "    \n",
    "    source_set=dataset.loc[dataset['nameProject']!=target].reset_index(drop=True)\n",
    "    target_set=dataset.loc[dataset['nameProject']==target].reset_index(drop=True)\n",
    "\n",
    "    X_target=target_set.drop(['nameProject','testCase','isFlaky'], axis=1)\n",
    "    y_target=target_set['isFlaky']\n",
    "    X_source=source_set.drop(['nameProject','testCase','isFlaky'], axis=1)\n",
    "    y_source=source_set['isFlaky']\n",
    "    columns=X_source.columns\n",
    "\n",
    "    tmp['X_target'].append(X_target)\n",
    "    tmp['y_target'].append(y_target)\n",
    "\n",
    "    #1. Eseguo il clustering\n",
    "    km=KMeans(random_state=42, n_init='auto')\n",
    "    elbow=KElbowVisualizer(km, k=(2,20))\n",
    "    elbow.fit(X=X_source)\n",
    "    ideal_cluster=elbow.elbow_value_\n",
    "\n",
    "    \n",
    "    print(\"Numero Cluster generati: {}\".format(ideal_cluster))\n",
    "    km=KMeans(random_state=42, n_clusters=ideal_cluster, n_init='auto')\n",
    "    km.fit(X=X_source)\n",
    "    X_source['cluster']=km.predict(X=X_source)\n",
    "\n",
    "    local_model={\n",
    "        'Index_Cluster': [],\n",
    "        'X_cluster': [],\n",
    "        'y_cluster': [],\n",
    "        'Local pipeline': []\n",
    "    }\n",
    "    \n",
    "    #pipeline\n",
    "    pipeline = Pipeline(steps = [('scaler',MinMaxScaler()),\n",
    "                                 (\"model\", RandomForestClassifier(class_weight='balanced', random_state=42))]).set_output(transform = \"pandas\")\n",
    "\n",
    "    #2. Per ogni cluster addestro un modello\n",
    "    for i in range(0,ideal_cluster):\n",
    "        cluster=X_source.loc[X_source['cluster']==i]\n",
    "        indices=X_source.index[X_source['cluster'] == i].tolist()\n",
    "        \n",
    "        local_pip=copy.copy(pipeline)\n",
    "        local_pip.fit(cluster[NUMERICAL_FEATURES],y_source.iloc[indices])\n",
    "        y_predict=local_pip.predict(cluster[NUMERICAL_FEATURES])\n",
    "        #eval_and_log_metrics('Train',y_source.iloc[indices],y_predict)\n",
    "\n",
    "        local_model['Index_Cluster'].append(i)\n",
    "        local_model['X_cluster'].append(cluster[NUMERICAL_FEATURES])\n",
    "        local_model['y_cluster'].append(y_source.iloc[indices])\n",
    "        local_model['Local pipeline'].append(copy.copy(local_pip))\n",
    "    \n",
    "    tmp['local_model'].append(local_model)\n",
    "\n",
    "    #3. Per ogni campione identifico il cluster d'appartenenza e eseguo la prediction\n",
    "    y_predict=[]\n",
    "    for i in range(len(X_target)):\n",
    "        row=X_target.iloc[i, ].to_numpy()\n",
    "        row=row.reshape(1,-1)\n",
    "        index_cluster=km.predict(X=row)\n",
    "        local_pip=local_model['Local pipeline'][int(index_cluster)]\n",
    "        y_predict.append(local_pip.predict(row))\n",
    "    \n",
    "    \n",
    "    val_and_log_metrics(y_target,y_predict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hbase_e593f0efbf1144bcb5909d2630321e631a2e66bb\n",
      "Cluster 0: TF 82 - TNF 1805\n",
      "Cluster 1: TF 18 - TNF 133\n",
      "Cluster 2: TF 264 - TNF 6395\n",
      "Cluster 3: TF 81 - TNF 346\n",
      "activiti_b11f757a\n",
      "Cluster 0: TF 128 - TNF 711\n",
      "Cluster 1: TF 245 - TNF 5196\n",
      "Cluster 2: TF 18 - TNF 133\n",
      "Cluster 3: TF 3 - TNF 39\n",
      "Cluster 4: TF 27 - TNF 20\n",
      "Cluster 5: TF 122 - TNF 1968\n",
      "hector_29e88d0b988d9e5c8dc3b529414a270805ce0d7c\n",
      "Cluster 0: TF 286 - TNF 6359\n",
      "Cluster 1: TF 30 - TNF 59\n",
      "Cluster 2: TF 18 - TNF 133\n",
      "Cluster 3: TF 111 - TNF 459\n",
      "Cluster 4: TF 81 - TNF 1826\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(tmp['repository'])):\n",
    "    print(tmp['repository'][i])\n",
    "    \n",
    "    local_model=tmp['local_model'][i]\n",
    "    \n",
    "    for index in local_model['Index_Cluster']:\n",
    "        y_cluster=local_model['y_cluster'][index]\n",
    "        cluster_TF=np.count_nonzero(y_cluster.to_numpy())\n",
    "        cluster_TNF=y_cluster.to_numpy().size-cluster_TF\n",
    "        \n",
    "        print(\"Cluster {}: TF {} - TNF {}\".format(index,cluster_TF,cluster_TNF))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. CrossProject - LocalModel (Repositroy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CrossProject With FeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed=42)\n",
    "random.seed(42)\n",
    "\n",
    "class FeatureSelection_GA:\n",
    "    \n",
    "    def __init__(self,source,target,features):\n",
    "        self.source=source\n",
    "        self.target=target\n",
    "        self.features=features\n",
    "    \n",
    "    def run(self, size_population, n_iteration, goal, verbose=1):\n",
    "        self.verbose=verbose\n",
    "        \n",
    "        num_instance_selected=int(size_population/3)+int(size_population%3)\n",
    "        num_instance_crossover=int(size_population/3)\n",
    "        num_instance_mutation=int(size_population/3)\n",
    "        \n",
    "        population=self._gen_initialPopulation(size_population)\n",
    "        \n",
    "        fitness_value=[]\n",
    "        best_fitness=0\n",
    "        best_ga_instance=None\n",
    "        \n",
    "        #Valuto ogni istanza nella popolazione\n",
    "        best_fitness, best_ga_instance, fitness_value = self._evaluated_population(population)\n",
    "        \n",
    "        \n",
    "        iteration=0\n",
    "        while iteration<n_iteration and best_fitness<goal:\n",
    "            # Seleziono K individui\n",
    "            if self.verbose==1: print(\"Selezione\")\n",
    "            new_population = self._selection(population, fitness_value, num_instance_selected)\n",
    "            \n",
    "            # Eseguo il crossover \n",
    "            if self.verbose==1: print(\"Crossover\")\n",
    "            while len(new_population)<num_instance_selected+num_instance_crossover:\n",
    "                index_instance1=np.random.randint(low=0, high=num_instance_selected)\n",
    "                index_instance2=np.random.randint(low=0, high=num_instance_selected)\n",
    "                new_population.append(self._crossover(new_population[index_instance1],\n",
    "                                                      new_population[index_instance2]))\n",
    "            # Mutazione\n",
    "            if self.verbose==1: print(\"Mutazione\")\n",
    "            for _ in range(num_instance_mutation):\n",
    "                index=np.random.randint(low=0, high=num_instance_selected+num_instance_crossover) #Indice Istanza\n",
    "                new_population.append(self._mutation(new_population[index]))\n",
    "               \n",
    "            # Valuto ogni istanza nella popolazione\n",
    "            population=new_population\n",
    "            best_fitness, best_ga_instance, fitness_value = self._evaluated_population(population)\n",
    "            #Inserire qui l'interruzione basata su popolazione migliore\n",
    "            \n",
    "            iteration=iteration+1\n",
    "        \n",
    "        best_features=[]\n",
    "        for x, i in zip(best_ga_instance,range(0,len(best_ga_instance))):\n",
    "            if x==1:\n",
    "                best_features.append(self.features[i])\n",
    "                \n",
    "        return best_features, best_fitness\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    def fitness_function(self,instance):\n",
    "        \n",
    "        featuresToRemove=[]\n",
    "        for x,i in zip(instance,range(0,len(instance))):\n",
    "            if x==0: featuresToRemove.append(self.features[i])\n",
    "        \n",
    "        if len(featuresToRemove)==len(self.features): return 0\n",
    "        \n",
    "        X_target=self.target.drop(['nameProject','testCase','isFlaky']+featuresToRemove, axis=1)\n",
    "        y_target=self.target['isFlaky']\n",
    "        X_source=self.source.drop(['nameProject','testCase','isFlaky']+featuresToRemove, axis=1)\n",
    "        y_source=self.source['isFlaky']\n",
    "        \n",
    "        pipeline = Pipeline(steps = [('scaler',MinMaxScaler()),\n",
    "                                     (\"model\", RandomForestClassifier(class_weight='balanced', random_state=42))]).set_output(transform = \"pandas\")\n",
    "\n",
    "        pipeline.fit(X_source, y_source)\n",
    "        y_predict=pipeline.predict(X_target)\n",
    "        acc, pr, rec, f1, tn, fp, fn, tp = val_and_log_metrics(y_target,y_predict,False)\n",
    "        return f1\n",
    "        \n",
    "        \n",
    "    def _selection(self,population, fitness_values, size):\n",
    "        \n",
    "        total_fitness = sum(fitness_values)\n",
    "        normalized_fitness = [fitness / total_fitness for fitness in fitness_values]\n",
    "\n",
    "        cumulative_probabilities = [sum(normalized_fitness[:i+1]) for i in range(len(normalized_fitness))]\n",
    "\n",
    "        selected_individual = []\n",
    "        best=population[fitness_values.index(max(fitness_values))]\n",
    "        selected_individual.append(best)\n",
    "        \n",
    "        while len(selected_individual)<size:\n",
    "            random_value = random.random()\n",
    "            for i, cumulative_probability in enumerate(cumulative_probabilities):\n",
    "                if random_value <= cumulative_probability:\n",
    "                    selected_individual.append(population[i])\n",
    "                    break\n",
    "\n",
    "        return selected_individual\n",
    "        \n",
    "    \n",
    "    \n",
    "    def _crossover(self,instance1,instance2):\n",
    "                       \n",
    "        split_point = np.random.randint(low=1, high=25)\n",
    "        new_instance = instance1[0:split_point]+instance2[split_point:]\n",
    "        #print(len(new_instance))\n",
    "        return new_instance\n",
    "    \n",
    "    \n",
    "    def _mutation(self, instance):\n",
    "         #Indice gene \n",
    "        new_instance=copy.copy(instance)\n",
    "        for _ in range(0,3):\n",
    "            index_gene=np.random.randint(low=0, high=len(instance)) #Indice Instanza\n",
    "            if new_instance[index_gene]==0: new_instance[index_gene]=1\n",
    "            else: new_instance[index_gene]=0\n",
    "        return new_instance\n",
    "                       \n",
    "    def _gen_initialPopulation(self,size_population):\n",
    "        \n",
    "        population=[]\n",
    "        for i in range(size_population):\n",
    "            n = np.random.randint(low=1, high=27)  # Sostituisci 11 con il numero desiderato di 1\n",
    "            m = 26 - n\n",
    "            # Crea un array con n elementi 1 e m elementi 0 ordinati in modo casuale\n",
    "            array_casuale = np.array([1] * n + [0] * m)\n",
    "            np.random.shuffle(array_casuale)\n",
    "            population.append(array_casuale.tolist())\n",
    "        \n",
    "        return population\n",
    "\n",
    "    def _evaluated_population(self,population):\n",
    "        \n",
    "        fitness_value=[]\n",
    "        best_fitness=0\n",
    "        \n",
    "        best_ga_instance=None\n",
    "        for instance,i in zip(population, range(0,len(population))):\n",
    "            fit=self.fitness_function(instance) \n",
    "            fitness_value.append(fit)\n",
    "            if self.verbose==1: print('{}. {} : {}'.format(i,instance,fit))\n",
    "            if fit>best_fitness:\n",
    "                best_fitness=fit\n",
    "                best_ga_instance=instance\n",
    "        \n",
    "        return best_fitness, best_ga_instance, fitness_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository: hbase_e593f0efbf1144bcb5909d2630321e631a2e66bb\n",
      "Best Solution\n",
      "['conditionalTestLogic', 'testRunWar', 'lcom5', 'functionalDecomposition'] : 0.5\n",
      "    |--- Train_ACC 0.5958350458966982\n",
      "    |--- Train_PR 0.08402822322001283\n",
      "    |--- Train_REC 0.7359550561797753\n",
      "    |--- Train_F1 0.15083477259643063\n",
      "     Performance Test\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 73\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m     Performance Test\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     72\u001B[0m y_predict\u001B[38;5;241m=\u001B[39mpipeline\u001B[38;5;241m.\u001B[39mpredict(X_source_test)\n\u001B[0;32m---> 73\u001B[0m \u001B[43mval_and_log_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_source_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_predict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m     Performance Target\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     75\u001B[0m y_predict\u001B[38;5;241m=\u001B[39mpipeline\u001B[38;5;241m.\u001B[39mpredict(X_target)\n",
      "Cell \u001B[0;32mIn[22], line 33\u001B[0m, in \u001B[0;36mval_and_log_metrics\u001B[0;34m(y_true, y_predict, print)\u001B[0m\n\u001B[1;32m     30\u001B[0m fpr, tpr, _ \u001B[38;5;241m=\u001B[39m roc_curve(y_true,  y_predict)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mprint\u001B[39m:\n\u001B[0;32m---> 33\u001B[0m     \u001B[38;5;28;43mprint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m    |--- TEST_ACC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43macc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    |--- TEST_PR\u001B[39m\u001B[38;5;124m\"\u001B[39m,pr)\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    |--- TEST_REC\u001B[39m\u001B[38;5;124m\"\u001B[39m,rec)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "list_target=[repository1, repository2, repository3]\n",
    "\n",
    "NUMERICAL_FEATURES = [\n",
    "    \"tloc\",\n",
    "    \"tmcCabe\",\n",
    "    \"assertionDensity\",\n",
    "    \"assertionRoulette\",\n",
    "    \"mysteryGuest\",\n",
    "    \"eagerTest\",\n",
    "    \"sensitiveEquality\",\n",
    "    \"resourceOptimism\",\n",
    "    \"conditionalTestLogic\",\n",
    "    \"fireAndForget\",\n",
    "    \"testRunWar\",\n",
    "    \"loc\",\n",
    "    \"lcom2\",\n",
    "    \"lcom5\",\n",
    "    \"cbo\",\n",
    "    \"wmc\",\n",
    "    \"rfc\",\n",
    "    \"mpc\",\n",
    "    \"halsteadVocabulary\",\n",
    "    \"halsteadLength\",\n",
    "    \"halsteadVolume\",\n",
    "    \"classDataShouldBePrivate\",\n",
    "    \"complexClass\",\n",
    "    \"spaghettiCode\",\n",
    "    \"functionalDecomposition\",\n",
    "    \"godClass\"\n",
    "]\n",
    "\n",
    "\n",
    "for target in list_target:\n",
    "    print('Repository: {}'.format(target))\n",
    "    \n",
    "    target_set=dataset.loc[dataset['nameProject']==target]\n",
    "    source_set=dataset.loc[dataset['nameProject']!=target]\n",
    "    \n",
    "    geneticAlghoritm=FeatureSelection_GA(source_set, target_set,NUMERICAL_FEATURES)\n",
    "    best_ga_instance, best_fitness=geneticAlghoritm.run(100,30,0.7,0)\n",
    "    \n",
    "    print(\"Best Solution\")\n",
    "    print('{} : {}'.format(best_ga_instance, best_fitness))\n",
    "    \n",
    "    \n",
    "    X_target=target_set[best_ga_instance]\n",
    "    y_target=target_set['isFlaky']\n",
    "    X_source=source_set[best_ga_instance]\n",
    "    y_source=source_set['isFlaky']\n",
    "    \n",
    "\n",
    "    X_source_train, X_source_test, y_source_train, y_source_test= train_test_split(X_source, y_source,stratify=y_source, test_size=0.20,random_state=42)\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline(steps = [('scaler',MinMaxScaler()),\n",
    "                                 (\"model\", RandomForestClassifier(criterion='gini',\n",
    "                                                                  n_estimators=150,\n",
    "                                                                  class_weight='balanced', random_state=42))])\n",
    "\n",
    "    pipeline.fit(X_source_train,y_source_train)\n",
    "    y_predict=pipeline.predict(X_source_train)\n",
    "    eval_and_log_metrics('Train',y_source_train,y_predict)\n",
    "    print('     Performance Test')\n",
    "    y_predict=pipeline.predict(X_source_test)\n",
    "    val_and_log_metrics(y_source_test,y_predict)\n",
    "    print('     Performance Target')\n",
    "    y_predict=pipeline.predict(X_target)\n",
    "    val_and_log_metrics(y_target,y_predict)\n",
    "    print('')\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIC_SM_FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/angeloafeltra/anaconda3/envs/Flakiness_ML_Experiments/lib/python3.10/site-packages/minepy/mine.cpython-310-darwin.so, 0x0002): tried: '/Users/angeloafeltra/anaconda3/envs/Flakiness_ML_Experiments/lib/python3.10/site-packages/minepy/mine.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/angeloafeltra/anaconda3/envs/Flakiness_ML_Experiments/lib/python3.10/site-packages/minepy/mine.cpython-310-darwin.so' (no such file), '/Users/angeloafeltra/anaconda3/envs/Flakiness_ML_Experiments/lib/python3.10/site-packages/minepy/mine.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mminepy\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m target \u001B[38;5;129;01min\u001B[39;00m list_target[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRepository: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(target))\n",
      "File \u001B[0;32m~/anaconda3/envs/Flakiness_ML_Experiments/lib/python3.10/site-packages/minepy/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MINE, pstats, cstats\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmine\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m version \u001B[38;5;28;01mas\u001B[39;00m __version__\n\u001B[1;32m      4\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMINE\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpstats\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcstats\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[0;31mImportError\u001B[0m: dlopen(/Users/angeloafeltra/anaconda3/envs/Flakiness_ML_Experiments/lib/python3.10/site-packages/minepy/mine.cpython-310-darwin.so, 0x0002): tried: '/Users/angeloafeltra/anaconda3/envs/Flakiness_ML_Experiments/lib/python3.10/site-packages/minepy/mine.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/angeloafeltra/anaconda3/envs/Flakiness_ML_Experiments/lib/python3.10/site-packages/minepy/mine.cpython-310-darwin.so' (no such file), '/Users/angeloafeltra/anaconda3/envs/Flakiness_ML_Experiments/lib/python3.10/site-packages/minepy/mine.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))"
     ]
    }
   ],
   "source": [
    "import minepy\n",
    "\n",
    "for target in list_target[0:1]:\n",
    "    print('Repository: {}'.format(target))\n",
    "    \n",
    "    target_set=dataset.loc[dataset['nameProject']==target]\n",
    "    sources_set=dataset.loc[dataset['nameProject']!=target]\n",
    "    \n",
    "    \n",
    "    X_sources_set=sources_set.drop(['nameProject','testCase','isFlaky'],axis=1)\n",
    "    y_sources_set=source_set['isFlkay']\n",
    "    X_target_set=target_set.drop(['nameProject','testCase','isFlaky'],axis=1)\n",
    "    X_target_set=target_set['isFlkay']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
